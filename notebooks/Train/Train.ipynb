{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/ssd/git/3d-mri-domain-adaption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Creating directory /mnt/ssd/git/3d-mri-domain-adaption/logs/3D/ax_sax/train_on_ax_sax\n",
      "2020-12-17 10:42:36,746 INFO -------------------- Start --------------------\n",
      "2020-12-17 10:42:36,746 INFO Working directory: /mnt/ssd/git/3d-mri-domain-adaption.\n",
      "2020-12-17 10:42:36,746 INFO Log file: ./logs/3D/ax_sax/train_on_ax_sax/fold0.log\n",
      "2020-12-17 10:42:36,747 INFO Log level for console: INFO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpu:0', '/gpu:1']\n",
      "{'GPU_IDS': '0,1', 'GPUS': ['/gpu:0', '/gpu:1'], 'ARCHITECTURE': '3D', 'DATASET': 'GCN', 'FOLD': 0, 'EXP_NAME': 'ax_sax/train_on_ax_sax/fold0', 'EXPERIMENT': '3D/ax_sax/train_on_ax_sax/fold0', 'DATA_PATH_AX': '/mnt/ssd/data/gcn/ax_sax_from_flo/AX_3D/', 'DATA_PATH_AX2SAX': '/mnt/ssd/data/gcn/ax_sax_from_flo/AX_to_SAX_3D/', 'DF_PATH': '/mnt/ssd/data/gcn/gcn_05_2020_ax_sax_86/folds.csv', 'MODEL_PATH': 'models/3D/ax_sax/train_on_ax_sax/fold0/2020-12-17_10_42', 'TENSORBOARD_LOG_DIR': 'reports/tensorboard_logs/3D/ax_sax/train_on_ax_sax/fold0/2020-12-17_10_42', 'CONFIG_PATH': 'reports/configs/3D/ax_sax/train_on_ax_sax/fold0/2020-12-17_10_42', 'HISTORY_PATH': 'reports/history/3D/ax_sax/train_on_ax_sax/fold0/2020-12-17_10_42', 'DIM': [80, 112, 112], 'DEPTH': 4, 'FILTERS': 16, 'SPACING': [3, 3, 3], 'M_POOL': [2, 2, 2], 'F_SIZE': [3, 3, 3], 'IMG_CHANNELS': 1, 'MASK_VALUES': [1, 2, 3], 'MASK_CLASSES': 3, 'BORDER_MODE': 4, 'IMG_INTERPOLATION': 1, 'MSK_INTERPOLATION': 0, 'AUGMENT': False, 'SHUFFLE': True, 'AUGMENT_GRID': False, 'RESAMPLE': True, 'SCALER': 'MinMax', 'AX_LOSS_WEIGHT': 10.0, 'WEIGHT_MSE_INPLANE': True, 'MASK_SMALLER_THAN_THRESHOLD': 0.001, 'SAX_LOSS_WEIGHT': 10.0, 'CYCLE_LOSS': True, 'FOCUS_LOSS_WEIGHT': 1.0, 'FOCUS_LOSS': True, 'USE_SAX2AX_PROB': False, 'MIN_UNET_PROBABILITY': 0.9, 'GENERATOR_WORKER': 2, 'SEED': 42, 'BATCHSIZE': 2, 'INITIAL_EPOCH': 0, 'EPOCHS': 300, 'EPOCHS_BETWEEN_CHECKPOINTS': 5, 'MONITOR_FUNCTION': 'val_loss', 'MONITOR_MODE': 'min', 'SAVE_MODEL_FUNCTION': 'val_loss', 'SAVE_MODEL_MODE': 'min', 'MODEL_PATIENCE': 20, 'BN_FIRST': False, 'BATCH_NORMALISATION': True, 'USE_UPSAMPLE': True, 'PAD': 'same', 'KERNEL_INIT': 'he_normal', 'OPTIMIZER': 'adam', 'ACTIVATION': 'elu', 'LEARNING_RATE': 0.0001, 'DECAY_FACTOR': 0.3, 'MIN_LR': 1e-10, 'LOSS_FUNCTION': <function bce_dice_loss at 0x7f2059334048>}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.Notebook_imports import *\n",
    "from src.utils.Tensorflow_helper import choose_gpu_by_id\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import cv2\n",
    "# ------------------------------------------define GPU id/s to use\n",
    "GPU_IDS = '0,1'\n",
    "GPUS = choose_gpu_by_id(GPU_IDS)\n",
    "print(GPUS)\n",
    "# ------------------------------------------jupyter magic config\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# ------------------------------------------ import helpers\n",
    "from src.utils.Utils_io import Console_and_file_logger, init_config\n",
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "from src.data.Dataset import get_img_msk_files_from_split_dir, load_acdc_files, get_train_data_from_df, get_trainings_files\n",
    "from src.data.Generators import DataGenerator, CycleMotionDataGenerator\n",
    "from src.utils.KerasCallbacks import get_callbacks\n",
    "import src.utils.Loss_and_metrics as metr\n",
    "import src.models.SpatialTransformer as st\n",
    "from src.models.SpatialTransformer import create_affine_cycle_transformer_model\n",
    "from src.models.ModelUtils import load_pretrained_model\n",
    "# ------------------------------------------path and project params\n",
    "ARCHITECTURE = '3D' # 2D\n",
    "DATASET = 'GCN'  # 'acdc' # or 'gcn' or different versions such as gcn_01/02\n",
    "FOLD = 0 # CV fold 0-3\n",
    "EXP_NAME = 'ax_sax/train_on_ax_sax/fold0' # Define an experiment name, could have subfolder conventions\n",
    "EXPERIMENT = '{}/{}'.format(ARCHITECTURE, EXP_NAME) # Uniform path names, separation of concerns\n",
    "timestemp = str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")) # ad a timestep to each project to make repeated experiments unique\n",
    "\n",
    "# Our generator expects the following fix data structure (could be changed in src/data/Generators)\n",
    "# any-path/\n",
    "#    - AX_3D(anyname_img.nrrd and anyname_msk.nrrd)\n",
    "#    - AX_to_SAX_3D\n",
    "#    - SAX_3D\n",
    "#    - SAX_to_AX_3D\n",
    "DATA_PATH_AX = '/mnt/ssd/data/gcn/ax_sax_from_flo/AX_3D/' # path to AX 3D files\n",
    "DATA_PATH_AX2SAX = DATA_PATH_AX.replace('AX_3D', 'AX_to_SAX_3D') # path to ax2sax 3D files\n",
    "DF_PATH = '/mnt/ssd/data/gcn/gcn_05_2020_ax_sax_86/folds.csv' # path to folds dataframe\n",
    "\n",
    "MODEL_PATH = os.path.join('models', EXPERIMENT, timestemp)\n",
    "TENSORBOARD_LOG_DIR = os.path.join('reports/tensorboard_logs', EXPERIMENT,timestemp)\n",
    "CONFIG_PATH = os.path.join('reports/configs/',EXPERIMENT,timestemp)\n",
    "HISTORY_PATH = os.path.join('reports/history/',EXPERIMENT,timestemp)\n",
    "\n",
    "# ------------------------------------------static model, loss and generator hyperparameters\n",
    "DIM = [80, 112, 112] # network input params for spacing of 3, (z,y,x)\n",
    "DEPTH = 4 # number of down-/upsampling blocks\n",
    "FILTERS = 16 # initial number of filters, will be doubled after each downsampling block\n",
    "SPACING = [3, 3, 3] # if resample, resample to this spacing, (z,y,x)\n",
    "M_POOL = [2, 2, 2]# size of max-pooling used for downsampling and upsampling\n",
    "F_SIZE = [3, 3, 3] # conv filter size\n",
    "IMG_CHANNELS = 1 # Currently our model needs that image channel\n",
    "MASK_VALUES = [1, 2, 3]  #channel order: Background, RV, MYO, LV\n",
    "MASK_CLASSES = len(MASK_VALUES) # no of labels\n",
    "BORDER_MODE = cv2.BORDER_REFLECT_101 # border mode for the data generation\n",
    "IMG_INTERPOLATION = cv2.INTER_LINEAR # image interpolation in the genarator\n",
    "MSK_INTERPOLATION = cv2.INTER_NEAREST # mask interpolation in the generator\n",
    "AUGMENT = False # Not implemented for the AX2SAX case\n",
    "SHUFFLE = True\n",
    "AUGMENT_GRID = False # Not implemented for the AX2SAX case\n",
    "RESAMPLE = True\n",
    "SCALER = 'MinMax' # MinMax Standard or Robust\n",
    "\n",
    "AX_LOSS_WEIGHT = 10.0 # weighting factor of the ax2sax loss\n",
    "WEIGHT_MSE_INPLANE = True # turn inplane weighting on/off\n",
    "MASK_SMALLER_THAN_THRESHOLD = 0.001 # define the threshold for masking the ax2sax/sax2ax MSE loss, areas with smaller values, will be masked out\n",
    "\n",
    "SAX_LOSS_WEIGHT = 10.0 # weighting factor of the sax2ax loss\n",
    "CYCLE_LOSS = True # turn this loss on/off\n",
    "\n",
    "FOCUS_LOSS_WEIGHT = 1.0 # weighting of the focus loss\n",
    "FOCUS_LOSS = True # turn this loss on/off\n",
    "USE_SAX2AX_PROB = False # apply the focus loss on AX2SAX_mask predictions, or on AX2SAX2AX_mask (back-transformed) predictions\n",
    "MIN_UNET_PROBABILITY = 0.9 # threshold to count only prediction greater than this value for the focus loss\n",
    "\n",
    "# ------------------------------------------individual training params\n",
    "GENERATOR_WORKER = 2 # number of parallel workers in our generator. if not set, use batchsize, numbers greater than batchsize does not make any sense\n",
    "SEED = 42 # define a seed for the generator shuffle\n",
    "BATCHSIZE = 2 # 32, 64, 24, 16, 1 for 3spacing 3,3,3 use: 2\n",
    "INITIAL_EPOCH = 0 # change this to continue training\n",
    "EPOCHS = 300 # define a maximum numbers of epochs\n",
    "EPOCHS_BETWEEN_CHECKPOINTS = 5\n",
    "MONITOR_FUNCTION = 'val_loss'\n",
    "MONITOR_MODE = 'min'\n",
    "SAVE_MODEL_FUNCTION = 'val_loss'\n",
    "SAVE_MODEL_MODE = 'min'\n",
    "MODEL_PATIENCE = 20\n",
    "BN_FIRST = False # decide if batch normalisation between conv and activation or afterwards\n",
    "BATCH_NORMALISATION = True # apply BN or not\n",
    "USE_UPSAMPLE = True # otherwise use transpose for upsampling\n",
    "PAD = 'same' # padding strategy of the conv layers\n",
    "KERNEL_INIT = 'he_normal' # conv weight initialisation\n",
    "OPTIMIZER = 'adam' # Adam, Adagrad, RMSprop, Adadelta,  # https://keras.io/optimizers/\n",
    "ACTIVATION = 'elu' # tf.keras.layers.LeakyReLU(), relu or any other non linear activation function\n",
    "LEARNING_RATE = 1e-4 # start with a huge lr to converge fast\n",
    "DECAY_FACTOR = 0.3 # Define a learning rate decay for the ReduceLROnPlateau callback\n",
    "MIN_LR = 1e-10 # minimal lr, smaller lr does not improve the model\n",
    "DROPOUT_min = 0.3 # lower dropout at the shallow layers\n",
    "DROPOUT_max = 0.5 # higher dropout at the deep layers\n",
    "\n",
    "# ------------------------------------------these metrics and loss function are meant if you continue training of the U-Net\n",
    "metrics = [\n",
    "    metr.dice_coef_labels,\n",
    "    metr.dice_coef_myo,\n",
    "    metr.dice_coef_lv,\n",
    "    metr.dice_coef_rv\n",
    "]\n",
    "LOSS_FUNCTION = metr.bce_dice_loss\n",
    "\n",
    "# Create a logger instance with the following setup: info or debug to console and file and error logs to a separate file\n",
    "# Define a config for param injection,\n",
    "# save a serialized version to load the experiment for prediction/evaluation, \n",
    "# make sure all paths exist\n",
    "Console_and_file_logger(EXPERIMENT, logging.INFO)\n",
    "config = init_config(config=locals(), save=True)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Tensorflow setup and available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-17 10:42:50,054 INFO Is built with tensorflow: True\n",
      "2020-12-17 10:42:50,133 INFO Visible devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2020-12-17 10:42:50,765 INFO Local devices: \n",
      " [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17599250529092792772\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9735922964754997622\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7119157354592856410\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8596277156170993287\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22978786816\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8515477086180843154\n",
      "physical_device_desc: \"device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23561682304\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16239180294213861403\n",
      "physical_device_desc: \"device: 1, name: TITAN RTX, pci bus id: 0000:02:00.0, compute capability: 7.5\"\n",
      "]\n",
      "2020-12-17 10:42:50,932 INFO Compute dtype: float16\n",
      "2020-12-17 10:42:50,933 INFO Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "logging.info('Is built with tensorflow: {}'.format(tf.test.is_built_with_cuda()))\n",
    "logging.info('Visible devices:\\n{}'.format(tf.config.list_physical_devices()))\n",
    "logging.info('Local devices: \\n {}'.format(device_lib.list_local_devices()))\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "logging.info('Compute dtype: %s' % policy.compute_dtype)\n",
    "logging.info('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trainings and validation files for the choosen fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-17 10:42:51,398 INFO Found 162 images/masks in /mnt/ssd/data/gcn/ax_sax_from_flo/AX_3D/\n",
      "2020-12-17 10:42:51,399 INFO Patients train: 64\n",
      "2020-12-17 10:42:51,404 INFO Selected 120 of 162 files with 64 of 86 patients for training fold 0\n",
      "2020-12-17 10:42:51,405 INFO AX x_train files: 120, AX y_train files: 120\n",
      "2020-12-17 10:42:51,405 INFO AX x_val files: 42, AX y_val files: 42\n",
      "2020-12-17 10:42:51,409 INFO Found 162 images/masks in /mnt/ssd/data/gcn/ax_sax_from_flo/AX_to_SAX_3D/\n",
      "2020-12-17 10:42:51,409 INFO Patients train: 64\n",
      "2020-12-17 10:42:51,415 INFO Selected 120 of 162 files with 64 of 86 patients for training fold 0\n",
      "2020-12-17 10:42:51,416 INFO x_train files: 120, y_train files: 120\n",
      "2020-12-17 10:42:51,417 INFO x_val files: 42, y_val files: 42\n"
     ]
    }
   ],
   "source": [
    "# Load AX volumes\n",
    "x_train_ax, y_train_ax, x_val_ax, y_val_ax =  get_trainings_files(data_path=DATA_PATH_AX,path_to_folds_df=DF_PATH, fold=FOLD)\n",
    "\n",
    "logging.info('AX x_train files: {}, AX y_train files: {}'.format(len(x_train_ax), len(y_train_ax)))\n",
    "logging.info('AX x_val files: {}, AX y_val files: {}'.format(len(x_val_ax), len(y_val_ax)))\n",
    "\n",
    "# load AX2SAX volumes, they should be in the same directory but with a different suffix --> AX_to_SAX_3D\n",
    "x_train_sax, y_train_sax, x_val_sax, y_val_sax =  get_trainings_files(data_path=DATA_PATH_AX2SAX,path_to_folds_df=DF_PATH, fold=FOLD)\n",
    "config = init_config(config)\n",
    "\n",
    "logging.info('x_train files: {}, y_train files: {}'.format(len(x_train_sax), len(y_train_sax)))\n",
    "logging.info('x_val files: {}, y_val files: {}'.format(len(x_val_sax), len(y_val_sax)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "42\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# filter files by name, debugging purpose\n",
    "#x_val_ax = [x for x in x_val_ax if '4A4PVCYL_2006' in x]\n",
    "#x_val_sax = [x for x in x_val_sax if '4A4PVCYL_2006' in x]\n",
    "#y_val_ax = [x for x in y_val_ax if '4A4PVCYL_2006' in x]\n",
    "print(len(x_val_ax))\n",
    "print(len(x_val_sax))\n",
    "print(len(y_val_ax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-17 10:42:53,669 INFO Create DataGenerator\n",
      "2020-12-17 10:42:53,671 INFO Datagenerator created with: \n",
      " shape: [80, 112, 112]\n",
      " spacing: [3, 3, 3]\n",
      " batchsize: 2\n",
      " Scaler: MinMax\n",
      " Images: 120 \n",
      " Augment_grid: False \n",
      " Thread workers: 2\n",
      "2020-12-17 10:42:53,672 INFO No augmentation\n",
      "2020-12-17 10:42:53,672 INFO Create DataGenerator\n",
      "2020-12-17 10:42:53,673 INFO Datagenerator created with: \n",
      " shape: [80, 112, 112]\n",
      " spacing: [3, 3, 3]\n",
      " batchsize: 2\n",
      " Scaler: MinMax\n",
      " Images: 42 \n",
      " Augment_grid: False \n",
      " Thread workers: 2\n",
      "2020-12-17 10:42:53,673 INFO No augmentation\n"
     ]
    }
   ],
   "source": [
    "# create two generators, one for the training files, one for the validation files\n",
    "batch_generator = CycleMotionDataGenerator(x_train_ax, x_train_sax, config)\n",
    "valid_config = config.copy()\n",
    "valid_config['AUGMENT_GRID'] = False\n",
    "valid_config['AUGMENT'] = False\n",
    "valid_generator = CycleMotionDataGenerator(x_val_ax, x_val_sax, valid_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e36b4c36a74324b60e77b901c8652d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='batch', max=21), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select batch generator output\n",
    "x = ''\n",
    "y = ''\n",
    "@interact\n",
    "def select_batch(batch = (0,len(valid_generator), 1)):\n",
    "    global x, y, x2, y2\n",
    "    input_ , output_ = valid_generator.__getitem__(batch)\n",
    "    x = input_[0]\n",
    "    y = output_[0]\n",
    "    x2 = input_[1]\n",
    "    y2 = output_[1]\n",
    "    logging.info('input elements: {}'.format(len(input_)))\n",
    "    logging.info('output elements: {}'.format(len(output_)))\n",
    "    logging.info(x.shape)\n",
    "    logging.info(y.shape)\n",
    "    logging.info(x2.shape)\n",
    "    logging.info(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e4b6525d404523b97f89db9d0f99df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='im', max=1), IntSlider(value=3, description='slice_by', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def select_image_in_batch(im = (0,x.shape[0]- 1, 1),slice_by=(1,6)):\n",
    "    \n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "    temp_dir = 'reports/figures/temp/'\n",
    "    ensure_dir(temp_dir)\n",
    "\n",
    "    logging.info('AX: {}'.format(x[im].shape))\n",
    "    show_2D_or_3D(x[im][...,0][::slice_by])\n",
    "    plt.savefig(os.path.join(temp_dir,'ax.pdf'))\n",
    "    plt.show()\n",
    "    logging.info('AXtoSAX: {}'.format(y[im].shape))\n",
    "    show_2D_or_3D(y[im][...,0][::slice_by])\n",
    "    plt.savefig(os.path.join(temp_dir,'ax2sax.pdf'))\n",
    "    plt.show()\n",
    "    logging.info('SAX: {}'.format(x2[im].shape))\n",
    "    show_2D_or_3D(x2[im][...,0][::slice_by])\n",
    "    plt.savefig(os.path.join(temp_dir,'sax.pdf'))\n",
    "    plt.show()\n",
    "    logging.info('SAXtoAX: {}'.format(y2[im].shape))\n",
    "    show_2D_or_3D(y2[im][...,0][::slice_by])\n",
    "    plt.savefig(os.path.join(temp_dir,'sax2ax.pdf'))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-17 10:43:10,118 INFO Load model from Experiment: 2D/gcn_05_2020_sax_excl_ax_patients\n",
      "2020-12-17 10:43:10,119 INFO load model with keras api\n",
      "2020-12-17 10:43:12,450 INFO Unable to restore custom object of type _tf_keras_metric currently. Please make sure that the layer implements `get_config`and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "2020-12-17 10:43:12,451 INFO Keras API failed, use json repr. load model from: models/2D/gcn_05_2020_sax_excl_ax_patients/2020-11-20_17_24/model.json .\n",
      "2020-12-17 10:43:12,452 INFO loading model description\n",
      "2020-12-17 10:43:13,368 INFO loading model weights\n",
      "2020-12-17 10:43:13,533 INFO model models/2D/gcn_05_2020_sax_excl_ax_patients/2020-11-20_17_24/model.json loaded\n"
     ]
    }
   ],
   "source": [
    "# load a pretrained 2D unet\n",
    "\"\"\"\n",
    "load past config for model training \n",
    "\"\"\"\n",
    "if 'config_chooser' in locals():\n",
    "    config_file  = config_chooser.selected\n",
    "else:\n",
    "    #config_file = '/mnt/ssd/git/3d-mri-domain-adaption/reports/configs/2D/gcn_and_acdc_excl_ax/config.json' # config for TMI paper\n",
    "    config_file = '/mnt/ssd/git/cardio/reports/configs/2D/gcn_05_2020_sax_excl_ax_patients/2020-11-20_17_24/config.json' # retrained with downsampling\n",
    "\n",
    "# load config with all params into global namespace\n",
    "with open(config_file, encoding='utf-8') as data_file:\n",
    "    config_temp = json.loads(data_file.read())\n",
    "logging.info('Load model from Experiment: {}'.format(config_temp['EXPERIMENT']))\n",
    "\n",
    "if 'strategy' not in globals():\n",
    "    # distribute the training with the mirrored data paradigm across multiple gpus if available, if not use gpu 0\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=config.get('GPUS', [\"/gpu:0\"]))\n",
    "with strategy.scope():\n",
    "    globals()['unet'] = load_pretrained_model(config_temp, metrics, comp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-17 10:43:28,013 INFO unet given, use it to max probability\n",
      "2020-12-17 10:43:46,630 INFO adding ax2sax MSE loss with a weighting of 10.0\n",
      "2020-12-17 10:43:46,631 INFO adding cycle loss with a weighting of 10.0\n",
      "2020-12-17 10:43:46,632 INFO adding focus loss on mask_prob with a weighting of 1.0\n"
     ]
    }
   ],
   "source": [
    "if 'strategy' not in globals():\n",
    "    # distribute the training with the mirrored data paradigm across multiple gpus if available, if not use gpu 0\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=config.get('GPUS', [\"/gpu:0\"]))\n",
    "# inject the pre-trained unet if given, otherwise build the model without the pretrained unet\n",
    "with strategy.scope():\n",
    "    model = st.create_affine_cycle_transformer_model(config=config, unet=locals().get('unet', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"affine_cycle_transformer\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_1 (InputLayer)                             [(None, 80, 112, 112, 1)]        0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv_encoder (ConvEncoder)                       ((None, 5, 7, 7, 256), [(None, 8 3537424           input_1[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "global_average_pooling3d (GlobalAveragePooling3D (None, 256)                      0                 conv_encoder[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense1 (Dense)                                   (None, 256)                      65792             global_average_pooling3d[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense2 (Dense)                                   (None, 9)                        2313              dense1[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (TensorFlowOpLayer)  [(None, 3)]                      0                 dense2[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (TensorFlowOpLayer)  [(None, 3)]                      0                 dense2[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate (Concatenate)                        (None, 6)                        0                 tf_op_layer_strided_slice_1[0][0]                 \n",
      "                                                                                                    tf_op_layer_strided_slice_2[0][0]                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (TensorFlowOpLayer)    [(None, 6)]                      0                 dense2[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "ax2sax_mod_matrix (Euler2Matrix)                 (None, 12)                       0                 concatenate[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "ax2sax_matrix (Euler2Matrix)                     (None, 12)                       0                 tf_op_layer_strided_slice[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "ax2sax_mod_st (SpatialTransformer)               (None, 80, 112, 112, 1)          0                 input_1[0][0]                                     \n",
      "                                                                                                    ax2sax_mod_matrix[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "input_2 (InputLayer)                             [(None, 80, 112, 112, 1)]        0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "inverse3d_matrix (Inverse3DMatrix)               (None, 12)                       0                 ax2sax_matrix[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "mask_prob (UnetWrapper)                          (None, 80, 112, 112, 3)          19432275          ax2sax_mod_st[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "inverse3d_matrix_1 (Inverse3DMatrix)             (None, 12)                       0                 ax2sax_mod_matrix[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "ax2sax (SpatialTransformer)                      (None, 80, 112, 112, 1)          0                 input_1[0][0]                                     \n",
      "                                                                                                    ax2sax_matrix[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "sax2ax (SpatialTransformer)                      (None, 80, 112, 112, 1)          0                 input_2[0][0]                                     \n",
      "                                                                                                    inverse3d_matrix[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "mask2ax (SpatialTransformer)                     (None, 80, 112, 112, 3)          0                 mask_prob[0][0]                                   \n",
      "                                                                                                    inverse3d_matrix_1[0][0]                          \n",
      "======================================================================================================================================================\n",
      "Total params: 23,037,804\n",
      "Trainable params: 3,603,545\n",
      "Non-trainable params: 19,434,259\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=150)\n",
    "#plot_model(model, to_file='reports/figures/temp_graph.pdf',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21431215a7bb4adbb50746a9e58639db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='im', max=1), Text(value='0.001', description='mask_small…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def select_image_in_batch(im = (0,x.shape[0]- 1, 1),mask_smaller_than='0.001', slice_by=(1,6)):\n",
    "    global m\n",
    "    import numpy as np\n",
    "    temp = x[im]\n",
    "    sax = x2[im]\n",
    "    temp_ = y[im]\n",
    "    \n",
    "    mask = temp_ >float(mask_smaller_than)\n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info('prediction on: {}'.format(temp.shape))\n",
    "    show_2D_or_3D(temp[::slice_by])\n",
    "    plt.show()\n",
    "    pred, inv_pred, ax2sax_mod, prob, ax_msk,m, m_mod = model.predict(x = [np.expand_dims(temp,axis=0),np.expand_dims(sax,axis=0)])                     \n",
    "    logging.info('rotated by the model: {}'.format(pred[0].shape))\n",
    "    show_2D_or_3D(pred[0][::slice_by], mask[::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('inverse rotation on SAX: {}'.format(inv_pred[0].shape))\n",
    "    show_2D_or_3D(inv_pred[0][::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('predicted mask: {}'.format(inv_pred[0].shape))\n",
    "    show_2D_or_3D(prob[0][::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('predicted mask in ax: {}'.format(ax_msk[0].shape))\n",
    "    show_2D_or_3D(ax_msk[0][::slice_by])\n",
    "    plt.show()\n",
    "    \n",
    "    # calculate the loss mask from target AX2SAX image\n",
    "    mask = temp_ >float(mask_smaller_than)\n",
    "    logging.info('masked by GT: {}'.format(mask.shape))\n",
    "    masked = pred[0] * mask\n",
    "    show_2D_or_3D(masked[::slice_by], mask[::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('target (AX2SAX): {}'.format(temp_.shape))\n",
    "    show_2D_or_3D(temp_[::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('Created MSE mask by thresholding the target (AX2SAX) with {}: {}'.format(mask_smaller_than,temp_.shape))\n",
    "    show_2D_or_3D(mask[::slice_by])\n",
    "    plt.show()\n",
    "\n",
    "    try:\n",
    "        from tensorflow.keras.metrics import MSE as mse\n",
    "        logging.info('MSE: {}'.format(mse(pred[0], temp_).numpy().mean()))\n",
    "        logging.info('prob loss: {}'.format(metr.max_volume_loss(min_probabillity=0.5)(temp_[tf.newaxis,...],prob).numpy().mean()))\n",
    "        print(np.reshape(m[0],(3,4)))\n",
    "        print(np.reshape(m_mod[0],(3,4)))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-17 10:43:48,700 INFO Fit model, start trainings process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 26.8504 - ax2sax_loss: 1.1781 - sax2ax_loss: 1.4077 - mask_prob_loss: 0.9926\n",
      "Epoch 00001: val_loss improved from inf to 26.60986, saving model to models/3D/ax_sax/train_on_ax_sax/fold0/2020-12-17_10_42/model.h5\n",
      "60/60 [==============================] - 165s 3s/step - loss: 26.8504 - ax2sax_loss: 1.1781 - sax2ax_loss: 1.4077 - mask_prob_loss: 0.9926 - val_loss: 26.6099 - val_ax2sax_loss: 1.2003 - val_sax2ax_loss: 1.3616 - val_mask_prob_loss: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 26.2664 - ax2sax_loss: 1.1480 - sax2ax_loss: 1.3794 - mask_prob_loss: 0.9926\n",
      "Epoch 00002: val_loss improved from 26.60986 to 26.18927, saving model to models/3D/ax_sax/train_on_ax_sax/fold0/2020-12-17_10_42/model.h5\n",
      "60/60 [==============================] - 124s 2s/step - loss: 26.2664 - ax2sax_loss: 1.1480 - sax2ax_loss: 1.3794 - mask_prob_loss: 0.9926 - val_loss: 26.1893 - val_ax2sax_loss: 1.1846 - val_sax2ax_loss: 1.3353 - val_mask_prob_loss: 0.9903 - lr: 1.0000e-04\n",
      "Epoch 3/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 26.0794 - ax2sax_loss: 1.1379 - sax2ax_loss: 1.3708 - mask_prob_loss: 0.9924\n",
      "Epoch 00003: val_loss improved from 26.18927 to 25.23007, saving model to models/3D/ax_sax/train_on_ax_sax/fold0/2020-12-17_10_42/model.h5\n",
      "60/60 [==============================] - 127s 2s/step - loss: 26.0794 - ax2sax_loss: 1.1379 - sax2ax_loss: 1.3708 - mask_prob_loss: 0.9924 - val_loss: 25.2301 - val_ax2sax_loss: 1.1413 - val_sax2ax_loss: 1.2827 - val_mask_prob_loss: 0.9900 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 25.0581 - ax2sax_loss: 1.0856 - sax2ax_loss: 1.3211 - mask_prob_loss: 0.9914\n",
      "Epoch 00004: val_loss improved from 25.23007 to 23.84656, saving model to models/3D/ax_sax/train_on_ax_sax/fold0/2020-12-17_10_42/model.h5\n",
      "60/60 [==============================] - 130s 2s/step - loss: 25.0581 - ax2sax_loss: 1.0856 - sax2ax_loss: 1.3211 - mask_prob_loss: 0.9914 - val_loss: 23.8466 - val_ax2sax_loss: 1.0679 - val_sax2ax_loss: 1.2178 - val_mask_prob_loss: 0.9900 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 23.4313 - ax2sax_loss: 1.0103 - sax2ax_loss: 1.2338 - mask_prob_loss: 0.9901\n",
      "Epoch 00005: val_loss improved from 23.84656 to 23.68465, saving model to models/3D/ax_sax/train_on_ax_sax/fold0/2020-12-17_10_42/model.h5\n",
      "60/60 [==============================] - 126s 2s/step - loss: 23.4313 - ax2sax_loss: 1.0103 - sax2ax_loss: 1.2338 - mask_prob_loss: 0.9901 - val_loss: 23.6846 - val_ax2sax_loss: 1.0605 - val_sax2ax_loss: 1.2090 - val_mask_prob_loss: 0.9898 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 23.0025 - ax2sax_loss: 0.9880 - sax2ax_loss: 1.2132 - mask_prob_loss: 0.9900\n",
      "Epoch 00006: val_loss improved from 23.68465 to 23.10851, saving model to models/3D/ax_sax/train_on_ax_sax/fold0/2020-12-17_10_42/model.h5\n",
      "60/60 [==============================] - 127s 2s/step - loss: 23.0025 - ax2sax_loss: 0.9880 - sax2ax_loss: 1.2132 - mask_prob_loss: 0.9900 - val_loss: 23.1085 - val_ax2sax_loss: 1.0306 - val_sax2ax_loss: 1.1813 - val_mask_prob_loss: 0.9902 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 22.6042 - ax2sax_loss: 0.9704 - sax2ax_loss: 1.1910 - mask_prob_loss: 0.9901\n",
      "Epoch 00007: val_loss improved from 23.10851 to 22.81109, saving model to models/3D/ax_sax/train_on_ax_sax/fold0/2020-12-17_10_42/model.h5\n",
      "60/60 [==============================] - 128s 2s/step - loss: 22.6042 - ax2sax_loss: 0.9704 - sax2ax_loss: 1.1910 - mask_prob_loss: 0.9901 - val_loss: 22.8111 - val_ax2sax_loss: 1.0164 - val_sax2ax_loss: 1.1657 - val_mask_prob_loss: 0.9902 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "21/60 [=========>....................] - ETA: 1:03 - loss: 22.2227 - ax2sax_loss: 0.9629 - sax2ax_loss: 1.1602 - mask_prob_loss: 0.9911"
     ]
    }
   ],
   "source": [
    "# train one model\n",
    "initial_epoch = 0\n",
    "logging.info('Fit model, start trainings process')\n",
    "# fit model with trainingsgenerator\n",
    "results = model.fit(\n",
    "    x=batch_generator,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(valid_generator),\n",
    "    epochs=200,\n",
    "    callbacks = get_callbacks(config, valid_generator),\n",
    "    steps_per_epoch = len(batch_generator),\n",
    "    initial_epoch=initial_epoch,\n",
    "    max_queue_size=20,\n",
    "    workers=8,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if for any reason you want to save the latest model, use this cell\n",
    "#tf.keras.models.save_model(model,filepath=config['MODEL_PATH'],overwrite=True,include_optimizer=False,save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['MODEL_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-07 14:30:29,323 INFO Load model from Experiment: 3D/ax_sax/unetwithdownsamplingaugmentation_new_data\n",
      "2020-12-07 14:30:30,068 INFO unet given, use it to max probability\n",
      "2020-12-07 14:30:48,204 INFO adding ax2sax MSE loss with a weighting of 10.0\n",
      "2020-12-07 14:30:48,205 INFO adding cycle loss with a weighting of 10.0\n",
      "2020-12-07 14:30:48,206 INFO adding focus loss on mask_prob with a weighting of 1.0\n",
      "2020-12-07 14:30:48,484 INFO loaded model weights as h5 file\n"
     ]
    }
   ],
   "source": [
    "# Fast tests of a trained model, the \"real\" predictions will be done in src/notebooks/Predict\n",
    "\n",
    "\"\"\"\n",
    "load past config for model training \n",
    "\"\"\"\n",
    "if 'strategy' not in locals():\n",
    "    # distribute the training with the mirrored data paradigm across multiple gpus if available, if not use gpu 0\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=config.get('GPUS', [\"/gpu:0\"]))\n",
    "\n",
    "# round the crop and pad values instead of ceil\n",
    "#config_file = 'reports/configs/3D/ax_sax/unetwithdownsamplingaugmentation_new_data/2020-12-03_18_20/config.json' # Fold 0\n",
    "#config_file = 'reports/configs/3D/ax_sax/unetwithdownsamplingaugmentation_new_data/2020-12-03_22_02/config.json' # Fold 1\n",
    "#config_file = 'reports/configs/3D/ax_sax/unetwithdownsamplingaugmentation_new_data/2020-12-04_16_56/config.json' # Fold 2\n",
    "config_file = 'reports/configs/3D/ax_sax/unetwithdownsamplingaugmentation_new_data/2020-12-07_12_36/config.json' # Fold 3\n",
    "\n",
    "\n",
    "# load a pre-trained ax2sax model, create the graph and load the weights separately, due to own loss functions, this is easier\n",
    "with open(config_file, encoding='utf-8') as data_file:\n",
    "    config_temp = json.loads(data_file.read())\n",
    "config_temp['LOSS_FUNCTION'] = config['LOSS_FUNCTION']\n",
    "logging.info('Load model from Experiment: {}'.format(config_temp['EXPERIMENT']))\n",
    "\n",
    "with strategy.scope():\n",
    "    globals()['model'] = st.create_affine_cycle_transformer_model(config=config_temp, metrics=metrics, unet=locals().get('unet', None))\n",
    "    model.load_weights(os.path.join(config_temp['MODEL_PATH'],'model.h5'))\n",
    "    logging.info('loaded model weights as h5 file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast predictions with all files of the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-03 20:07:27,707 INFO Create DataGenerator\n",
      "2020-12-03 20:07:27,708 INFO Datagenerator created with: \n",
      " shape: [80, 112, 112]\n",
      " spacing: [3, 3, 3]\n",
      " batchsize: 10\n",
      " Scaler: MinMax\n",
      " Images: 120 \n",
      " Augment_grid: False \n",
      " Thread workers: 2\n",
      "2020-12-03 20:07:27,709 INFO No augmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcda926c12e41d386c1bac03825d31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='im', max=9), IntSlider(value=3, description='slice_by', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict, visualise the transformation of AX train files\n",
    "import numpy as np\n",
    "cfg = config.copy()\n",
    "cfg['BATCHSIZE'] = 10\n",
    "cfg['AUGMENT_GRID'] = False\n",
    "valid_generator = CycleMotionDataGenerator(x_train_ax, x_train_sax, cfg)\n",
    "input_, output_ = valid_generator.__getitem__(0)\n",
    "x_ = input_[0]\n",
    "x2_ = input_[1]\n",
    "y_ = output_[0]\n",
    "y2_ = output_[1]\n",
    "@interact\n",
    "def select_image_in_batch(im = (0,x_.shape[0]- 1, 1), slice_by=(1,6)):\n",
    "    global m\n",
    "    temp = x_[im]\n",
    "    temp_ = y_[im]\n",
    "    sax = x2_[im]\n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info('prediction on:')\n",
    "    show_2D_or_3D(temp[::slice_by])\n",
    "    plt.show()\n",
    "    pred, inv_pred, ax2sax_mod, pred_mask, ax2sax_msk,m_first, m = model.predict(x=[np.expand_dims(temp,axis=0),np.expand_dims(sax,axis=0)])\n",
    "\n",
    "    logging.info('rotated by the model')\n",
    "    show_2D_or_3D(pred[0][::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('modified rotation of the model')\n",
    "    show_2D_or_3D(ax2sax_mod[0][::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('predicted mask:')\n",
    "    show_2D_or_3D(pred_mask[0][::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('target (SAX):')\n",
    "    show_2D_or_3D(temp_[::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('inverted rotation on SAX')\n",
    "    show_2D_or_3D(inv_pred[0][::slice_by])\n",
    "    plt.show()\n",
    "    try:\n",
    "        print(np.reshape(m_first[0],(3,4)))\n",
    "        print(np.reshape(m[0],(3,4)))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on the heldout test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-03 20:08:19,977 INFO Create DataGenerator\n",
      "2020-12-03 20:08:19,977 INFO Datagenerator created with: \n",
      " shape: [80, 112, 112]\n",
      " spacing: [3, 3, 3]\n",
      " batchsize: 42\n",
      " Scaler: MinMax\n",
      " Images: 42 \n",
      " Augment_grid: False \n",
      " Thread workers: 2\n",
      "2020-12-03 20:08:19,978 INFO No augmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bde9676ae554b3e925284ca81a94a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='im', max=41), IntSlider(value=3, description='slice_by'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = config.copy()\n",
    "cfg['BATCHSIZE'] = len(x_val_ax)\n",
    "v_generator = CycleMotionDataGenerator(x_val_ax, x_val_sax, cfg)\n",
    "input_, output_ = v_generator.__getitem__(0)\n",
    "x_ = input_[0]\n",
    "x2_ = input_[1]\n",
    "y_ = output_[0]\n",
    "y2_ = output_[1]\n",
    "@interact\n",
    "def select_image_in_batch(im = (0,x_.shape[0]- 1, 1), slice_by=(1,6)):\n",
    "    global m\n",
    "    temp = x_[im]\n",
    "    temp_ = y_[im]\n",
    "    sax = x2_[im]\n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info('prediction on:')\n",
    "    show_2D_or_3D(temp[::slice_by])\n",
    "    plt.show()\n",
    "    \n",
    "    pred, inv_pred, ax2sax_mod, pred_mask, ax_mask, m_first, m = model.predict(x=[np.expand_dims(temp,axis=0),np.expand_dims(sax,axis=0)])\n",
    "    logging.info('rotated by the model')\n",
    "    show_2D_or_3D(pred[0][::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('modified rotation')\n",
    "    show_2D_or_3D(ax2sax_mod[0][::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('predicted mask')\n",
    "    show_2D_or_3D(pred_mask[0][::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('predicted in AX')\n",
    "    show_2D_or_3D(ax_mask[0][::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('target (SAX):')\n",
    "    show_2D_or_3D(temp_[::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('inverted rotation on SAX')\n",
    "    show_2D_or_3D(inv_pred[0][::slice_by])\n",
    "    plt.show()\n",
    "    try:\n",
    "        print(np.reshape(m_first[0],(3,4)))\n",
    "        print(np.reshape(m[0],(3,4)))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the memory usage\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ax2sax",
   "language": "python",
   "name": "ax2sax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
