{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/data/git/cardio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2020-07-06 12:44:23,163 INFO -------------------- Start --------------------\n",
      "2020-07-06 12:44:23,163 INFO Working directory: /mnt/data/git/cardio.\n",
      "2020-07-06 12:44:23,163 INFO Log file: ./logs/3D/ax_sax/st_unet_ax_and_sax/temp.log\n",
      "2020-07-06 12:44:23,163 INFO Log level for console: INFO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpu:0', '/gpu:1']\n",
      "{'GPU_IDS': '0,1', 'GPUS': ['/gpu:0', '/gpu:1'], 'EXPERIMENT': '3D/ax_sax/st_unet_ax_and_sax/temp', 'ARCHITECTURE': '3D', 'DATASET': 'GCN', 'TRAIN_PATH': 'data/raw/GCN/3D/train/', 'VAL_PATH': 'data/raw/GCN/3D/val/', 'TEST_PATH': 'data/raw/GCN/3D/val/', 'DATA_PATH': '/mnt/data/git/cardio/data/raw/gcn_05_2020_ax_sax_86/AX_3D_ISO/', 'FOLD': 0, 'MODEL_PATH': 'models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-06_12_44', 'TENSORBOARD_LOG_DIR': 'reports/tensorboard_logs/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-06_12_44', 'CONFIG_PATH': 'reports/configs/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-06_12_44', 'HISTORY_PATH': 'reports/history/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-06_12_44', 'DIM': [32, 64, 64], 'DEPTH': 4, 'FILTERS': 32, 'SPACING': [5, 5, 5], 'M_POOL': [2, 2, 2], 'F_SIZE': [3, 3, 3], 'IMG_CHANNELS': 1, 'MASK_VALUES': [0, 1, 2, 3], 'MASK_CLASSES': 4, 'BORDER_MODE': 4, 'IMG_INTERPOLATION': 1, 'MSK_INTERPOLATION': 0, 'AUGMENT': False, 'SHUFFLE': True, 'AUGMENT_GRID': False, 'RESAMPLE': True, 'SCALER': 'MinMax', 'SEED': 42, 'BATCHSIZE': 16, 'INITIAL_EPOCH': 0, 'EPOCHS': 300, 'EPOCHS_BETWEEN_CHECKPOINTS': 5, 'MONITOR_FUNCTION': 'loss', 'MONITOR_MODE': 'min', 'SAVE_MODEL_FUNCTION': 'loss', 'SAVE_MODEL_MODE': 'min', 'BN_FIRST': False, 'BATCH_NORMALISATION': True, 'USE_UPSAMPLE': True, 'PAD': 'same', 'KERNEL_INIT': 'he_normal', 'OPTIMIZER': 'adam', 'ACTIVATION': 'elu', 'LEARNING_RATE': 0.01, 'DECAY_FACTOR': 0.3, 'MIN_LR': 1e-10, 'LOSS_FUNCTION': <function bce_dice_loss at 0x7f9288060f28>}\n"
     ]
    }
   ],
   "source": [
    "# define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.notebook_imports import *\n",
    "from pyforest import *\n",
    "from src.utils.Tensorflow_helper import choose_gpu_by_id\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# define GPU id to use\n",
    "GPU_IDS = '0,1'\n",
    "GPUS = choose_gpu_by_id(GPU_IDS)\n",
    "print(GPUS)\n",
    "\n",
    "# jupyter magic config\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import helpers\n",
    "from src.utils.utils_io import Console_and_file_logger, init_config\n",
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "from src.data.Dataset import get_img_msk_files_from_split_dir, load_acdc_files, get_train_data_from_df, get_trainings_files\n",
    "from src.data.Generators import DataGenerator, get_samples\n",
    "#from src.utils.unet_3d_metrics import weighted_dice_coefficient_loss\n",
    "from src.utils.KerasCallbacks import get_callbacks\n",
    "import src.utils.my_metrics as metr\n",
    "import cv2\n",
    "from tensorflow.keras.losses import mse\n",
    "import src.utils.my_metrics as metr\n",
    "\n",
    "\n",
    "# define experiment name for report, model and log paths + filenames\n",
    "#EXPERIMENT = '2D/tf2/acdc/combined/2D_NOrot90_dfsplit_6_224_11_fold1'\n",
    "EXPERIMENT = '3D/ax_sax/st_unet_ax_and_sax/temp'\n",
    "now = datetime.datetime.now()\n",
    "# image params, change for different input data/architecture\n",
    "ARCHITECTURE = '3D' # 2D\n",
    "# path params\n",
    "DATASET = 'GCN'  # 'acdc' # or 'gcn'\n",
    "TRAIN_PATH = 'data/raw/{}/{}/train/'.format(DATASET, ARCHITECTURE)\n",
    "VAL_PATH = 'data/raw/{}/{}/val/'.format(DATASET, ARCHITECTURE)\n",
    "TEST_PATH = 'data/raw/{}/{}/val/'.format(DATASET, ARCHITECTURE)\n",
    "#DF_DATA_PATH = 'data/raw/{}/{}/df_kfold.csv'.format(DATASET, ARCHITECTURE)\n",
    "#DF_DATA_PATH = 'data/raw/miccai2020/2d_dataset.csv' # miccai special case\n",
    "DATA_PATH = '/mnt/data/git/cardio/data/raw/gcn_05_2020_ax_sax_86/AX_3D_ISO/'\n",
    "FOLD = 0\n",
    "\n",
    "MODEL_PATH = os.path.join('models', EXPERIMENT, str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "TENSORBOARD_LOG_DIR = os.path.join('reports/tensorboard_logs', EXPERIMENT,str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "CONFIG_PATH = os.path.join('reports/configs/',EXPERIMENT,str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "HISTORY_PATH = os.path.join('reports/history/',EXPERIMENT,str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "\n",
    "DIM = [32,64, 64] # network input params for spacing of 5\n",
    "#DIM = [80, 224, 224]\n",
    "DEPTH = 4 # number of down-/upsampling blocks\n",
    "FILTERS = 32 # initial number of filters, will be doubled after each downsampling block\n",
    "#SPACING = [8,1.1, 1,1] # used by sitk, order will be reversed to have the same shape as dim\n",
    "SPACING = [5,5, 5] # if resample, resample to this spacing\n",
    "M_POOL = [2, 2, 2]# used for downsampling and upsampling\n",
    "F_SIZE = [3, 3, 3] # conv filter size\n",
    "IMG_CHANNELS = 1\n",
    "MASK_VALUES = [0, 1, 2, 3]  #channel order: Background, RV, MYO, LV\n",
    "MASK_CLASSES = len(MASK_VALUES) # no of labels\n",
    "BORDER_MODE = cv2.BORDER_REFLECT_101\n",
    "IMG_INTERPOLATION = cv2.INTER_LINEAR\n",
    "MSK_INTERPOLATION = cv2.INTER_NEAREST\n",
    "AUGMENT = False\n",
    "SHUFFLE = True\n",
    "AUGMENT_GRID = False\n",
    "RESAMPLE = True\n",
    "SCALER = 'MinMax' # MinMax Standard or Robust\n",
    "\n",
    "# training params\n",
    "#GENERATOR_WORKER = 6# if not set, use batchsize\n",
    "SEED = 42 # define a seed for the generator shuffle\n",
    "BATCHSIZE = 16 # 32, 64, 24, 16, 1 for 3D use: 8\n",
    "INITIAL_EPOCH = 0 # change this to continue training\n",
    "EPOCHS = 300 # define a maximum numbers of epochs\n",
    "EPOCHS_BETWEEN_CHECKPOINTS = 5\n",
    "MONITOR_FUNCTION = 'loss'\n",
    "MONITOR_MODE = 'min'\n",
    "SAVE_MODEL_FUNCTION = 'loss'\n",
    "SAVE_MODEL_MODE = 'min'\n",
    "BN_FIRST = False # decide if BN between Conv and activation or afterwards\n",
    "BATCH_NORMALISATION = True # apply BN or not\n",
    "USE_UPSAMPLE = True # otherwise use transpose\n",
    "PAD = 'same' # padding strategy\n",
    "KERNEL_INIT = 'he_normal' # conv weight initialisation\n",
    "OPTIMIZER = 'adam' # Adam, Adagrad, RMSprop, Adadelta,  # https://keras.io/optimizers/\n",
    "ACTIVATION = 'elu' # tf.keras.layers.LeakyReLU(), relu, any non linear activation function\n",
    "LEARNING_RATE = 1e-2 # start with a huge lr to converge fast\n",
    "DECAY_FACTOR = 0.3 # Define a learning rate decay for the ReduceLROnPlateau callback\n",
    "MIN_LR = 1e-10 # smaller lr does not improve the model\n",
    "DROPOUT_min = 0.3 # lower dropout at the shallow layers\n",
    "DROPOUT_max = 0.5 # higher dropout at the deep layers\n",
    "\n",
    "metrics = [\n",
    "    metr.dice_coef_labels,\n",
    "    metr.dice_coef_myo,\n",
    "    metr.dice_coef_lv,\n",
    "    metr.dice_coef_rv\n",
    "]\n",
    "\n",
    "#MASKING_VALUES = [2]\n",
    "#MASKING_IMAGE = False\n",
    "\n",
    "LOSS_FUNCTION = metr.bce_dice_loss\n",
    "#LOSS_FUNCTION = metr.jaccard_distance_loss\n",
    "#LOSS_FUNCTION = metr.bce_dice_jac_loss\n",
    "\n",
    "Console_and_file_logger(EXPERIMENT, logging.INFO)\n",
    "\n",
    "# Define a config for param injection,\n",
    "# save a serialized version, \n",
    "# make sure all paths exist\n",
    "config = init_config(config=locals(), save=True)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 12:44:25,693 INFO Found 162 images/masks in /mnt/data/git/cardio/data/raw/gcn_05_2020_ax_sax_86/AX_3D_ISO/\n",
      "2020-07-06 12:44:25,698 INFO Selected 120 of 162 files with 64 of 86 patients for training fold 0\n",
      "2020-07-06 12:44:25,699 INFO x_train files: 120, y_train files: 120\n",
      "2020-07-06 12:44:25,700 INFO x_val files: 42, y_val files: 42\n"
     ]
    }
   ],
   "source": [
    "# Load AX slices\n",
    "\n",
    "from src.data.Generators import MotionDataGenerator, CycleMotionDataGenerator, SpatialUnetDataGenerator\n",
    "info = {}\n",
    "\n",
    "x_train_ax, y_train_ax, x_val_ax, y_val_ax =  get_trainings_files(data_path=DATA_PATH,fold=FOLD)\n",
    "config.update(info)\n",
    "config = init_config(config)\n",
    "\n",
    "logging.info('x_train files: {}, y_train files: {}'.format(len(x_train_ax), len(y_train_ax)))\n",
    "logging.info('x_val files: {}, y_val files: {}'.format(len(x_val_ax), len(y_val_ax)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 12:44:26,092 INFO Found 162 images/masks in /mnt/data/git/cardio/data/raw/gcn_05_2020_ax_sax_86/SAX_3D_ISO/\n",
      "2020-07-06 12:44:26,098 INFO Selected 120 of 162 files with 64 of 86 patients for training fold 0\n",
      "2020-07-06 12:44:26,098 INFO x_train files: 120, y_train files: 120\n",
      "2020-07-06 12:44:26,099 INFO x_val files: 42, y_val files: 42\n"
     ]
    }
   ],
   "source": [
    "# load SAX slices\n",
    "DATA_PATH_SAX = DATA_PATH.replace('AX_3D_ISO', 'SAX_3D_ISO')\n",
    "#DATA_PATH_SAX = 'data/interim/sax_ax_3d_thres_50_max/ax_to_sax'\n",
    "x_train_sax, y_train_sax, x_val_sax, y_val_sax =  get_trainings_files(data_path=DATA_PATH_SAX,fold=FOLD)\n",
    "config.update(info)\n",
    "config = init_config(config)\n",
    "\n",
    "logging.info('x_train files: {}, y_train files: {}'.format(len(x_train_sax), len(y_train_sax)))\n",
    "logging.info('x_val files: {}, y_val files: {}'.format(len(x_val_sax), len(y_val_sax)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ax examples: ['/mnt/data/git/cardio/data/raw/gcn_05_2020_ax_sax_86/AX_3D_ISO/0000-0PTV75MP_2005-06-27_ED_img.nrrd', '/mnt/data/git/cardio/data/raw/gcn_05_2020_ax_sax_86/AX_3D_ISO/0000-0PTV75MP_2005-06-27_ES_img.nrrd']\n",
      "sax_examples: ['/mnt/data/git/cardio/data/raw/gcn_05_2020_ax_sax_86/SAX_3D_ISO/0000-0PTV75MP_2005-06-27_ED_img.nrrd', '/mnt/data/git/cardio/data/raw/gcn_05_2020_ax_sax_86/SAX_3D_ISO/0000-0PTV75MP_2005-06-27_ES_img.nrrd']\n"
     ]
    }
   ],
   "source": [
    "print('ax examples: {}'.format(x_train_ax[:2]))\n",
    "print('sax_examples: {}'.format(x_train_sax[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter files by name\n",
    "#x_train_ax = [x for x in x_train_ax if 'CT8YR38C_2005' in x]\n",
    "#print(len(x_train_ax))\n",
    "#x_train_sax = [x for x in x_train_sax if 'CT8YR38C_2005' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 12:44:28,459 INFO -------------------- Start --------------------\n",
      "2020-07-06 12:44:28,460 INFO Working directory: /mnt/data/git/cardio.\n",
      "2020-07-06 12:44:28,460 INFO Log file: ./logs/temp.log\n",
      "2020-07-06 12:44:28,461 INFO Log level for console: INFO\n",
      "2020-07-06 12:44:28,461 INFO Create DataGenerator\n",
      "2020-07-06 12:44:28,463 INFO Datagenerator created with: \n",
      " shape: [32, 64, 64]\n",
      " spacing: [5, 5, 5]\n",
      " batchsize: 16\n",
      " Scaler: MinMax\n",
      " Images: 240 \n",
      " Augment_grid: False \n",
      " Thread workers: 16\n",
      "2020-07-06 12:44:28,463 INFO No augmentation\n"
     ]
    }
   ],
   "source": [
    "Console_and_file_logger('temp', logging.INFO)\n",
    "batch_generator = SpatialUnetDataGenerator(x_train_ax + x_train_sax, y_train_ax + y_train_sax, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc086fb0df24ba6bdb9379275baeeac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=7, description='batch', max=15), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select batch generator output\n",
    "@interact\n",
    "def select_batch(batch = (0,len(batch_generator), 1)):\n",
    "    global x, y\n",
    "    input_ , output_ = batch_generator.__getitem__(batch)\n",
    "    x = input_[0]\n",
    "    y = output_[0]\n",
    "    m = output_[2]\n",
    "    logging.info('input image: {}'.format(x.shape))\n",
    "    logging.info('pred mask: {}'.format(y.shape))\n",
    "    logging.info('transformation matrix: {}'.format(m.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5a16cb42f446be93e5fde77a361e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=7, description='im', max=15), IntSlider(value=4, description='slice_by',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def select_image_in_batch(im = (0,x.shape[0]- 1, 1),slice_by=(1,8)):\n",
    "    \n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "    #show_2D_or_3D(x[im][...,0][::5])\n",
    "    logging.info(x[im].shape)\n",
    "    show_2D_or_3D(x[im][...,0][::slice_by])\n",
    "    plt.savefig('reports/images/temp/ax.pdf')\n",
    "    plt.show()\n",
    "    logging.info(y[im].shape)\n",
    "    show_2D_or_3D(y[im][::slice_by])\n",
    "    plt.savefig('reports/images/temp/sax.pdf')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using tensorflow, need to monkey patch\n",
      "tf.python.backend.slice overwritten by monkey patch\n"
     ]
    }
   ],
   "source": [
    "import src.models.SpatialTransformer as st\n",
    "from src.models.SpatialTransformer import create_affine_transformer, create_affine_cycle_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "if 'strategy' in locals():\n",
    "    pass\n",
    "else:\n",
    "    print('create a new strategy')\n",
    "    # distribute the training with the mirrored data paradigm across multiple gpus if available, if not use gpu 0\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=config.get('GPUS', [\"/gpu:0\"]))\n",
    "with strategy.scope():\n",
    "    model = st.create_spatial_unet(config=config, metrics=metrics, unet_2d=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"enc_st_unet_st\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 32, 64, 64, 1)]   0         \n",
      "_________________________________________________________________\n",
      "trainable_3D_unet (Functiona (None, 32, 64, 64, 4)     25894724  \n",
      "=================================================================\n",
      "Total params: 25,894,724\n",
      "Trainable params: 25,888,836\n",
      "Non-trainable params: 5,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='data/temp/graph.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c5b0c3147f4cdeb1ca2ee5559712d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=7, description='im', max=15), IntSlider(value=6, description='slice_by',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions of the untrained model on the current generator\n",
    "@interact\n",
    "def select_image_in_batch(im = (0,x.shape[0]- 1, 1),slice_by=(1,11)):\n",
    "    global m\n",
    "    temp = x[im]\n",
    "    temp_ = y[im]\n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info('prediction on: {}'.format(temp.shape))\n",
    "    show_2D_or_3D(temp[::slice_by])\n",
    "    plt.show()\n",
    "    pred = model.predict(np.expand_dims(temp,axis=0))\n",
    "    logging.info('max: {}'.format(pred[0][::slice_by].max()))\n",
    "    logging.info('predicted masks of the model: {}'.format(pred[0].shape))\n",
    "    show_2D_or_3D(temp[::slice_by], pred[0][::slice_by])\n",
    "    plt.show()\n",
    "    \"\"\"logging.info('internal repr of the input image: {}'.format(inv.shape))\n",
    "    show_2D_or_3D(inv[0][::slice_by])\n",
    "    plt.show()\"\"\"\n",
    "    logging.info('target mask: {}'.format(temp_.shape))\n",
    "    show_2D_or_3D(temp[::slice_by], temp_[::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('MSE: {}'.format(mse(pred[0], temp_).numpy().mean()))\n",
    "    logging.info('MSE center cube: {}'.format(metr.cubic_center_loss_wrapper(pred[0], temp_).numpy().mean()))\n",
    "    try:\n",
    "        print(np.reshape(m[0],(3,4)))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.Unets import get_optimizer\n",
    "model.compile(optimizer=get_optimizer(config, 'finetune'),\n",
    "                      loss={'warped': metr.front_mse, 'cycle_warped': 'mse' },\n",
    "                      loss_weights={'warped': 1.0, 'cycle_warped': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-03 13:03:08,342 INFO Fit model, start trainings process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-03 13:03:11,820 INFO batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n",
      "2020-07-03 13:03:14,954 INFO batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-03 13:03:28,536 WARNING From /home/sven/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.0401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-03 13:03:35,493 INFO Saved model to disk: models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: loss improved from inf to 0.04008, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 763ms/step - loss: 0.0401 - lr: 0.0100\n",
      "Epoch 2/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.1716\n",
      "Epoch 00002: loss improved from 0.04008 to -0.17164, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 822ms/step - loss: -0.1716 - lr: 0.0100\n",
      "Epoch 3/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.3745\n",
      "Epoch 00003: loss improved from -0.17164 to -0.37452, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 831ms/step - loss: -0.3745 - lr: 0.0100\n",
      "Epoch 4/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.4534\n",
      "Epoch 00004: loss improved from -0.37452 to -0.45338, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 810ms/step - loss: -0.4534 - lr: 0.0100\n",
      "Epoch 5/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.4954\n",
      "Epoch 00005: loss improved from -0.45338 to -0.49544, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 801ms/step - loss: -0.4954 - lr: 0.0100\n",
      "Epoch 6/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.5377\n",
      "Epoch 00006: loss improved from -0.49544 to -0.53772, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 808ms/step - loss: -0.5377 - lr: 0.0100\n",
      "Epoch 7/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.5539\n",
      "Epoch 00007: loss improved from -0.53772 to -0.55393, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 13s 836ms/step - loss: -0.5539 - lr: 0.0100\n",
      "Epoch 8/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.5658\n",
      "Epoch 00008: loss improved from -0.55393 to -0.56577, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 827ms/step - loss: -0.5658 - lr: 0.0100\n",
      "Epoch 9/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.6478\n",
      "Epoch 00009: loss improved from -0.56577 to -0.64780, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 13s 860ms/step - loss: -0.6478 - lr: 0.0100\n",
      "Epoch 10/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.6768\n",
      "Epoch 00010: loss improved from -0.64780 to -0.67677, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 764ms/step - loss: -0.6768 - lr: 0.0100\n",
      "Epoch 11/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.6961\n",
      "Epoch 00011: loss improved from -0.67677 to -0.69612, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 755ms/step - loss: -0.6961 - lr: 0.0100\n",
      "Epoch 12/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7211\n",
      "Epoch 00012: loss improved from -0.69612 to -0.72105, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 751ms/step - loss: -0.7211 - lr: 0.0100\n",
      "Epoch 13/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7326\n",
      "Epoch 00013: loss improved from -0.72105 to -0.73256, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 830ms/step - loss: -0.7326 - lr: 0.0100\n",
      "Epoch 14/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7491\n",
      "Epoch 00014: loss improved from -0.73256 to -0.74915, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 804ms/step - loss: -0.7491 - lr: 0.0100\n",
      "Epoch 15/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7648\n",
      "Epoch 00015: loss improved from -0.74915 to -0.76482, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 805ms/step - loss: -0.7648 - lr: 0.0100\n",
      "Epoch 16/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7740\n",
      "Epoch 00016: loss improved from -0.76482 to -0.77402, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 818ms/step - loss: -0.7740 - lr: 0.0100\n",
      "Epoch 17/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7737\n",
      "Epoch 00017: loss did not improve from -0.77402\n",
      "15/15 [==============================] - 9s 567ms/step - loss: -0.7737 - lr: 0.0100\n",
      "Epoch 18/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7801\n",
      "Epoch 00018: loss improved from -0.77402 to -0.78008, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 784ms/step - loss: -0.7801 - lr: 0.0100\n",
      "Epoch 19/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7852\n",
      "Epoch 00019: loss improved from -0.78008 to -0.78524, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 823ms/step - loss: -0.7852 - lr: 0.0100\n",
      "Epoch 20/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7884 ETA: 0s - loss: -0.\n",
      "Epoch 00020: loss improved from -0.78524 to -0.78838, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 820ms/step - loss: -0.7884 - lr: 0.0100\n",
      "Epoch 21/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7913\n",
      "Epoch 00021: loss improved from -0.78838 to -0.79125, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 812ms/step - loss: -0.7913 - lr: 0.0100\n",
      "Epoch 22/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7747\n",
      "Epoch 00022: loss did not improve from -0.79125\n",
      "15/15 [==============================] - 8s 542ms/step - loss: -0.7747 - lr: 0.0100\n",
      "Epoch 23/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7770\n",
      "Epoch 00023: loss did not improve from -0.79125\n",
      "15/15 [==============================] - 8s 526ms/step - loss: -0.7770 - lr: 0.0100\n",
      "Epoch 24/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7935\n",
      "Epoch 00024: loss improved from -0.79125 to -0.79351, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 791ms/step - loss: -0.7935 - lr: 0.0100\n",
      "Epoch 25/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.7945\n",
      "Epoch 00025: loss improved from -0.79351 to -0.79453, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 820ms/step - loss: -0.7945 - lr: 0.0100\n",
      "Epoch 26/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8061\n",
      "Epoch 00026: loss improved from -0.79453 to -0.80607, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 792ms/step - loss: -0.8061 - lr: 0.0100\n",
      "Epoch 27/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8107\n",
      "Epoch 00027: loss improved from -0.80607 to -0.81072, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 774ms/step - loss: -0.8107 - lr: 0.0100\n",
      "Epoch 28/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8162\n",
      "Epoch 00028: loss improved from -0.81072 to -0.81622, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 776ms/step - loss: -0.8162 - lr: 0.0100\n",
      "Epoch 29/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8185\n",
      "Epoch 00029: loss improved from -0.81622 to -0.81846, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 779ms/step - loss: -0.8185 - lr: 0.0100\n",
      "Epoch 30/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8214\n",
      "Epoch 00030: loss improved from -0.81846 to -0.82140, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 790ms/step - loss: -0.8214 - lr: 0.0100\n",
      "Epoch 31/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8193\n",
      "Epoch 00031: loss did not improve from -0.82140\n",
      "15/15 [==============================] - 8s 542ms/step - loss: -0.8193 - lr: 0.0100\n",
      "Epoch 32/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8204\n",
      "Epoch 00032: loss did not improve from -0.82140\n",
      "15/15 [==============================] - 8s 541ms/step - loss: -0.8204 - lr: 0.0100\n",
      "Epoch 33/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8219\n",
      "Epoch 00033: loss improved from -0.82140 to -0.82188, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 788ms/step - loss: -0.8219 - lr: 0.0100\n",
      "Epoch 34/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8240\n",
      "Epoch 00034: loss improved from -0.82188 to -0.82403, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 789ms/step - loss: -0.8240 - lr: 0.0100\n",
      "Epoch 35/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8251\n",
      "Epoch 00035: loss improved from -0.82403 to -0.82509, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 780ms/step - loss: -0.8251 - lr: 0.0100\n",
      "Epoch 36/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8280\n",
      "Epoch 00036: loss improved from -0.82509 to -0.82798, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 787ms/step - loss: -0.8280 - lr: 0.0100\n",
      "Epoch 37/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8297\n",
      "Epoch 00037: loss improved from -0.82798 to -0.82967, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 782ms/step - loss: -0.8297 - lr: 0.0100\n",
      "Epoch 38/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8316\n",
      "Epoch 00038: loss improved from -0.82967 to -0.83159, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 797ms/step - loss: -0.8316 - lr: 0.0100\n",
      "Epoch 39/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8327\n",
      "Epoch 00039: loss improved from -0.83159 to -0.83273, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 759ms/step - loss: -0.8327 - lr: 0.0100\n",
      "Epoch 40/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8358\n",
      "Epoch 00040: loss improved from -0.83273 to -0.83581, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 781ms/step - loss: -0.8358 - lr: 0.0100\n",
      "Epoch 41/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8336\n",
      "Epoch 00041: loss did not improve from -0.83581\n",
      "15/15 [==============================] - 8s 515ms/step - loss: -0.8336 - lr: 0.0100\n",
      "Epoch 42/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8347\n",
      "Epoch 00042: loss did not improve from -0.83581\n",
      "15/15 [==============================] - 8s 538ms/step - loss: -0.8347 - lr: 0.0100\n",
      "Epoch 43/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8375\n",
      "Epoch 00043: loss improved from -0.83581 to -0.83748, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 797ms/step - loss: -0.8375 - lr: 0.0100\n",
      "Epoch 44/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8382\n",
      "Epoch 00044: loss improved from -0.83748 to -0.83823, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 818ms/step - loss: -0.8382 - lr: 0.0100\n",
      "Epoch 45/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8376\n",
      "Epoch 00045: loss did not improve from -0.83823\n",
      "15/15 [==============================] - 9s 570ms/step - loss: -0.8376 - lr: 0.0100\n",
      "Epoch 46/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8367\n",
      "Epoch 00046: loss did not improve from -0.83823\n",
      "15/15 [==============================] - 8s 535ms/step - loss: -0.8367 - lr: 0.0100\n",
      "Epoch 47/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8373\n",
      "Epoch 00047: loss did not improve from -0.83823\n",
      "15/15 [==============================] - 8s 537ms/step - loss: -0.8373 - lr: 0.0100\n",
      "Epoch 48/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8385\n",
      "Epoch 00048: loss improved from -0.83823 to -0.83846, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 762ms/step - loss: -0.8385 - lr: 0.0100\n",
      "Epoch 49/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8425\n",
      "Epoch 00049: loss improved from -0.83846 to -0.84248, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 818ms/step - loss: -0.8425 - lr: 0.0100\n",
      "Epoch 50/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8430\n",
      "Epoch 00050: loss improved from -0.84248 to -0.84297, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 774ms/step - loss: -0.8430 - lr: 0.0100\n",
      "Epoch 51/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8445\n",
      "Epoch 00051: loss improved from -0.84297 to -0.84451, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 794ms/step - loss: -0.8445 - lr: 0.0100\n",
      "Epoch 52/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8395\n",
      "Epoch 00052: loss did not improve from -0.84451\n",
      "15/15 [==============================] - 9s 597ms/step - loss: -0.8395 - lr: 0.0100\n",
      "Epoch 53/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8426\n",
      "Epoch 00053: loss did not improve from -0.84451\n",
      "15/15 [==============================] - 8s 525ms/step - loss: -0.8426 - lr: 0.0100\n",
      "Epoch 54/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8476\n",
      "Epoch 00054: loss improved from -0.84451 to -0.84760, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 752ms/step - loss: -0.8476 - lr: 0.0100\n",
      "Epoch 55/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8518\n",
      "Epoch 00055: loss improved from -0.84760 to -0.85185, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 833ms/step - loss: -0.8518 - lr: 0.0100\n",
      "Epoch 56/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8502\n",
      "Epoch 00056: loss did not improve from -0.85185\n",
      "15/15 [==============================] - 8s 554ms/step - loss: -0.8502 - lr: 0.0100\n",
      "Epoch 57/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8526\n",
      "Epoch 00057: loss improved from -0.85185 to -0.85261, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 800ms/step - loss: -0.8526 - lr: 0.0100\n",
      "Epoch 58/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8516\n",
      "Epoch 00058: loss did not improve from -0.85261\n",
      "15/15 [==============================] - 8s 544ms/step - loss: -0.8516 - lr: 0.0100\n",
      "Epoch 59/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8517\n",
      "Epoch 00059: loss did not improve from -0.85261\n",
      "15/15 [==============================] - 8s 526ms/step - loss: -0.8517 - lr: 0.0100\n",
      "Epoch 60/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8531\n",
      "Epoch 00060: loss improved from -0.85261 to -0.85307, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 818ms/step - loss: -0.8531 - lr: 0.0100\n",
      "Epoch 61/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8546\n",
      "Epoch 00061: loss improved from -0.85307 to -0.85464, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 776ms/step - loss: -0.8546 - lr: 0.0100\n",
      "Epoch 62/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8540\n",
      "Epoch 00062: loss did not improve from -0.85464\n",
      "15/15 [==============================] - 9s 574ms/step - loss: -0.8540 - lr: 0.0100\n",
      "Epoch 63/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8547 ETA: 1s - loss: -\n",
      "Epoch 00063: loss improved from -0.85464 to -0.85472, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 804ms/step - loss: -0.8547 - lr: 0.0100\n",
      "Epoch 64/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8563\n",
      "Epoch 00064: loss improved from -0.85472 to -0.85627, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 785ms/step - loss: -0.8563 - lr: 0.0100\n",
      "Epoch 65/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8556\n",
      "Epoch 00065: loss did not improve from -0.85627\n",
      "15/15 [==============================] - 8s 545ms/step - loss: -0.8556 - lr: 0.0100\n",
      "Epoch 66/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8547\n",
      "Epoch 00066: loss did not improve from -0.85627\n",
      "15/15 [==============================] - 8s 505ms/step - loss: -0.8547 - lr: 0.0100\n",
      "Epoch 67/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8541\n",
      "Epoch 00067: loss did not improve from -0.85627\n",
      "15/15 [==============================] - 9s 567ms/step - loss: -0.8541 - lr: 0.0100\n",
      "Epoch 68/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8569\n",
      "Epoch 00068: loss improved from -0.85627 to -0.85692, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 815ms/step - loss: -0.8569 - lr: 0.0100\n",
      "Epoch 69/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8579\n",
      "Epoch 00069: loss improved from -0.85692 to -0.85787, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 763ms/step - loss: -0.8579 - lr: 0.0100\n",
      "Epoch 70/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8592\n",
      "Epoch 00070: loss improved from -0.85787 to -0.85921, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 823ms/step - loss: -0.8592 - lr: 0.0100\n",
      "Epoch 71/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8599\n",
      "Epoch 00071: loss improved from -0.85921 to -0.85987, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 808ms/step - loss: -0.8599 - lr: 0.0100\n",
      "Epoch 72/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8566\n",
      "Epoch 00072: loss did not improve from -0.85987\n",
      "15/15 [==============================] - 8s 545ms/step - loss: -0.8566 - lr: 0.0100\n",
      "Epoch 73/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8620\n",
      "Epoch 00073: loss improved from -0.85987 to -0.86196, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 819ms/step - loss: -0.8620 - lr: 0.0100\n",
      "Epoch 74/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8610\n",
      "Epoch 00074: loss did not improve from -0.86196\n",
      "15/15 [==============================] - 8s 546ms/step - loss: -0.8610 - lr: 0.0100\n",
      "Epoch 75/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8619\n",
      "Epoch 00075: loss did not improve from -0.86196\n",
      "15/15 [==============================] - 8s 565ms/step - loss: -0.8619 - lr: 0.0100\n",
      "Epoch 76/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8630\n",
      "Epoch 00076: loss improved from -0.86196 to -0.86297, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 753ms/step - loss: -0.8630 - lr: 0.0100\n",
      "Epoch 77/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8629\n",
      "Epoch 00077: loss did not improve from -0.86297\n",
      "15/15 [==============================] - 8s 548ms/step - loss: -0.8629 - lr: 0.0100\n",
      "Epoch 78/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8639\n",
      "Epoch 00078: loss improved from -0.86297 to -0.86390, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 796ms/step - loss: -0.8639 - lr: 0.0100\n",
      "Epoch 79/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8634\n",
      "Epoch 00079: loss did not improve from -0.86390\n",
      "15/15 [==============================] - 8s 535ms/step - loss: -0.8634 - lr: 0.0100\n",
      "Epoch 80/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8656\n",
      "Epoch 00080: loss improved from -0.86390 to -0.86558, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 792ms/step - loss: -0.8656 - lr: 0.0100\n",
      "Epoch 81/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8593\n",
      "Epoch 00081: loss did not improve from -0.86558\n",
      "15/15 [==============================] - 8s 562ms/step - loss: -0.8593 - lr: 0.0100\n",
      "Epoch 82/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8630\n",
      "Epoch 00082: loss did not improve from -0.86558\n",
      "15/15 [==============================] - 8s 545ms/step - loss: -0.8630 - lr: 0.0100\n",
      "Epoch 83/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8643\n",
      "Epoch 00083: loss did not improve from -0.86558\n",
      "15/15 [==============================] - 8s 532ms/step - loss: -0.8643 - lr: 0.0100\n",
      "Epoch 84/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8643\n",
      "Epoch 00084: loss did not improve from -0.86558\n",
      "15/15 [==============================] - 8s 513ms/step - loss: -0.8643 - lr: 0.0100\n",
      "Epoch 85/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8649\n",
      "Epoch 00085: loss did not improve from -0.86558\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0029999999329447745.\n",
      "15/15 [==============================] - 8s 547ms/step - loss: -0.8649 - lr: 0.0030\n",
      "Epoch 86/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8711\n",
      "Epoch 00086: loss improved from -0.86558 to -0.87113, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 775ms/step - loss: -0.8711 - lr: 0.0030\n",
      "Epoch 87/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8722\n",
      "Epoch 00087: loss improved from -0.87113 to -0.87222, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 811ms/step - loss: -0.8722 - lr: 0.0030\n",
      "Epoch 88/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8738\n",
      "Epoch 00088: loss improved from -0.87222 to -0.87378, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 798ms/step - loss: -0.8738 - lr: 0.0030\n",
      "Epoch 89/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8740\n",
      "Epoch 00089: loss improved from -0.87378 to -0.87404, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 806ms/step - loss: -0.8740 - lr: 0.0030\n",
      "Epoch 90/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8749\n",
      "Epoch 00090: loss improved from -0.87404 to -0.87494, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 797ms/step - loss: -0.8749 - lr: 0.0030\n",
      "Epoch 91/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8753\n",
      "Epoch 00091: loss improved from -0.87494 to -0.87528, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 790ms/step - loss: -0.8753 - lr: 0.0030\n",
      "Epoch 92/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8762\n",
      "Epoch 00092: loss improved from -0.87528 to -0.87616, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 797ms/step - loss: -0.8762 - lr: 0.0030\n",
      "Epoch 93/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8759\n",
      "Epoch 00093: loss did not improve from -0.87616\n",
      "15/15 [==============================] - 8s 546ms/step - loss: -0.8759 - lr: 0.0030\n",
      "Epoch 94/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8762\n",
      "Epoch 00094: loss improved from -0.87616 to -0.87622, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 812ms/step - loss: -0.8762 - lr: 0.0030\n",
      "Epoch 95/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8768\n",
      "Epoch 00095: loss improved from -0.87622 to -0.87678, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 13s 837ms/step - loss: -0.8768 - lr: 0.0030\n",
      "Epoch 96/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8773\n",
      "Epoch 00096: loss improved from -0.87678 to -0.87734, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 794ms/step - loss: -0.8773 - lr: 0.0030\n",
      "Epoch 97/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8771\n",
      "Epoch 00097: loss did not improve from -0.87734\n",
      "15/15 [==============================] - 8s 536ms/step - loss: -0.8771 - lr: 0.0030\n",
      "Epoch 98/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8767\n",
      "Epoch 00098: loss did not improve from -0.87734\n",
      "15/15 [==============================] - 8s 520ms/step - loss: -0.8767 - lr: 0.0030\n",
      "Epoch 99/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8778\n",
      "Epoch 00099: loss improved from -0.87734 to -0.87783, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 770ms/step - loss: -0.8778 - lr: 0.0030\n",
      "Epoch 100/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8779\n",
      "Epoch 00100: loss improved from -0.87783 to -0.87795, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 769ms/step - loss: -0.8779 - lr: 0.0030\n",
      "Epoch 101/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8776\n",
      "Epoch 00101: loss did not improve from -0.87795\n",
      "15/15 [==============================] - 8s 519ms/step - loss: -0.8776 - lr: 0.0030\n",
      "Epoch 102/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8796\n",
      "Epoch 00102: loss improved from -0.87795 to -0.87957, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 10s 694ms/step - loss: -0.8796 - lr: 0.0030\n",
      "Epoch 103/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8786\n",
      "Epoch 00103: loss did not improve from -0.87957\n",
      "15/15 [==============================] - 8s 554ms/step - loss: -0.8786 - lr: 0.0030\n",
      "Epoch 104/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8789\n",
      "Epoch 00104: loss did not improve from -0.87957\n",
      "15/15 [==============================] - 8s 511ms/step - loss: -0.8789 - lr: 0.0030\n",
      "Epoch 105/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8790\n",
      "Epoch 00105: loss did not improve from -0.87957\n",
      "15/15 [==============================] - 8s 508ms/step - loss: -0.8790 - lr: 0.0030\n",
      "Epoch 106/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8791\n",
      "Epoch 00106: loss did not improve from -0.87957\n",
      "15/15 [==============================] - 8s 529ms/step - loss: -0.8791 - lr: 0.0030\n",
      "Epoch 107/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8797\n",
      "Epoch 00107: loss improved from -0.87957 to -0.87974, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 775ms/step - loss: -0.8797 - lr: 0.0030\n",
      "Epoch 108/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8800\n",
      "Epoch 00108: loss improved from -0.87974 to -0.88002, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 824ms/step - loss: -0.8800 - lr: 0.0030\n",
      "Epoch 109/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8791\n",
      "Epoch 00109: loss did not improve from -0.88002\n",
      "15/15 [==============================] - 8s 508ms/step - loss: -0.8791 - lr: 0.0030\n",
      "Epoch 110/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8800\n",
      "Epoch 00110: loss did not improve from -0.88002\n",
      "15/15 [==============================] - 8s 545ms/step - loss: -0.8800 - lr: 0.0030\n",
      "Epoch 111/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8806\n",
      "Epoch 00111: loss improved from -0.88002 to -0.88055, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 764ms/step - loss: -0.8806 - lr: 0.0030\n",
      "Epoch 112/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8803\n",
      "Epoch 00112: loss did not improve from -0.88055\n",
      "15/15 [==============================] - 8s 514ms/step - loss: -0.8803 - lr: 0.0030\n",
      "Epoch 113/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8793\n",
      "Epoch 00113: loss did not improve from -0.88055\n",
      "15/15 [==============================] - 8s 508ms/step - loss: -0.8793 - lr: 0.0030\n",
      "Epoch 114/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8799\n",
      "Epoch 00114: loss did not improve from -0.88055\n",
      "15/15 [==============================] - 8s 522ms/step - loss: -0.8799 - lr: 0.0030\n",
      "Epoch 115/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8814\n",
      "Epoch 00115: loss improved from -0.88055 to -0.88142, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 782ms/step - loss: -0.8814 - lr: 0.0030\n",
      "Epoch 116/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8822\n",
      "Epoch 00116: loss improved from -0.88142 to -0.88224, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 750ms/step - loss: -0.8822 - lr: 0.0030\n",
      "Epoch 117/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8814\n",
      "Epoch 00117: loss did not improve from -0.88224\n",
      "15/15 [==============================] - 8s 531ms/step - loss: -0.8814 - lr: 0.0030\n",
      "Epoch 118/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8815\n",
      "Epoch 00118: loss did not improve from -0.88224\n",
      "15/15 [==============================] - 8s 535ms/step - loss: -0.8815 - lr: 0.0030\n",
      "Epoch 119/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8815\n",
      "Epoch 00119: loss did not improve from -0.88224\n",
      "15/15 [==============================] - 8s 521ms/step - loss: -0.8815 - lr: 0.0030\n",
      "Epoch 120/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8813\n",
      "Epoch 00120: loss did not improve from -0.88224\n",
      "15/15 [==============================] - 8s 525ms/step - loss: -0.8813 - lr: 0.0030\n",
      "Epoch 121/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8819\n",
      "Epoch 00121: loss did not improve from -0.88224\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.0009000000078231095.\n",
      "15/15 [==============================] - 8s 527ms/step - loss: -0.8819 - lr: 9.0000e-04\n",
      "Epoch 122/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8833\n",
      "Epoch 00122: loss improved from -0.88224 to -0.88334, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 780ms/step - loss: -0.8833 - lr: 9.0000e-04\n",
      "Epoch 123/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8844\n",
      "Epoch 00123: loss improved from -0.88334 to -0.88441, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 776ms/step - loss: -0.8844 - lr: 9.0000e-04\n",
      "Epoch 124/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8852\n",
      "Epoch 00124: loss improved from -0.88441 to -0.88521, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 797ms/step - loss: -0.8852 - lr: 9.0000e-04\n",
      "Epoch 125/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8851\n",
      "Epoch 00125: loss did not improve from -0.88521\n",
      "15/15 [==============================] - 8s 530ms/step - loss: -0.8851 - lr: 9.0000e-04\n",
      "Epoch 126/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8849\n",
      "Epoch 00126: loss did not improve from -0.88521\n",
      "15/15 [==============================] - 8s 535ms/step - loss: -0.8849 - lr: 9.0000e-04\n",
      "Epoch 127/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8847\n",
      "Epoch 00127: loss did not improve from -0.88521\n",
      "15/15 [==============================] - 8s 505ms/step - loss: -0.8847 - lr: 9.0000e-04\n",
      "Epoch 128/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8850\n",
      "Epoch 00128: loss did not improve from -0.88521\n",
      "15/15 [==============================] - 8s 504ms/step - loss: -0.8850 - lr: 9.0000e-04\n",
      "Epoch 129/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8852\n",
      "Epoch 00129: loss improved from -0.88521 to -0.88524, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 0.00026999999536201356.\n",
      "15/15 [==============================] - 12s 784ms/step - loss: -0.8852 - lr: 2.7000e-04\n",
      "Epoch 130/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8853\n",
      "Epoch 00130: loss improved from -0.88524 to -0.88527, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 823ms/step - loss: -0.8853 - lr: 2.7000e-04\n",
      "Epoch 131/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8855\n",
      "Epoch 00131: loss improved from -0.88527 to -0.88551, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 827ms/step - loss: -0.8855 - lr: 2.7000e-04\n",
      "Epoch 132/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8860\n",
      "Epoch 00132: loss improved from -0.88551 to -0.88602, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 13s 841ms/step - loss: -0.8860 - lr: 2.7000e-04\n",
      "Epoch 133/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8862\n",
      "Epoch 00133: loss improved from -0.88602 to -0.88616, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 745ms/step - loss: -0.8862 - lr: 2.7000e-04\n",
      "Epoch 134/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8868\n",
      "Epoch 00134: loss improved from -0.88616 to -0.88684, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 809ms/step - loss: -0.8868 - lr: 2.7000e-04\n",
      "Epoch 135/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8867\n",
      "Epoch 00135: loss did not improve from -0.88684\n",
      "15/15 [==============================] - 8s 537ms/step - loss: -0.8867 - lr: 2.7000e-04\n",
      "Epoch 136/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8862\n",
      "Epoch 00136: loss did not improve from -0.88684\n",
      "15/15 [==============================] - 8s 510ms/step - loss: -0.8862 - lr: 2.7000e-04\n",
      "Epoch 137/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8859\n",
      "Epoch 00137: loss did not improve from -0.88684\n",
      "15/15 [==============================] - 8s 542ms/step - loss: -0.8859 - lr: 2.7000e-04\n",
      "Epoch 138/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8864 ETA: 1s - loss: -\n",
      "Epoch 00138: loss did not improve from -0.88684\n",
      "15/15 [==============================] - 8s 544ms/step - loss: -0.8864 - lr: 2.7000e-04\n",
      "Epoch 139/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8864\n",
      "Epoch 00139: loss did not improve from -0.88684\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 8.099999686237424e-05.\n",
      "15/15 [==============================] - 8s 534ms/step - loss: -0.8864 - lr: 8.1000e-05\n",
      "Epoch 140/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8858\n",
      "Epoch 00140: loss did not improve from -0.88684\n",
      "15/15 [==============================] - 8s 527ms/step - loss: -0.8858 - lr: 8.1000e-05\n",
      "Epoch 141/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8867\n",
      "Epoch 00141: loss did not improve from -0.88684\n",
      "15/15 [==============================] - 8s 526ms/step - loss: -0.8867 - lr: 8.1000e-05\n",
      "Epoch 142/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8864\n",
      "Epoch 00142: loss did not improve from -0.88684\n",
      "15/15 [==============================] - 8s 503ms/step - loss: -0.8864 - lr: 8.1000e-05\n",
      "Epoch 143/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8868\n",
      "Epoch 00143: loss did not improve from -0.88684\n",
      "15/15 [==============================] - 8s 526ms/step - loss: -0.8868 - lr: 8.1000e-05\n",
      "Epoch 144/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8868\n",
      "Epoch 00144: loss did not improve from -0.88684\n",
      "15/15 [==============================] - 8s 510ms/step - loss: -0.8868 - lr: 8.1000e-05\n",
      "Epoch 145/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8866\n",
      "Epoch 00145: loss did not improve from -0.88684\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-05.\n",
      "15/15 [==============================] - 8s 515ms/step - loss: -0.8866 - lr: 2.4300e-05\n",
      "Epoch 146/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8865\n",
      "Epoch 00146: loss did not improve from -0.88684\n",
      "15/15 [==============================] - 8s 543ms/step - loss: -0.8865 - lr: 2.4300e-05\n",
      "Epoch 147/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8866\n",
      "Epoch 00147: loss did not improve from -0.88684\n",
      "15/15 [==============================] - 8s 520ms/step - loss: -0.8866 - lr: 2.4300e-05\n",
      "Epoch 148/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8870\n",
      "Epoch 00148: loss improved from -0.88684 to -0.88702, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 12s 772ms/step - loss: -0.8870 - lr: 2.4300e-05\n",
      "Epoch 149/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8861\n",
      "Epoch 00149: loss did not improve from -0.88702\n",
      "15/15 [==============================] - 8s 516ms/step - loss: -0.8861 - lr: 2.4300e-05\n",
      "Epoch 150/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8867\n",
      "Epoch 00150: loss did not improve from -0.88702\n",
      "15/15 [==============================] - 8s 507ms/step - loss: -0.8867 - lr: 2.4300e-05\n",
      "Epoch 151/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8857\n",
      "Epoch 00151: loss did not improve from -0.88702\n",
      "15/15 [==============================] - 8s 522ms/step - loss: -0.8857 - lr: 2.4300e-05\n",
      "Epoch 152/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8865\n",
      "Epoch 00152: loss did not improve from -0.88702\n",
      "15/15 [==============================] - 7s 496ms/step - loss: -0.8865 - lr: 2.4300e-05\n",
      "Epoch 153/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8869\n",
      "Epoch 00153: loss did not improve from -0.88702\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-06.\n",
      "15/15 [==============================] - 8s 543ms/step - loss: -0.8869 - lr: 7.2900e-06\n",
      "Epoch 154/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8874\n",
      "Epoch 00154: loss improved from -0.88702 to -0.88741, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 766ms/step - loss: -0.8874 - lr: 7.2900e-06\n",
      "Epoch 155/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8871\n",
      "Epoch 00155: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 527ms/step - loss: -0.8871 - lr: 7.2900e-06\n",
      "Epoch 156/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8864\n",
      "Epoch 00156: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 541ms/step - loss: -0.8864 - lr: 7.2900e-06\n",
      "Epoch 157/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8869\n",
      "Epoch 00157: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 7s 497ms/step - loss: -0.8869 - lr: 7.2900e-06\n",
      "Epoch 158/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8861\n",
      "Epoch 00158: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 522ms/step - loss: -0.8861 - lr: 7.2900e-06\n",
      "Epoch 159/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8868\n",
      "Epoch 00159: loss did not improve from -0.88741\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 2.186999927289435e-06.\n",
      "15/15 [==============================] - 8s 505ms/step - loss: -0.8868 - lr: 2.1870e-06\n",
      "Epoch 160/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8870\n",
      "Epoch 00160: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 501ms/step - loss: -0.8870 - lr: 2.1870e-06\n",
      "Epoch 161/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8871\n",
      "Epoch 00161: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 508ms/step - loss: -0.8871 - lr: 2.1870e-06\n",
      "Epoch 162/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8873\n",
      "Epoch 00162: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 504ms/step - loss: -0.8873 - lr: 2.1870e-06\n",
      "Epoch 163/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8871\n",
      "Epoch 00163: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 501ms/step - loss: -0.8871 - lr: 2.1870e-06\n",
      "Epoch 164/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8863\n",
      "Epoch 00164: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 7s 490ms/step - loss: -0.8863 - lr: 2.1870e-06\n",
      "Epoch 165/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8870\n",
      "Epoch 00165: loss did not improve from -0.88741\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 6.560999509019894e-07.\n",
      "15/15 [==============================] - 8s 519ms/step - loss: -0.8870 - lr: 6.5610e-07\n",
      "Epoch 166/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8865\n",
      "Epoch 00166: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 508ms/step - loss: -0.8865 - lr: 6.5610e-07\n",
      "Epoch 167/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8862\n",
      "Epoch 00167: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 540ms/step - loss: -0.8862 - lr: 6.5610e-07\n",
      "Epoch 168/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8863\n",
      "Epoch 00168: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 518ms/step - loss: -0.8863 - lr: 6.5610e-07\n",
      "Epoch 169/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8864\n",
      "Epoch 00169: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 525ms/step - loss: -0.8864 - lr: 6.5610e-07\n",
      "Epoch 170/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8869\n",
      "Epoch 00170: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 523ms/step - loss: -0.8869 - lr: 6.5610e-07\n",
      "Epoch 171/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8868\n",
      "Epoch 00171: loss did not improve from -0.88741\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9682997844938655e-07.\n",
      "15/15 [==============================] - 8s 529ms/step - loss: -0.8868 - lr: 1.9683e-07\n",
      "Epoch 172/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8855\n",
      "Epoch 00172: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 512ms/step - loss: -0.8855 - lr: 1.9683e-07\n",
      "Epoch 173/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8863\n",
      "Epoch 00173: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 516ms/step - loss: -0.8863 - lr: 1.9683e-07\n",
      "Epoch 174/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8870\n",
      "Epoch 00174: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 530ms/step - loss: -0.8870 - lr: 1.9683e-07\n",
      "Epoch 175/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8870\n",
      "Epoch 00175: loss did not improve from -0.88741\n",
      "15/15 [==============================] - 8s 546ms/step - loss: -0.8870 - lr: 1.9683e-07\n",
      "Epoch 176/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8876\n",
      "Epoch 00176: loss improved from -0.88741 to -0.88758, saving model to models/3D/ax_sax/st_unet_ax_and_sax/temp/2020-07-03_13_01/checkpoint.h5\n",
      "15/15 [==============================] - 11s 764ms/step - loss: -0.8876 - lr: 1.9683e-07\n",
      "Epoch 177/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8871\n",
      "Epoch 00177: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 566ms/step - loss: -0.8871 - lr: 1.9683e-07\n",
      "Epoch 178/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8866\n",
      "Epoch 00178: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 556ms/step - loss: -0.8866 - lr: 1.9683e-07\n",
      "Epoch 179/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8869\n",
      "Epoch 00179: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 520ms/step - loss: -0.8869 - lr: 1.9683e-07\n",
      "Epoch 180/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8869\n",
      "Epoch 00180: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 512ms/step - loss: -0.8869 - lr: 1.9683e-07\n",
      "Epoch 181/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8866\n",
      "Epoch 00181: loss did not improve from -0.88758\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 5.9048991829513396e-08.\n",
      "15/15 [==============================] - 8s 543ms/step - loss: -0.8866 - lr: 5.9049e-08\n",
      "Epoch 182/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8869\n",
      "Epoch 00182: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 528ms/step - loss: -0.8869 - lr: 5.9049e-08\n",
      "Epoch 183/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8864 ETA: 1s - loss: -\n",
      "Epoch 00183: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 9s 568ms/step - loss: -0.8864 - lr: 5.9049e-08\n",
      "Epoch 184/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8863\n",
      "Epoch 00184: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 546ms/step - loss: -0.8863 - lr: 5.9049e-08\n",
      "Epoch 185/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8865\n",
      "Epoch 00185: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 529ms/step - loss: -0.8865 - lr: 5.9049e-08\n",
      "Epoch 186/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8864\n",
      "Epoch 00186: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 526ms/step - loss: -0.8864 - lr: 5.9049e-08\n",
      "Epoch 187/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8863\n",
      "Epoch 00187: loss did not improve from -0.88758\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 1.771469797517966e-08.\n",
      "15/15 [==============================] - 8s 557ms/step - loss: -0.8863 - lr: 1.7715e-08\n",
      "Epoch 188/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8869\n",
      "Epoch 00188: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 531ms/step - loss: -0.8869 - lr: 1.7715e-08\n",
      "Epoch 189/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8863\n",
      "Epoch 00189: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 527ms/step - loss: -0.8863 - lr: 1.7715e-08\n",
      "Epoch 190/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8873\n",
      "Epoch 00190: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 508ms/step - loss: -0.8873 - lr: 1.7715e-08\n",
      "Epoch 191/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8870\n",
      "Epoch 00191: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 516ms/step - loss: -0.8870 - lr: 1.7715e-08\n",
      "Epoch 192/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8865\n",
      "Epoch 00192: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 536ms/step - loss: -0.8865 - lr: 1.7715e-08\n",
      "Epoch 193/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8863\n",
      "Epoch 00193: loss did not improve from -0.88758\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 5.314409179391077e-09.\n",
      "15/15 [==============================] - 8s 511ms/step - loss: -0.8863 - lr: 5.3144e-09\n",
      "Epoch 194/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8862\n",
      "Epoch 00194: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 519ms/step - loss: -0.8862 - lr: 5.3144e-09\n",
      "Epoch 195/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8870\n",
      "Epoch 00195: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 524ms/step - loss: -0.8870 - lr: 5.3144e-09\n",
      "Epoch 196/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8861\n",
      "Epoch 00196: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 530ms/step - loss: -0.8861 - lr: 5.3144e-09\n",
      "Epoch 197/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8862\n",
      "Epoch 00197: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 510ms/step - loss: -0.8862 - lr: 5.3144e-09\n",
      "Epoch 198/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8866\n",
      "Epoch 00198: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 539ms/step - loss: -0.8866 - lr: 5.3144e-09\n",
      "Epoch 199/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8864\n",
      "Epoch 00199: loss did not improve from -0.88758\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 1.5943228071080283e-09.\n",
      "15/15 [==============================] - 8s 528ms/step - loss: -0.8864 - lr: 1.5943e-09\n",
      "Epoch 200/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8865\n",
      "Epoch 00200: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 529ms/step - loss: -0.8865 - lr: 1.5943e-09\n",
      "Epoch 201/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8861\n",
      "Epoch 00201: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 516ms/step - loss: -0.8861 - lr: 1.5943e-09\n",
      "Epoch 202/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8870\n",
      "Epoch 00202: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 503ms/step - loss: -0.8870 - lr: 1.5943e-09\n",
      "Epoch 203/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8863\n",
      "Epoch 00203: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 514ms/step - loss: -0.8863 - lr: 1.5943e-09\n",
      "Epoch 204/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8861\n",
      "Epoch 00204: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 536ms/step - loss: -0.8861 - lr: 1.5943e-09\n",
      "Epoch 205/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8865\n",
      "Epoch 00205: loss did not improve from -0.88758\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 4.782968354710703e-10.\n",
      "15/15 [==============================] - 8s 516ms/step - loss: -0.8865 - lr: 4.7830e-10\n",
      "Epoch 206/400\n",
      "15/15 [==============================] - ETA: 0s - loss: -0.8863\n",
      "Epoch 00206: loss did not improve from -0.88758\n",
      "15/15 [==============================] - 8s 542ms/step - loss: -0.8863 - lr: 4.7830e-10\n",
      "Epoch 00206: early stopping\n"
     ]
    }
   ],
   "source": [
    "# train one model\n",
    "initial_epoch = 0\n",
    "# training\n",
    "\n",
    "# start a new main process for this training to free gpu memory afterwards\n",
    "logging.info('Fit model, start trainings process')\n",
    "# fit model with trainingsgenerator\n",
    "results = model.fit(\n",
    "    x=batch_generator,\n",
    "    epochs=400,\n",
    "    callbacks = get_callbacks(config),\n",
    "    steps_per_epoch = len(batch_generator),\n",
    "    initial_epoch=initial_epoch,\n",
    "    max_queue_size=6,\n",
    "    workers=8,\n",
    "    #use_multiprocessing=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained AXtoSAX rotation model\n",
    "\n",
    "\"\"\"\n",
    "load past config for model training \n",
    "\"\"\"\n",
    "if tf.distribute.get_strategy():\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "else:\n",
    "    # distribute the training with the mirrored data paradigm across multiple gpus if available, if not use gpu 0\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=config.get('GPUS', [\"/gpu:0\"]))\n",
    "tf.print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "# trained on the full volume, finetuned on firt 20 slices with a margin of 50 (cube mse loss), start looks good, some mistakes are still there\n",
    "config_file  = 'reports/configs/3D/ax_sax/motion_ax_to_sax/isotrop_finetune_topbottom/2020-06-29_18_02/config.json'\n",
    "#config_file = 'reports/configs/2D/acdc/cv/fold3/2020-05-12_22_54/config.json'\n",
    "load = True # change to false, if this pipeline is used without finetuning\n",
    "# load config with all params into global namespace\n",
    "from src.models.Unets import load_pretrained_model\n",
    "if load: # load pretrained model\n",
    "    with open(config_file, encoding='utf-8') as data_file:\n",
    "        config_temp = json.loads(data_file.read())\n",
    "    config_temp['LOSS_FUNCTION'] = config['LOSS_FUNCTION']\n",
    "    logging.info('Load model from Experiment: {}'.format(config_temp['EXPERIMENT']))\n",
    "    #logging.info('config:\\n {}'.format(json.dumps(config, indent=4, sort_keys=True)))\n",
    "\n",
    "    try:\n",
    "        with strategy.scope():\n",
    "            globals()['model'] = load_pretrained_model(config_temp, metrics, comp=False,multigpu=False, transformer=True)\n",
    "            #model.summary()\n",
    "    except Exception as e:\n",
    "        logging.error(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast predictions with all files of the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 09:44:54,339 INFO Create DataGenerator\n",
      "2020-07-06 09:44:54,341 INFO Datagenerator created with: \n",
      " shape: [32, 64, 64]\n",
      " spacing: [5, 5, 5]\n",
      " batchsize: 16\n",
      " Scaler: MinMax\n",
      " Images: 84 \n",
      " Augment_grid: False \n",
      " Thread workers: 16\n",
      "2020-07-06 09:44:54,341 INFO No augmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c0bb401d9f417dba4972baf58620d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=7, description='im', max=15), IntSlider(value=5, description='slice_by',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.my_metrics import front_mse as cube_loss\n",
    "cfg = config.copy()\n",
    "cfg['BATCHSIZE'] = 10\n",
    "valid_generator = SpatialUnetDataGenerator(x_val_ax + x_val_sax, y_val_ax + y_val_sax, config)\n",
    "#valid_generator = MotionDataGenerator(x_train_ax, x_train_sax, cfg)\n",
    "input_, output_ = valid_generator.__getitem__(0)\n",
    "x_ = input_[0]\n",
    "y_ = output_[0]\n",
    "@interact\n",
    "def select_image_in_batch(im = (0,x_.shape[0]- 1, 1), slice_by=(1,10)):\n",
    "    global m\n",
    "    temp = x_[im]\n",
    "    temp_ = y_[im]\n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info('prediction on:')\n",
    "    show_2D_or_3D(temp[::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('predicted by the model')\n",
    "    pred = model.predict(np.expand_dims(temp,axis=0))\n",
    "    show_2D_or_3D(temp[::slice_by],pred[0][::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('target (SAX):')\n",
    "    show_2D_or_3D(temp[::slice_by],temp_[::slice_by])\n",
    "    plt.show()\n",
    "    \"\"\"logging.info('inverted rotation')\n",
    "    show_2D_or_3D(inv[0][::slice_by])\n",
    "    plt.show()\"\"\"\n",
    "    z_margin = 10\n",
    "    inplane_margin = 10\n",
    "    y_true = temp_\n",
    "    y_pred = pred[0]\n",
    "    y_true = y_true[:z_margin, inplane_margin: -inplane_margin, inplane_margin:-inplane_margin,:]\n",
    "    y_pred = y_pred[:z_margin, inplane_margin: -inplane_margin, inplane_margin:-inplane_margin,:]\n",
    "    print('cropped volumes by the loss')\n",
    "    show_2D_or_3D(y_pred)\n",
    "    plt.show()\n",
    "    show_2D_or_3D(y_true)\n",
    "    plt.show()\n",
    "    \n",
    "    print(y_true.shape)\n",
    "    print(y_pred.shape)\n",
    "    print('MSE: {}'.format(mse(temp_, pred[0]).numpy().mean()))\n",
    "    print('MSE center cube: {}'.format(cube_loss(temp_, pred[0]).numpy().mean()))\n",
    "    try:\n",
    "        print(np.reshape(m[0],(3,4)))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on the heldout test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 09:30:45,085 INFO Create DataGenerator\n",
      "2020-07-06 09:30:45,086 INFO Datagenerator created with: \n",
      " shape: [32, 64, 64]\n",
      " spacing: [5, 5, 5]\n",
      " batchsize: 42\n",
      " Scaler: MinMax\n",
      " Images: 42 \n",
      " Augment_grid: False \n",
      " Thread workers: 32\n",
      "2020-07-06 09:30:45,087 INFO No augmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f825e98b26094f2eb63b2db93754f5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='im', max=41), IntSlider(value=6, description='slice_by'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = config.copy()\n",
    "cfg['BATCHSIZE'] = len(x_val_ax)\n",
    "v_generator = MotionDataGenerator(x_val_ax, x_val_sax, cfg)\n",
    "input_, output_ = v_generator.__getitem__(0)\n",
    "x_ = input_[0]\n",
    "y_ = output_[0]\n",
    "@interact\n",
    "def select_image_in_batch(im = (0,x_.shape[0]- 1, 1), slice_by=(1,11)):\n",
    "    global m\n",
    "    temp = x_[im]\n",
    "    temp_ = y_[im]\n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info('prediction on:')\n",
    "    show_2D_or_3D(temp[::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('rotated by the model')\n",
    "    pred = model.predict(np.expand_dims(temp,axis=0))\n",
    "    show_2D_or_3D(pred[0][::slice_by])\n",
    "    plt.show()\n",
    "    logging.info('target (SAX):')\n",
    "    show_2D_or_3D(temp_[::slice_by])\n",
    "    plt.show()\n",
    "    print('MSE: {}'.format(mse(pred[0], temp_).numpy().mean()))\n",
    "    print('MSE center cube: {}'.format(metr.cubic_center_loss_wrapper(pred[0], temp_).numpy().mean()))\n",
    "    try:\n",
    "        print(np.reshape(m[0],(3,4)))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. AX and SAX volumes \n",
    "\n",
    "Create a MotionDatagenerator from the heldout test split without shuffle and batchsize == len(files)\n",
    "\n",
    "## 2. AX images and AX masks\n",
    "\n",
    "Create a Datagenerator from AX image and mask files, both will be used in the next cell for the prediction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a motion generator with the val files without shuffle for sorted predictions\n",
    "from src.models.SpatialTransformer import create_affine_transformer_fixed\n",
    "from src.data.Preprocess import from_channel_to_flat, transform_to_binary_mask\n",
    "from src.data.Postprocess import clean_3d_prediction_3d_cc\n",
    "import shutil\n",
    "from src.data.Dataset import copy_meta_and_save\n",
    "cfg = config.copy()\n",
    "cfg['BATCHSIZE'] = len(x_val_ax)\n",
    "cfg['SHUFFLE'] = False\n",
    "v_generator = MotionDataGenerator(x_val_ax, x_val_sax, cfg)\n",
    "input_, output_ = v_generator.__getitem__(0)\n",
    "x_ = input_[0]\n",
    "y_ = output_[0]\n",
    "msk_cfg = cfg.copy()\n",
    "msk_cfg['IMG_CHANNELS'] = 1\n",
    "v_msk_generator = DataGenerator(x_val_ax, y_val_ax, msk_cfg)\n",
    "__, ax_msk_ = v_msk_generator.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict AXtoSAX rotation, predict SAX Segmentation, rotate the mask reverse (SAXtoAX) by the predicted inverse\n",
    "Complete pipeline:\n",
    "1. AX_isotrop, \n",
    "2. Motion-generator which center crops or resize (needs to be changed) in plane, crop and pad in Z  to align to the network shape, no further resampling\n",
    "3. Rotated into SAX domain by the trained Spatial-Transformer + Encoder (trained on the trainings split)\n",
    "4. Mask prediction with a 3D Wrapper, fed with a pre-trained 2D unet (traind on fold1 from the improved SPIE pipeline)\n",
    "5. Connected Component filtering & binarizing with a threshold of 0.5\n",
    "6. Label-wise transformation of the mask back into the AX domain (with linear interpolation) inverted matrix from 3.\n",
    "7. Second Connected Component Filtering (need to be checked if really necessary)\n",
    "8. Copied the dicom metadata, direction and origin from the original AX_isotrop file to the predicted mask, the input AX image, and the AX GT mask, saved all three files\n",
    "9. Evaluated 3D metrics on the Pred and GT 3D Masks, both files have a spacing of (1.5,1.5,1.5) and a size of 80,224,224 (better would be to use the AX_isotrop mask before the generator, therefore the generator steps need to be inverted, in some very few cases we resize here which is an nearest neighbor interpolation on the GT mask. This step could be changed to padding, but was kept to resize to align with the trainings preprocessing of the unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def select_image_in_batch(im=(0, x_.shape[0] - 1, 1), \n",
    "                          slice_n=(1, 11), \n",
    "                          export_path='data/predicted/temp/',\n",
    "                          shift_z=20,\n",
    "                          debug=False,\n",
    "                         save=False):\n",
    "    \"\"\"\n",
    "    Use the spatial transformer to rotate, predict segmentations, reverse the rotation on the masks and save the nrrd files (image, gt and pred)\n",
    "    :param im: slider to select another image from the generator\n",
    "    :param slice_n: The show_2D_3D method slices to a maximum of 20 slices in z, this parameter allows to further slice the visualisations\n",
    "    :param export_path: path to save the img, gt and prediction volumes as nrrd file, the file names will be the same as in x_ax_val...\n",
    "    :param debug: bool to enable plotting of the intermediate steps\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    global m\n",
    "\n",
    "    full_file_name = y_val_ax[im]\n",
    "    filename = os.path.basename(full_file_name)\n",
    "    logging.info(filename)\n",
    "    temp = x_[im]\n",
    "    temp_ = y_[im]\n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info('Prediction on AX volume:')\n",
    "    if debug: show_2D_or_3D(temp[::slice_n])\n",
    "    plt.show()\n",
    "    \n",
    "    # Predict rotation of AX and get transformation matrix\n",
    "    logging.info('AX --> SAX rotated by the model')\n",
    "    pred, m = model.predict(np.expand_dims(temp, axis=0))\n",
    "    if debug: show_2D_or_3D(pred[0][::slice_n])\n",
    "    plt.show()\n",
    "    \n",
    "    # make copy of m for reusage\n",
    "    m_ = m.copy()\n",
    "    \n",
    "    # Repeat the transformation increase the z translation manually\n",
    "    #z_shift = m_[0][-1]\n",
    "    #m_[0][-1] += shift_z\n",
    "    #logging.info('Repeat the transformation - extend the Z-translation from {} to {}'.format(z_shift, m_[0][-1]))\n",
    "    #logging.getLogger().setLevel(logging.ERROR)\n",
    "    transformer = create_affine_transformer_fixed(config=config, interp_method='linear')\n",
    "    #pred, m = transformer.predict(x=[np.expand_dims(temp, axis=0), m_])\n",
    "    #if debug: show_2D_or_3D(pred[0][::slice_n])\n",
    "    #plt.show()\n",
    "    \n",
    "    # reshape m to matrix\n",
    "    m = np.reshape(m, (3, 4))\n",
    "\n",
    "    # create a square ident matrix slice m into it\n",
    "    m_matrix = np.identity(4)\n",
    "    # slice m (3,4) into identity (4,4)\n",
    "    m_matrix[:3, :] = m\n",
    "    # calc inverse, flatten the matrix and cut off the last row for the spatial transformer\n",
    "    m_matrix_inverse = np.linalg.inv(m_matrix)\n",
    "    m_matrix_inverse_flatten = m_matrix_inverse.flatten()[:-4]\n",
    "\n",
    "    # show the target AXtoSAX volume\n",
    "    logging.info('Target (SAX):')\n",
    "    if debug: show_2D_or_3D(temp_[::slice_n])\n",
    "    plt.show()\n",
    "\n",
    "    # apply the inverse to our AXtoSAX volume\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info('Apply the invers rotation to our AXtoSAX')\n",
    "    logging.getLogger().setLevel(logging.ERROR)\n",
    "    inv, _ = transformer.predict(x=[pred, np.expand_dims(m_matrix_inverse_flatten, axis=0)])\n",
    "    #if debug: show_2D_or_3D(inv[0][::slice_n])\n",
    "    plt.show()\n",
    "\n",
    "    # load a 3D wrapper model for segmenting the new SAX\n",
    "    if 'unet' in globals():\n",
    "        msk = unet.predict(x=pred)\n",
    "        msk = clean_3d_prediction_3d_cc(from_channel_to_flat(msk[0] >= 0.5))\n",
    "        msk = transform_to_binary_mask(msk)\n",
    "        logging.getLogger().setLevel(logging.INFO)\n",
    "        logging.info('Predicted mask')\n",
    "        if debug: show_2D_or_3D(pred[0][::slice_n], msk[::slice_n])\n",
    "        plt.show()\n",
    "\n",
    "        # apply inverse to our msk and plot it together with the inverse AXtoSAX\n",
    "        logging.getLogger().setLevel(logging.ERROR)\n",
    "        m_transformer = create_affine_transformer_fixed(config=config, interp_method='nearest')\n",
    "        inv_msk = list()\n",
    "        for c in range(msk.shape[-1]):\n",
    "            inv_m, _ = m_transformer.predict(\n",
    "                x=[np.expand_dims(msk[..., c], axis=0), np.expand_dims(m_matrix_inverse_flatten, axis=0)])\n",
    "            inv_msk.append(inv_m[..., 0] >= 0.5)\n",
    "        inv_msk = np.stack(inv_msk, axis=-1)\n",
    "        logging.getLogger().setLevel(logging.INFO)\n",
    "        logging.info('Predicted mask rotated to AX on inverse AXtoSAX')\n",
    "        if debug: show_2D_or_3D(inv[0][::slice_n], inv_msk[0][::slice_n])\n",
    "        plt.show()\n",
    "        logging.info('Predicted mask rotated to AX on original AX image')\n",
    "        show_2D_or_3D(temp[::slice_n], inv_msk[0][::slice_n])\n",
    "        plt.show()\n",
    "        \n",
    "        # get the AX target segmentation, processed by the generator to have it in the same shape\n",
    "        msk_gt_raw = ax_msk_[im]\n",
    "        msk_flatten = clean_3d_prediction_3d_cc(from_channel_to_flat(inv_msk[0]))\n",
    "        msk_gt_flatten = from_channel_to_flat(msk_gt_raw)\n",
    "        logging.info('GT on AX')\n",
    "        show_2D_or_3D(temp[::slice_n], msk_gt_flatten[::slice_n])\n",
    "        plt.show()\n",
    "        \n",
    "        # create a nrrd file for the gt, pred and image volume\n",
    "        sitk_pred = sitk.GetImageFromArray(msk_flatten)\n",
    "        sitk_ax_img = sitk.GetImageFromArray(temp)\n",
    "        sitk_ax_msk = sitk.GetImageFromArray(msk_gt_flatten)\n",
    "\n",
    "        ensure_dir(os.path.join(export_path, 'pred'))\n",
    "        ensure_dir(os.path.join(export_path, 'image'))\n",
    "        ensure_dir(os.path.join(export_path, 'gt'))\n",
    "        \n",
    "        # load a reference nrrd file, copy all metadata and save the volumes\n",
    "        reference_sitk = sitk.ReadImage(full_file_name)\n",
    "        if save:\n",
    "            copy_meta_and_save(sitk_pred, reference_sitk, os.path.join(export_path, 'pred', filename))\n",
    "            copy_meta_and_save(sitk_ax_img, reference_sitk,os.path.join(export_path, 'image', filename.replace('msk', 'img')))\n",
    "            copy_meta_and_save(sitk_ax_msk, reference_sitk, os.path.join(export_path, 'gt', filename))\n",
    "        # shutil.copyfile(full_file_name, os.path.join(export_path, 'gt', filename))\n",
    "    else:\n",
    "        logging.info('no unet in global namespace, segmentation is not possible')\n",
    "\n",
    "    logging.info('MSE: {}'.format(mse(pred[0], temp_).numpy().mean()))\n",
    "    logging.info('MSE center cube: {}'.format(metr.cubic_center_loss_wrapper(pred[0], temp_).numpy().mean()))\n",
    "    try:\n",
    "        print(np.reshape(m[0], (3, 4)))\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_z = 10\n",
    "path_ = 'data/predicted/AX_to_SAX_to_AX_finetune_first20z_margin_50/3D/'\n",
    "for i in range(x_.shape[0]):\n",
    "    select_image_in_batch(im=i,slice_n=5, debug=False,shift_z=shift_z, export_path=path_, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the memory usage\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a previous config and by this a pre-trained model\n",
    "from ipyfilechooser import FileChooser\n",
    "config_chooser = FileChooser(os.path.join(os.getcwd(),'reports/configs'), 'config.json')\n",
    "display(config_chooser) # 3D/wrapper/fold1/last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load past config for model training \n",
    "\"\"\"\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(devices=config.get('GPUS', [\"/gpu:0\"]))\n",
    "if strategy:\n",
    "    pass\n",
    "else:\n",
    "    print('creating new strategy')\n",
    "    # distribute the training with the mirrored data paradigm across multiple gpus if available, if not use gpu 0\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=config.get('GPUS', [\"/gpu:0\"]))\n",
    "if config_chooser:\n",
    "    config_file  = config_chooser.selected\n",
    "#config_file = 'reports/configs/2D/acdc/cv/fold3/2020-05-12_22_54/config.json'\n",
    "load = True # change to false, if this pipeline is used without finetuning\n",
    "# load config with all params into global namespace\n",
    "from src.models.Unets import load_pretrained_model\n",
    "if load: # load pretrained model\n",
    "    with open(config_file, encoding='utf-8') as data_file:\n",
    "        config_temp = json.loads(data_file.read())\n",
    "    config_temp['LOSS_FUNCTION'] = config['LOSS_FUNCTION']\n",
    "    logging.info('Load model from Experiment: {}'.format(config_temp['EXPERIMENT']))\n",
    "    #logging.info('config:\\n {}'.format(json.dumps(config, indent=4, sort_keys=True)))\n",
    "    try:\n",
    "        with strategy.scope():\n",
    "            globals()['unet'] = load_pretrained_model(config_temp, metrics, comp=False,multigpu=False)\n",
    "            globals()['unet'].summary()\n",
    "    except Exception as e:\n",
    "        logging.error(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
