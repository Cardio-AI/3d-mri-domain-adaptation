{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/data/git/cardio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2020-07-23 17:19:18,586 INFO -------------------- Start --------------------\n",
      "2020-07-23 17:19:18,587 INFO Working directory: /mnt/data/git/cardio.\n",
      "2020-07-23 17:19:18,587 INFO Log file: ./logs/2D/ax_sax/gcn_and_acdc_exlusive_ax/.log\n",
      "2020-07-23 17:19:18,587 INFO Log level for console: INFO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpu:0', '/gpu:1']\n",
      "{'GPU_IDS': '0,1', 'GPUS': ['/gpu:0', '/gpu:1'], 'EXPERIMENT': '2D/ax_sax/gcn_and_acdc_exlusive_ax/', 'ARCHITECTURE': '2D', 'DATASET': 'GCN', 'TRAIN_PATH': 'data/raw/GCN/2D/train/', 'VAL_PATH': 'data/raw/GCN/2D/val/', 'TEST_PATH': 'data/raw/GCN/2D/val/', 'DF_DATA_PATH': 'data/raw/gcn_05_2020/SAx_3Ddf_kfold.csv', 'DATA_PATH': '/mnt/data/git/cardio/data/raw/gcn_05_2020_sax_excl_ax_patients/2D/', 'FOLD': 0, 'MODEL_PATH': 'models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19', 'TENSORBOARD_LOG_DIR': 'reports/tensorboard_logs/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19', 'CONFIG_PATH': 'reports/configs/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19', 'HISTORY_PATH': 'reports/history/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19', 'DIM': [224, 224], 'DEPTH': 4, 'FILTERS': 48, 'SPACING': [1.5, 1.5], 'M_POOL': [2, 2], 'F_SIZE': [3, 3], 'IMG_CHANNELS': 1, 'MASK_VALUES': [0, 1, 2, 3], 'MASK_CLASSES': 4, 'BORDER_MODE': 0, 'IMG_INTERPOLATION': 1, 'MSK_INTERPOLATION': 0, 'AUGMENT': True, 'SHUFFLE': True, 'AUGMENT_GRID': False, 'RESAMPLE': False, 'SCALER': 'MinMax', 'SEED': 42, 'BATCHSIZE': 32, 'INITIAL_EPOCH': 0, 'EPOCHS': 300, 'EPOCHS_BETWEEN_CHECKPOINTS': 5, 'MONITOR_FUNCTION': 'val_dice_coef_labels', 'MONITOR_MODE': 'max', 'SAVE_MODEL_FUNCTION': 'val_dice_coef_labels', 'SAVE_MODEL_MODE': 'max', 'BN_FIRST': False, 'BATCH_NORMALISATION': True, 'USE_UPSAMPLE': True, 'PAD': 'same', 'KERNEL_INIT': 'he_normal', 'OPTIMIZER': 'adam', 'ACTIVATION': 'elu', 'LEARNING_RATE': 0.001, 'DECAY_FACTOR': 0.3, 'MIN_LR': 1e-10, 'LOSS_FUNCTION': <function bce_dice_loss at 0x7f0a56b41048>}\n"
     ]
    }
   ],
   "source": [
    "# define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.notebook_imports import *\n",
    "from pyforest import *\n",
    "from src.utils.Tensorflow_helper import choose_gpu_by_id\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# define GPU id to use\n",
    "GPU_IDS = '0,1'\n",
    "GPUS = choose_gpu_by_id(GPU_IDS)\n",
    "print(GPUS)\n",
    "\n",
    "# jupyter magic config\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import helpers\n",
    "from src.utils.utils_io import Console_and_file_logger, init_config\n",
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "from src.data.Dataset import get_img_msk_files_from_split_dir, load_acdc_files, get_train_data_from_df, get_trainings_files\n",
    "from src.data.Generators import DataGenerator, get_samples\n",
    "from src.utils.KerasCallbacks import get_callbacks\n",
    "import src.utils.my_metrics as metr\n",
    "import cv2\n",
    "\n",
    "\n",
    "# define experiment name for report, model and log paths + filenames\n",
    "#EXPERIMENT = '2D/tf2/acdc/combined/2D_NOrot90_dfsplit_6_224_11_fold1'\n",
    "EXPERIMENT = '2D/ax_sax/gcn_and_acdc_exlusive_ax/'\n",
    "now = datetime.datetime.now()\n",
    "# image params, change for different input data/architecture\n",
    "ARCHITECTURE = '2D' # 2D\n",
    "# path params\n",
    "DATASET = 'GCN'  # 'acdc' # or 'gcn'\n",
    "TRAIN_PATH = 'data/raw/{}/{}/train/'.format(DATASET, ARCHITECTURE)\n",
    "VAL_PATH = 'data/raw/{}/{}/val/'.format(DATASET, ARCHITECTURE)\n",
    "TEST_PATH = 'data/raw/{}/{}/val/'.format(DATASET, ARCHITECTURE)\n",
    "DF_DATA_PATH = 'data/raw/gcn_05_2020/SAx_3Ddf_kfold.csv'.format(DATASET, ARCHITECTURE)\n",
    "#DF_DATA_PATH = 'data/raw/miccai2020/2d_dataset.csv' # miccai special case\n",
    "DATA_PATH = '/mnt/data/git/cardio/data/raw/gcn_05_2020_sax_excl_ax_patients/2D/'\n",
    "FOLD = 0\n",
    "\n",
    "MODEL_PATH = os.path.join('models', EXPERIMENT, str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "TENSORBOARD_LOG_DIR = os.path.join('reports/tensorboard_logs', EXPERIMENT,str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "CONFIG_PATH = os.path.join('reports/configs/',EXPERIMENT,str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "HISTORY_PATH = os.path.join('reports/history/',EXPERIMENT,str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "\n",
    "DIM = [224, 224] # network input params\n",
    "DEPTH = 4 # number of down-/upsampling blocks\n",
    "FILTERS = 48 # initial number of filters, will be doubled after each downsampling block\n",
    "#SPACING = [8,1.1, 1,1] # used by sitk, order will be reversed to have the same shape as dim\n",
    "SPACING = [1.5, 1.5] # if resample, resample to this spacing\n",
    "M_POOL = [2, 2]# used for downsampling and upsampling\n",
    "F_SIZE = [3, 3] # conv filter size\n",
    "IMG_CHANNELS = 1\n",
    "MASK_VALUES = [0, 1, 2, 3]  #channel order: Background, RV, MYO, LV\n",
    "MASK_CLASSES = len(MASK_VALUES) # no of labels\n",
    "BORDER_MODE = cv2.cv2.BORDER_CONSTANT\n",
    "IMG_INTERPOLATION = cv2.INTER_LINEAR\n",
    "MSK_INTERPOLATION = cv2.INTER_NEAREST\n",
    "AUGMENT = True\n",
    "SHUFFLE = True\n",
    "AUGMENT_GRID = False\n",
    "RESAMPLE = False\n",
    "SCALER = 'MinMax' # MinMax Standard or Robust\n",
    "\n",
    "# training params\n",
    "#GENERATOR_WORKER = 6# if not set, use batchsize\n",
    "SEED = 42 # define a seed for the generator shuffle\n",
    "BATCHSIZE = 32 # 32, 64, 24, 16, 1 for 3D use: 8\n",
    "INITIAL_EPOCH = 0 # change this to continue training\n",
    "EPOCHS = 300 # define a maximum numbers of epochs\n",
    "EPOCHS_BETWEEN_CHECKPOINTS = 5\n",
    "MONITOR_FUNCTION = 'val_dice_coef_labels'\n",
    "MONITOR_MODE = 'max'\n",
    "SAVE_MODEL_FUNCTION = 'val_dice_coef_labels'\n",
    "SAVE_MODEL_MODE = 'max'\n",
    "BN_FIRST = False # decide if BN between Conv and activation or afterwards\n",
    "BATCH_NORMALISATION = True # apply BN or not\n",
    "USE_UPSAMPLE = True # otherwise use transpose\n",
    "PAD = 'same' # padding strategy\n",
    "KERNEL_INIT = 'he_normal' # conv weight initialisation\n",
    "OPTIMIZER = 'adam' # Adam, Adagrad, RMSprop, Adadelta,  # https://keras.io/optimizers/\n",
    "ACTIVATION = 'elu' # tf.keras.layers.LeakyReLU(), relu, any non linear activation function\n",
    "LEARNING_RATE = 0.001 # start with a huge lr to converge fast\n",
    "DECAY_FACTOR = 0.3 # Define a learning rate decay for the ReduceLROnPlateau callback\n",
    "MIN_LR = 1e-10 # smaller lr does not improve the model\n",
    "DROPOUT_min = 0.3 # lower dropout at the shallow layers\n",
    "DROPOUT_max = 0.5 # higher dropout at the deep layers\n",
    "\n",
    "metrics = [\n",
    "    metr.dice_coef_labels,\n",
    "    metr.dice_coef_myo,\n",
    "    metr.dice_coef_lv,\n",
    "    metr.dice_coef_rv\n",
    "]\n",
    "\n",
    "LOSS_FUNCTION = metr.bce_dice_loss\n",
    "#LOSS_FUNCTION = metr.jaccard_distance_loss\n",
    "#LOSS_FUNCTION = metr.bce_dice_jac_loss\n",
    "\n",
    "Console_and_file_logger(EXPERIMENT, logging.INFO)\n",
    "\n",
    "# Define a config for param injection,\n",
    "# save a serialized version, \n",
    "# make sure all paths exist\n",
    "config = init_config(config=locals(), save=True)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training, val and test-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-22 17:33:44,801 INFO found: 193 files\n",
      "2020-07-22 17:33:44,802 INFO found: 193 patients\n"
     ]
    }
   ],
   "source": [
    "from src.data.Dataset import get_kfolded_data\n",
    "df = get_kfolded_data(kfolds=4, path_to_data='data/raw/gcn_05_2020_sax_excl_ax_patients/4D/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/raw/gcn_05_2020_sax_excl_ax_patients/df_4d.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:19:37,690 INFO Found 13330 images/masks in /mnt/data/git/cardio/data/raw/gcn_05_2020_sax_excl_ax_patients/2D/\n",
      "2020-07-23 17:19:37,690 INFO Patients train: 144\n",
      "2020-07-23 17:19:38,095 INFO Selected 9975 of 13330 files with 144 of 193 patients for training fold 0\n",
      "2020-07-23 17:19:38,120 INFO Found 1902 images/masks in data/raw/ACDC/2D/all/\n",
      "2020-07-23 17:19:38,120 INFO Patients train: 1426\n",
      "2020-07-23 17:19:38,269 INFO Selected 1426 of 1902 files with 1426 of 100 patients for training fold 0\n",
      "2020-07-23 17:19:38,270 INFO x_train files: 11401, y_train files: 11401\n",
      "2020-07-23 17:19:38,270 INFO x_val files: 3831, y_val files: 3831\n"
     ]
    }
   ],
   "source": [
    "# used for training a model from scratch\n",
    "info = {}\n",
    "\n",
    "# 2D & 3D file or ACDC format\n",
    "#x_train, y_train = get_img_msk_files_from_split_dir(config['TRAIN_PATH'])\n",
    "#x_val, y_val = get_img_msk_files_from_split_dir(config['VAL_PATH'])\n",
    "#x_test, y_test = get_img_msk_files_from_split_dir(config['TEST_PATH'])\n",
    "\n",
    "# load files from df_folds dataframe\n",
    "#x_train, y_train, x_val, y_val, info = get_train_data_from_df(first_df=config['DF_DATA_PATH'], second_df='reports/kfolds_data/2D/gcn/df_kfold.csv', n_second_df=25, n_first_df=0)\n",
    "#x_train, y_train, x_val, y_val, info = get_train_data_from_df(first_df=config['DF_DATA_PATH'], fold=FOLD)\n",
    "x_train, y_train, x_val, y_val =  get_trainings_files(data_path=DATA_PATH,fold=FOLD,path_to_folds_df='data/raw/gcn_05_2020_sax_excl_ax_patients/df_4d.csv')\n",
    "x_train_, y_train_, x_val_, y_val_ =  get_trainings_files(data_path='data/raw/ACDC/2D/all/',fold=FOLD,path_to_folds_df='data/raw/ACDC/2D/df_kfold.csv')\n",
    "\n",
    "x_train +=x_train_\n",
    "y_train +=y_train_\n",
    "x_val += x_val_ \n",
    "y_val += y_val_\n",
    "# finetune specials\n",
    "#_, _, x_val, y_val, info_ = get_train_data_from_df(firs_df='reports/kfolds_data/2D/gcn/df_kfold.csv')\n",
    "\n",
    "config.update(info)\n",
    "config = init_config(config)\n",
    "\n",
    "logging.info('x_train files: {}, y_train files: {}'.format(len(x_train), len(y_train)))\n",
    "logging.info('x_val files: {}, y_val files: {}'.format(len(x_val), len(y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:20:01,448 INFO Create DataGenerator\n",
      "2020-07-23 17:20:01,495 INFO Datagenerator created with: \n",
      " shape: [224, 224]\n",
      " spacing: [1.5, 1.5]\n",
      " batchsize: 32\n",
      " Scaler: MinMax\n",
      " Images: 11401 \n",
      " Augment_grid: False \n",
      " Thread workers: 32\n",
      "2020-07-23 17:20:01,496 INFO Data will be augmented (shift,scale and rotate) with albumentation\n",
      "2020-07-23 17:20:01,496 INFO Create DataGenerator\n",
      "2020-07-23 17:20:01,512 INFO Datagenerator created with: \n",
      " shape: [224, 224]\n",
      " spacing: [1.5, 1.5]\n",
      " batchsize: 32\n",
      " Scaler: MinMax\n",
      " Images: 3831 \n",
      " Augment_grid: False \n",
      " Thread workers: 32\n",
      "2020-07-23 17:20:01,513 INFO No augmentation\n"
     ]
    }
   ],
   "source": [
    "# create a batch generator\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "batch_generator = DataGenerator(x_train, y_train, config=config)\n",
    "val_config = config.copy()\n",
    "val_config['AUGMENT_GRID'] = False# make sure no augmentation will be applied to the validation data\n",
    "val_config['AUGMENT'] = False\n",
    "validation_generator = DataGenerator(x_val, y_val , config=val_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa959f54a6d74cecacb07263d9712494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=178, description='batch', max=356), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select batch generator output\n",
    "x = ''\n",
    "y = ''\n",
    "@interact\n",
    "def select_batch(batch = (0,len(batch_generator), 1)):\n",
    "    global x, y\n",
    "    x, y = batch_generator.__getitem__(batch)\n",
    "    print(x.shape)\n",
    "    print('selected batch : ' + str(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numpy import save\n",
    "#root_folder = 'data/interim/acdc/2d_numpy/'\n",
    "#for i, (x_2d, y_2d) in enumerate(zip(x,y)):\n",
    "#    f_path = os.path.join(root_folder, '{}'.format(i))\n",
    "#    save('{}{}'.format(f_path, '_x.npy'), x_2d)\n",
    "#    save('{}{}'.format(f_path, '_y.npy'), y_2d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80208de6f1a84f7c9a4d813a6d2d7056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='im', max=31), IntSlider(value=6, description='slice_n',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def select_image_in_batch(im = (0,BATCHSIZE- 1, 1), slice_n=(1,11)):\n",
    "    \n",
    "    # logging level == debug --> visualise the generator steps\n",
    "    print(x.shape, y.shape)\n",
    "    show_2D_or_3D(x[im], y[im])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bc87be2aba4aa4b651454ec56abc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='config_file', options=('reports/configs/2D/acdc/finetune/2019-10-0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def interact_load_pretrained_model(config_file=glob.glob('reports/configs/{}/acdc/finetune/**/*.json'.format(config.get('ARCHITECTURE', '2D')), recursive=False), load=False):\n",
    "    \"\"\"\n",
    "    load past config for model training \n",
    "    \"\"\"\n",
    "    # load config with all params into global namespace\n",
    "    from src.models.ModelUtils import load_pretrained_model\n",
    "    if load:\n",
    "        with open(config_file, encoding='utf-8') as data_file:\n",
    "            config_temp = json.loads(data_file.read())\n",
    "        config_temp['LOSS_FUNCTION'] = config['LOSS_FUNCTION']\n",
    "        logging.info('Load model from Experiment: {}'.format(config_temp['EXPERIMENT']))\n",
    "        #logging.info('config:\\n {}'.format(json.dumps(config, indent=4, sort_keys=True)))\n",
    "    \n",
    "        try:\n",
    "            # load model\n",
    "            globals()['model'] = load_pretrained_model(config_temp, metrics)\n",
    "            model.summary()\n",
    "        except Exception as e:\n",
    "            logging.error(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a009458b2f44e59dff02108b66274a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/mnt/data/git/cardio/reports/configs', filename='config.json', show_hidden='False')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a previous config and by this a pre-trained model\n",
    "from ipyfilechooser import FileChooser\n",
    "config_chooser = FileChooser(os.path.join(os.getcwd(),'reports/configs'), 'config.json')\n",
    "display(config_chooser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:20:20,663 INFO Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "2020-07-23 17:20:20,677 INFO Create model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using tensorflow, need to monkey patch\n",
      "tf.python.backend.slice overwritten by monkey patch\n",
      "(None, 224, 224, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:20:21,037 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2020-07-23 17:20:21,040 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2020-07-23 17:20:21,047 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2020-07-23 17:20:21,050 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2020-07-23 17:20:21,065 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2020-07-23 17:20:21,068 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2020-07-23 17:20:21,105 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2020-07-23 17:20:21,108 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2020-07-23 17:20:21,113 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2020-07-23 17:20:21,116 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 224, 224, 48) 480         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 224, 224, 48) 192         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 224, 224, 48) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 48) 20784       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 48) 192         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 112, 112, 48) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 112, 112, 96) 41568       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 96) 384         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 112, 112, 96) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 112, 112, 96) 83040       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 112, 96) 384         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 96)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 192)  166080      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 192)  768         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 56, 56, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 192)  331968      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 192)  768         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 28, 28, 384)  663936      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 384)  1536        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 28, 28, 384)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 384)  1327488     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 384)  1536        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 384)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 14, 14, 768)  2654976     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 14, 14, 768)  3072        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 768)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 768)  5309184     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 14, 14, 768)  3072        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 28, 28, 768)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 28, 28, 384)  2654592     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28, 28, 768)  0           conv2d_10[0][0]                  \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 384)  2654592     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 28, 28, 384)  1536        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 28, 28, 384)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 384)  1327488     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 384)  1536        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 56, 56, 384)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 56, 56, 192)  663744      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 56, 56, 384)  0           conv2d_13[0][0]                  \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 56, 56, 192)  663744      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 56, 56, 192)  768         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 56, 56, 192)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 56, 56, 192)  331968      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 56, 56, 192)  768         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 112, 112, 192 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 112, 112, 96) 165984      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 112, 112, 192 0           conv2d_16[0][0]                  \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 112, 112, 96) 165984      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 112, 112, 96) 384         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 112, 112, 96) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 112, 112, 96) 83040       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 112, 112, 96) 384         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 96) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 224, 224, 48) 41520       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 224, 224, 96) 0           conv2d_19[0][0]                  \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 224, 224, 48) 41520       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 224, 224, 48) 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 224, 224, 48) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 224, 224, 48) 20784       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 224, 224, 48) 192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "unet (Conv2D)                   (None, 224, 224, 4)  196         batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 19,432,324\n",
      "Trainable params: 19,423,492\n",
      "Non-trainable params: 8,832\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cell for automation of the model loading process\n",
    "# load one basemodel for the finetuning task\n",
    "\"\"\"\n",
    "load past config for model training \n",
    "\"\"\"\n",
    "if 'streategy' in locals():\n",
    "    pass\n",
    "else:\n",
    "    # distribute the training with the mirrored data paradigm across multiple gpus if available, if not use gpu 0\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=config.get('GPUS', [\"/gpu:0\"]))\n",
    "if 'config_chooser' in locals():\n",
    "    config_file  = config_chooser.selected\n",
    "load = False # change to false, if this pipeline is used without finetuning\n",
    "# load config with all params into global namespace\n",
    "from src.models.ModelUtils import load_pretrained_model\n",
    "if load: # load pretrained model\n",
    "    with open(config_file, encoding='utf-8') as data_file:\n",
    "        config_temp = json.loads(data_file.read())\n",
    "    config_temp['LOSS_FUNCTION'] = config['LOSS_FUNCTION']\n",
    "    logging.info('Load model from Experiment: {}'.format(config_temp['EXPERIMENT']))\n",
    "    try:\n",
    "        with strategy.scope():\n",
    "            globals()['model'] = load_pretrained_model(config_temp, metrics, comp=False,multigpu=False)\n",
    "            model.summary()\n",
    "    except Exception as e:\n",
    "        logging.error(str(e))\n",
    "        \n",
    "else:\n",
    "    pass\n",
    "# distribute the training with the mirrored data paradigm across multiple gpus if available, if not use gpu 0\n",
    "#from src.models.ModelManager_2d3d import get_model, create_comb_shared_unet, create_unet, create_3d_wrapper\n",
    "#from src.models.ModelManager_2d3d import get_model, create_unet\n",
    "import src.models.Unets as modelmanager\n",
    "with strategy.scope():\n",
    "    # create new model\n",
    "    logging.info('Create model')\n",
    "    #model = modelmanager.create_2d_3d_avg_model(config, metrics, supervision=False)\n",
    "    model = modelmanager.create_unet(config, metrics, supervision=False)\n",
    "    #model = modelmanager.create_stacked_unet(config, metrics, supervision=False, unet_2d=model)\n",
    "    #model = modelmanager.create_stacked_unet_concat_input(config, metrics, supervision=False, unet_2d=model)\n",
    "    #model = create_comb_shared_unet(config, metrics)\n",
    "    #model = modelmanager.create_3d_wrapper_for_2d_unet(config=config, metrics=metrics, unet_2d=model)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-22 17:34:57,860 WARNING From /home/sven/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:110: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-07-22 17:34:57,875 WARNING From /home/sven/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:110: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-07-22 17:35:01,769 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-22_17_33/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:20:39,442 INFO Fit model, start trainings process\n",
      "2020-07-23 17:20:39,816 WARNING From /home/sven/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:20:41,668 INFO batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n",
      "2020-07-23 17:20:44,452 INFO batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/356 [..............................] - ETA: 0s - loss: 0.1805 - dice_coef_labels: 0.0142 - dice_coef_myo: 0.0203 - dice_coef_lv: 0.0289 - dice_coef_rv: 0.0095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:20:51,978 WARNING From /home/sven/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - ETA: 0s - loss: -0.5314 - dice_coef_labels: 0.5403 - dice_coef_myo: 0.4735 - dice_coef_lv: 0.6281 - dice_coef_rv: 0.5761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:22:35,820 INFO Saved model to disk: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_dice_coef_labels improved from -inf to 0.61712, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:22:38,762 WARNING From /home/sven/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:110: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-07-23 17:22:38,777 WARNING From /home/sven/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:110: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-07-23 17:22:43,256 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_dice_coef_labels improved from -inf to 0.61712, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 112s 314ms/step - loss: -0.5314 - dice_coef_labels: 0.5403 - dice_coef_myo: 0.4735 - dice_coef_lv: 0.6281 - dice_coef_rv: 0.5761 - val_loss: -0.6137 - val_dice_coef_labels: 0.6171 - val_dice_coef_myo: 0.5240 - val_dice_coef_lv: 0.7265 - val_dice_coef_rv: 0.6612 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.7656 - dice_coef_labels: 0.7521 - dice_coef_myo: 0.6965 - dice_coef_lv: 0.8617 - dice_coef_rv: 0.7798\n",
      "Epoch 00002: val_dice_coef_labels improved from 0.61712 to 0.74739, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:24:36,955 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_dice_coef_labels improved from 0.61712 to 0.74739, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 113s 318ms/step - loss: -0.7656 - dice_coef_labels: 0.7521 - dice_coef_myo: 0.6965 - dice_coef_lv: 0.8617 - dice_coef_rv: 0.7798 - val_loss: -0.7506 - val_dice_coef_labels: 0.7474 - val_dice_coef_myo: 0.7103 - val_dice_coef_lv: 0.8418 - val_dice_coef_rv: 0.7648 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8027 - dice_coef_labels: 0.7894 - dice_coef_myo: 0.7369 - dice_coef_lv: 0.8869 - dice_coef_rv: 0.8150\n",
      "Epoch 00003: val_dice_coef_labels improved from 0.74739 to 0.78073, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:26:35,763 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_dice_coef_labels improved from 0.74739 to 0.78073, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 332ms/step - loss: -0.8027 - dice_coef_labels: 0.7894 - dice_coef_myo: 0.7369 - dice_coef_lv: 0.8869 - dice_coef_rv: 0.8150 - val_loss: -0.7823 - val_dice_coef_labels: 0.7807 - val_dice_coef_myo: 0.7357 - val_dice_coef_lv: 0.8584 - val_dice_coef_rv: 0.8030 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8230 - dice_coef_labels: 0.8110 - dice_coef_myo: 0.7567 - dice_coef_lv: 0.8988 - dice_coef_rv: 0.8375\n",
      "Epoch 00004: val_dice_coef_labels improved from 0.78073 to 0.80829, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:28:37,185 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_dice_coef_labels improved from 0.78073 to 0.80829, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 121s 340ms/step - loss: -0.8230 - dice_coef_labels: 0.8110 - dice_coef_myo: 0.7567 - dice_coef_lv: 0.8988 - dice_coef_rv: 0.8375 - val_loss: -0.8104 - val_dice_coef_labels: 0.8083 - val_dice_coef_myo: 0.7647 - val_dice_coef_lv: 0.8792 - val_dice_coef_rv: 0.8288 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8330 - dice_coef_labels: 0.8215 - dice_coef_myo: 0.7658 - dice_coef_lv: 0.9034 - dice_coef_rv: 0.8490\n",
      "Epoch 00005: val_dice_coef_labels improved from 0.80829 to 0.81037, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:30:38,226 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_dice_coef_labels improved from 0.80829 to 0.81037, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 121s 339ms/step - loss: -0.8330 - dice_coef_labels: 0.8215 - dice_coef_myo: 0.7658 - dice_coef_lv: 0.9034 - dice_coef_rv: 0.8490 - val_loss: -0.8161 - val_dice_coef_labels: 0.8104 - val_dice_coef_myo: 0.7497 - val_dice_coef_lv: 0.8862 - val_dice_coef_rv: 0.8384 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8487 - dice_coef_labels: 0.8371 - dice_coef_myo: 0.7790 - dice_coef_lv: 0.9145 - dice_coef_rv: 0.8655\n",
      "Epoch 00006: val_dice_coef_labels improved from 0.81037 to 0.83712, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:32:37,079 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_dice_coef_labels improved from 0.81037 to 0.83712, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 332ms/step - loss: -0.8487 - dice_coef_labels: 0.8371 - dice_coef_myo: 0.7790 - dice_coef_lv: 0.9145 - dice_coef_rv: 0.8655 - val_loss: -0.8466 - val_dice_coef_labels: 0.8371 - val_dice_coef_myo: 0.7901 - val_dice_coef_lv: 0.9165 - val_dice_coef_rv: 0.8588 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8483 - dice_coef_labels: 0.8372 - dice_coef_myo: 0.7803 - dice_coef_lv: 0.9132 - dice_coef_rv: 0.8650\n",
      "Epoch 00007: val_dice_coef_labels did not improve from 0.83712\n",
      "\n",
      "Epoch 00007: val_dice_coef_labels did not improve from 0.83712\n",
      "356/356 [==============================] - 112s 315ms/step - loss: -0.8483 - dice_coef_labels: 0.8372 - dice_coef_myo: 0.7803 - dice_coef_lv: 0.9132 - dice_coef_rv: 0.8650 - val_loss: -0.8391 - val_dice_coef_labels: 0.8327 - val_dice_coef_myo: 0.7928 - val_dice_coef_lv: 0.9024 - val_dice_coef_rv: 0.8518 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8543 - dice_coef_labels: 0.8438 - dice_coef_myo: 0.7871 - dice_coef_lv: 0.9158 - dice_coef_rv: 0.8715\n",
      "Epoch 00008: val_dice_coef_labels improved from 0.83712 to 0.84229, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:36:32,660 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_dice_coef_labels improved from 0.83712 to 0.84229, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 123s 344ms/step - loss: -0.8543 - dice_coef_labels: 0.8438 - dice_coef_myo: 0.7871 - dice_coef_lv: 0.9158 - dice_coef_rv: 0.8715 - val_loss: -0.8509 - val_dice_coef_labels: 0.8423 - val_dice_coef_myo: 0.7867 - val_dice_coef_lv: 0.9149 - val_dice_coef_rv: 0.8672 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8581 - dice_coef_labels: 0.8481 - dice_coef_myo: 0.7892 - dice_coef_lv: 0.9170 - dice_coef_rv: 0.8773\n",
      "Epoch 00009: val_dice_coef_labels did not improve from 0.84229\n",
      "\n",
      "Epoch 00009: val_dice_coef_labels did not improve from 0.84229\n",
      "356/356 [==============================] - 112s 315ms/step - loss: -0.8581 - dice_coef_labels: 0.8481 - dice_coef_myo: 0.7892 - dice_coef_lv: 0.9170 - dice_coef_rv: 0.8773 - val_loss: -0.8442 - val_dice_coef_labels: 0.8402 - val_dice_coef_myo: 0.7924 - val_dice_coef_lv: 0.9032 - val_dice_coef_rv: 0.8631 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8626 - dice_coef_labels: 0.8522 - dice_coef_myo: 0.7942 - dice_coef_lv: 0.9205 - dice_coef_rv: 0.8809\n",
      "Epoch 00010: val_dice_coef_labels improved from 0.84229 to 0.85711, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:40:27,535 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_dice_coef_labels improved from 0.84229 to 0.85711, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 122s 343ms/step - loss: -0.8626 - dice_coef_labels: 0.8522 - dice_coef_myo: 0.7942 - dice_coef_lv: 0.9205 - dice_coef_rv: 0.8809 - val_loss: -0.8641 - val_dice_coef_labels: 0.8571 - val_dice_coef_myo: 0.8089 - val_dice_coef_lv: 0.9219 - val_dice_coef_rv: 0.8803 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8657 - dice_coef_labels: 0.8548 - dice_coef_myo: 0.7963 - dice_coef_lv: 0.9237 - dice_coef_rv: 0.8838\n",
      "Epoch 00011: val_dice_coef_labels did not improve from 0.85711\n",
      "\n",
      "Epoch 00011: val_dice_coef_labels did not improve from 0.85711\n",
      "356/356 [==============================] - 110s 308ms/step - loss: -0.8657 - dice_coef_labels: 0.8548 - dice_coef_myo: 0.7963 - dice_coef_lv: 0.9237 - dice_coef_rv: 0.8838 - val_loss: -0.8144 - val_dice_coef_labels: 0.8132 - val_dice_coef_myo: 0.7733 - val_dice_coef_lv: 0.8831 - val_dice_coef_rv: 0.8331 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8674 - dice_coef_labels: 0.8565 - dice_coef_myo: 0.7993 - dice_coef_lv: 0.9251 - dice_coef_rv: 0.8846\n",
      "Epoch 00012: val_dice_coef_labels did not improve from 0.85711\n",
      "\n",
      "Epoch 00012: val_dice_coef_labels did not improve from 0.85711\n",
      "356/356 [==============================] - 111s 310ms/step - loss: -0.8674 - dice_coef_labels: 0.8565 - dice_coef_myo: 0.7993 - dice_coef_lv: 0.9251 - dice_coef_rv: 0.8846 - val_loss: -0.8239 - val_dice_coef_labels: 0.8275 - val_dice_coef_myo: 0.7550 - val_dice_coef_lv: 0.8741 - val_dice_coef_rv: 0.8591 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8696 - dice_coef_labels: 0.8591 - dice_coef_myo: 0.8021 - dice_coef_lv: 0.9260 - dice_coef_rv: 0.8872\n",
      "Epoch 00013: val_dice_coef_labels improved from 0.85711 to 0.86441, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:46:06,851 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_dice_coef_labels improved from 0.85711 to 0.86441, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 331ms/step - loss: -0.8696 - dice_coef_labels: 0.8591 - dice_coef_myo: 0.8021 - dice_coef_lv: 0.9260 - dice_coef_rv: 0.8872 - val_loss: -0.8708 - val_dice_coef_labels: 0.8644 - val_dice_coef_myo: 0.8193 - val_dice_coef_lv: 0.9245 - val_dice_coef_rv: 0.8869 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8720 - dice_coef_labels: 0.8614 - dice_coef_myo: 0.8026 - dice_coef_lv: 0.9277 - dice_coef_rv: 0.8904\n",
      "Epoch 00014: val_dice_coef_labels did not improve from 0.86441\n",
      "\n",
      "Epoch 00014: val_dice_coef_labels did not improve from 0.86441\n",
      "356/356 [==============================] - 110s 308ms/step - loss: -0.8720 - dice_coef_labels: 0.8614 - dice_coef_myo: 0.8026 - dice_coef_lv: 0.9277 - dice_coef_rv: 0.8904 - val_loss: -0.8561 - val_dice_coef_labels: 0.8517 - val_dice_coef_myo: 0.8053 - val_dice_coef_lv: 0.9112 - val_dice_coef_rv: 0.8745 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8744 - dice_coef_labels: 0.8640 - dice_coef_myo: 0.8074 - dice_coef_lv: 0.9290 - dice_coef_rv: 0.8917\n",
      "Epoch 00015: val_dice_coef_labels did not improve from 0.86441\n",
      "\n",
      "Epoch 00015: val_dice_coef_labels did not improve from 0.86441\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8744 - dice_coef_labels: 0.8640 - dice_coef_myo: 0.8074 - dice_coef_lv: 0.9290 - dice_coef_rv: 0.8917 - val_loss: -0.8675 - val_dice_coef_labels: 0.8574 - val_dice_coef_myo: 0.8163 - val_dice_coef_lv: 0.9292 - val_dice_coef_rv: 0.8778 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8713 - dice_coef_labels: 0.8609 - dice_coef_myo: 0.8026 - dice_coef_lv: 0.9266 - dice_coef_rv: 0.8898\n",
      "Epoch 00016: val_dice_coef_labels did not improve from 0.86441\n",
      "\n",
      "Epoch 00016: val_dice_coef_labels did not improve from 0.86441\n",
      "356/356 [==============================] - 110s 310ms/step - loss: -0.8713 - dice_coef_labels: 0.8609 - dice_coef_myo: 0.8026 - dice_coef_lv: 0.9266 - dice_coef_rv: 0.8898 - val_loss: -0.8632 - val_dice_coef_labels: 0.8568 - val_dice_coef_myo: 0.8113 - val_dice_coef_lv: 0.9188 - val_dice_coef_rv: 0.8793 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8724 - dice_coef_labels: 0.8621 - dice_coef_myo: 0.8049 - dice_coef_lv: 0.9268 - dice_coef_rv: 0.8903\n",
      "Epoch 00017: val_dice_coef_labels did not improve from 0.86441\n",
      "\n",
      "Epoch 00017: val_dice_coef_labels did not improve from 0.86441\n",
      "356/356 [==============================] - 110s 310ms/step - loss: -0.8724 - dice_coef_labels: 0.8621 - dice_coef_myo: 0.8049 - dice_coef_lv: 0.9268 - dice_coef_rv: 0.8903 - val_loss: -0.8547 - val_dice_coef_labels: 0.8509 - val_dice_coef_myo: 0.8059 - val_dice_coef_lv: 0.9087 - val_dice_coef_rv: 0.8730 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8760 - dice_coef_labels: 0.8658 - dice_coef_myo: 0.8075 - dice_coef_lv: 0.9293 - dice_coef_rv: 0.8943\n",
      "Epoch 00018: val_dice_coef_labels did not improve from 0.86441\n",
      "\n",
      "Epoch 00018: val_dice_coef_labels did not improve from 0.86441\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "356/356 [==============================] - 110s 310ms/step - loss: -0.8760 - dice_coef_labels: 0.8658 - dice_coef_myo: 0.8075 - dice_coef_lv: 0.9293 - dice_coef_rv: 0.8943 - val_loss: -0.8680 - val_dice_coef_labels: 0.8596 - val_dice_coef_myo: 0.8203 - val_dice_coef_lv: 0.9278 - val_dice_coef_rv: 0.8786 - lr: 3.0000e-04\n",
      "Epoch 19/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8834 - dice_coef_labels: 0.8734 - dice_coef_myo: 0.8163 - dice_coef_lv: 0.9339 - dice_coef_rv: 0.9013\n",
      "Epoch 00019: val_dice_coef_labels improved from 0.86441 to 0.87342, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:57:19,031 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: val_dice_coef_labels improved from 0.86441 to 0.87342, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 331ms/step - loss: -0.8834 - dice_coef_labels: 0.8734 - dice_coef_myo: 0.8163 - dice_coef_lv: 0.9339 - dice_coef_rv: 0.9013 - val_loss: -0.8810 - val_dice_coef_labels: 0.8734 - val_dice_coef_myo: 0.8289 - val_dice_coef_lv: 0.9325 - val_dice_coef_rv: 0.8947 - lr: 3.0000e-04\n",
      "Epoch 20/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8862 - dice_coef_labels: 0.8763 - dice_coef_myo: 0.8188 - dice_coef_lv: 0.9356 - dice_coef_rv: 0.9045\n",
      "Epoch 00020: val_dice_coef_labels improved from 0.87342 to 0.87376, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 17:59:17,086 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: val_dice_coef_labels improved from 0.87342 to 0.87376, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 330ms/step - loss: -0.8862 - dice_coef_labels: 0.8763 - dice_coef_myo: 0.8188 - dice_coef_lv: 0.9356 - dice_coef_rv: 0.9045 - val_loss: -0.8813 - val_dice_coef_labels: 0.8738 - val_dice_coef_myo: 0.8266 - val_dice_coef_lv: 0.9330 - val_dice_coef_rv: 0.8962 - lr: 3.0000e-04\n",
      "Epoch 21/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8870 - dice_coef_labels: 0.8765 - dice_coef_myo: 0.8200 - dice_coef_lv: 0.9375 - dice_coef_rv: 0.9042\n",
      "Epoch 00021: val_dice_coef_labels did not improve from 0.87376\n",
      "\n",
      "Epoch 00021: val_dice_coef_labels did not improve from 0.87376\n",
      "356/356 [==============================] - 110s 308ms/step - loss: -0.8870 - dice_coef_labels: 0.8765 - dice_coef_myo: 0.8200 - dice_coef_lv: 0.9375 - dice_coef_rv: 0.9042 - val_loss: -0.8732 - val_dice_coef_labels: 0.8725 - val_dice_coef_myo: 0.8266 - val_dice_coef_lv: 0.9100 - val_dice_coef_rv: 0.8942 - lr: 3.0000e-04\n",
      "Epoch 22/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8887 - dice_coef_labels: 0.8789 - dice_coef_myo: 0.8218 - dice_coef_lv: 0.9374 - dice_coef_rv: 0.9069\n",
      "Epoch 00022: val_dice_coef_labels improved from 0.87376 to 0.87618, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 18:03:06,483 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: val_dice_coef_labels improved from 0.87376 to 0.87618, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 119s 333ms/step - loss: -0.8887 - dice_coef_labels: 0.8789 - dice_coef_myo: 0.8218 - dice_coef_lv: 0.9374 - dice_coef_rv: 0.9069 - val_loss: -0.8829 - val_dice_coef_labels: 0.8762 - val_dice_coef_myo: 0.8259 - val_dice_coef_lv: 0.9328 - val_dice_coef_rv: 0.8998 - lr: 3.0000e-04\n",
      "Epoch 23/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8891 - dice_coef_labels: 0.8794 - dice_coef_myo: 0.8225 - dice_coef_lv: 0.9372 - dice_coef_rv: 0.9073\n",
      "Epoch 00023: val_dice_coef_labels did not improve from 0.87618\n",
      "\n",
      "Epoch 00023: val_dice_coef_labels did not improve from 0.87618\n",
      "356/356 [==============================] - 110s 308ms/step - loss: -0.8891 - dice_coef_labels: 0.8794 - dice_coef_myo: 0.8225 - dice_coef_lv: 0.9372 - dice_coef_rv: 0.9073 - val_loss: -0.8770 - val_dice_coef_labels: 0.8745 - val_dice_coef_myo: 0.8224 - val_dice_coef_lv: 0.9192 - val_dice_coef_rv: 0.8993 - lr: 3.0000e-04\n",
      "Epoch 24/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8905 - dice_coef_labels: 0.8808 - dice_coef_myo: 0.8223 - dice_coef_lv: 0.9381 - dice_coef_rv: 0.9097\n",
      "Epoch 00024: val_dice_coef_labels did not improve from 0.87618\n",
      "\n",
      "Epoch 00024: val_dice_coef_labels did not improve from 0.87618\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8905 - dice_coef_labels: 0.8808 - dice_coef_myo: 0.8223 - dice_coef_lv: 0.9381 - dice_coef_rv: 0.9097 - val_loss: -0.8829 - val_dice_coef_labels: 0.8759 - val_dice_coef_myo: 0.8276 - val_dice_coef_lv: 0.9322 - val_dice_coef_rv: 0.8989 - lr: 3.0000e-04\n",
      "Epoch 25/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8909 - dice_coef_labels: 0.8809 - dice_coef_myo: 0.8236 - dice_coef_lv: 0.9391 - dice_coef_rv: 0.9091\n",
      "Epoch 00025: val_dice_coef_labels did not improve from 0.87618\n",
      "\n",
      "Epoch 00025: val_dice_coef_labels did not improve from 0.87618\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8909 - dice_coef_labels: 0.8809 - dice_coef_myo: 0.8236 - dice_coef_lv: 0.9391 - dice_coef_rv: 0.9091 - val_loss: -0.8823 - val_dice_coef_labels: 0.8758 - val_dice_coef_myo: 0.8255 - val_dice_coef_lv: 0.9320 - val_dice_coef_rv: 0.8991 - lr: 3.0000e-04\n",
      "Epoch 26/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8908 - dice_coef_labels: 0.8812 - dice_coef_myo: 0.8232 - dice_coef_lv: 0.9380 - dice_coef_rv: 0.9097\n",
      "Epoch 00026: val_dice_coef_labels improved from 0.87618 to 0.88038, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 18:10:37,309 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: val_dice_coef_labels improved from 0.87618 to 0.88038, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 331ms/step - loss: -0.8908 - dice_coef_labels: 0.8812 - dice_coef_myo: 0.8232 - dice_coef_lv: 0.9380 - dice_coef_rv: 0.9097 - val_loss: -0.8769 - val_dice_coef_labels: 0.8804 - val_dice_coef_myo: 0.8348 - val_dice_coef_lv: 0.9019 - val_dice_coef_rv: 0.9029 - lr: 3.0000e-04\n",
      "Epoch 27/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8921 - dice_coef_labels: 0.8823 - dice_coef_myo: 0.8251 - dice_coef_lv: 0.9398 - dice_coef_rv: 0.9105\n",
      "Epoch 00027: val_dice_coef_labels did not improve from 0.88038\n",
      "\n",
      "Epoch 00027: val_dice_coef_labels did not improve from 0.88038\n",
      "356/356 [==============================] - 110s 308ms/step - loss: -0.8921 - dice_coef_labels: 0.8823 - dice_coef_myo: 0.8251 - dice_coef_lv: 0.9398 - dice_coef_rv: 0.9105 - val_loss: -0.8841 - val_dice_coef_labels: 0.8786 - val_dice_coef_myo: 0.8303 - val_dice_coef_lv: 0.9313 - val_dice_coef_rv: 0.9019 - lr: 3.0000e-04\n",
      "Epoch 28/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8917 - dice_coef_labels: 0.8822 - dice_coef_myo: 0.8260 - dice_coef_lv: 0.9388 - dice_coef_rv: 0.9098\n",
      "Epoch 00028: val_dice_coef_labels did not improve from 0.88038\n",
      "\n",
      "Epoch 00028: val_dice_coef_labels did not improve from 0.88038\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8917 - dice_coef_labels: 0.8822 - dice_coef_myo: 0.8260 - dice_coef_lv: 0.9388 - dice_coef_rv: 0.9098 - val_loss: -0.8865 - val_dice_coef_labels: 0.8790 - val_dice_coef_myo: 0.8332 - val_dice_coef_lv: 0.9364 - val_dice_coef_rv: 0.9011 - lr: 3.0000e-04\n",
      "Epoch 29/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8925 - dice_coef_labels: 0.8828 - dice_coef_myo: 0.8260 - dice_coef_lv: 0.9398 - dice_coef_rv: 0.9107\n",
      "Epoch 00029: val_dice_coef_labels did not improve from 0.88038\n",
      "\n",
      "Epoch 00029: val_dice_coef_labels did not improve from 0.88038\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8925 - dice_coef_labels: 0.8828 - dice_coef_myo: 0.8260 - dice_coef_lv: 0.9398 - dice_coef_rv: 0.9107 - val_loss: -0.8849 - val_dice_coef_labels: 0.8770 - val_dice_coef_myo: 0.8291 - val_dice_coef_lv: 0.9349 - val_dice_coef_rv: 0.9002 - lr: 3.0000e-04\n",
      "Epoch 30/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8931 - dice_coef_labels: 0.8837 - dice_coef_myo: 0.8260 - dice_coef_lv: 0.9393 - dice_coef_rv: 0.9122\n",
      "Epoch 00030: val_dice_coef_labels did not improve from 0.88038\n",
      "\n",
      "Epoch 00030: val_dice_coef_labels did not improve from 0.88038\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8931 - dice_coef_labels: 0.8837 - dice_coef_myo: 0.8260 - dice_coef_lv: 0.9393 - dice_coef_rv: 0.9122 - val_loss: -0.8883 - val_dice_coef_labels: 0.8803 - val_dice_coef_myo: 0.8324 - val_dice_coef_lv: 0.9388 - val_dice_coef_rv: 0.9032 - lr: 3.0000e-04\n",
      "Epoch 31/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8936 - dice_coef_labels: 0.8839 - dice_coef_myo: 0.8268 - dice_coef_lv: 0.9405 - dice_coef_rv: 0.9119\n",
      "Epoch 00031: val_dice_coef_labels did not improve from 0.88038\n",
      "\n",
      "Epoch 00031: val_dice_coef_labels did not improve from 0.88038\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "356/356 [==============================] - 110s 310ms/step - loss: -0.8936 - dice_coef_labels: 0.8839 - dice_coef_myo: 0.8268 - dice_coef_lv: 0.9405 - dice_coef_rv: 0.9119 - val_loss: -0.8859 - val_dice_coef_labels: 0.8792 - val_dice_coef_myo: 0.8346 - val_dice_coef_lv: 0.9346 - val_dice_coef_rv: 0.9008 - lr: 9.0000e-05\n",
      "Epoch 32/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8946 - dice_coef_labels: 0.8847 - dice_coef_myo: 0.8286 - dice_coef_lv: 0.9412 - dice_coef_rv: 0.9124\n",
      "Epoch 00032: val_dice_coef_labels improved from 0.88038 to 0.88242, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 18:21:49,806 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: val_dice_coef_labels improved from 0.88038 to 0.88242, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 331ms/step - loss: -0.8946 - dice_coef_labels: 0.8847 - dice_coef_myo: 0.8286 - dice_coef_lv: 0.9412 - dice_coef_rv: 0.9124 - val_loss: -0.8862 - val_dice_coef_labels: 0.8824 - val_dice_coef_myo: 0.8371 - val_dice_coef_lv: 0.9268 - val_dice_coef_rv: 0.9045 - lr: 9.0000e-05\n",
      "Epoch 33/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8961 - dice_coef_labels: 0.8864 - dice_coef_myo: 0.8295 - dice_coef_lv: 0.9421 - dice_coef_rv: 0.9145\n",
      "Epoch 00033: val_dice_coef_labels improved from 0.88242 to 0.88310, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 18:23:48,137 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_dice_coef_labels improved from 0.88242 to 0.88310, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 331ms/step - loss: -0.8961 - dice_coef_labels: 0.8864 - dice_coef_myo: 0.8295 - dice_coef_lv: 0.9421 - dice_coef_rv: 0.9145 - val_loss: -0.8863 - val_dice_coef_labels: 0.8831 - val_dice_coef_myo: 0.8366 - val_dice_coef_lv: 0.9255 - val_dice_coef_rv: 0.9057 - lr: 9.0000e-05\n",
      "Epoch 34/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8979 - dice_coef_labels: 0.8884 - dice_coef_myo: 0.8309 - dice_coef_lv: 0.9429 - dice_coef_rv: 0.9166\n",
      "Epoch 00034: val_dice_coef_labels did not improve from 0.88310\n",
      "\n",
      "Epoch 00034: val_dice_coef_labels did not improve from 0.88310\n",
      "356/356 [==============================] - 110s 309ms/step - loss: -0.8979 - dice_coef_labels: 0.8884 - dice_coef_myo: 0.8309 - dice_coef_lv: 0.9429 - dice_coef_rv: 0.9166 - val_loss: -0.8902 - val_dice_coef_labels: 0.8830 - val_dice_coef_myo: 0.8357 - val_dice_coef_lv: 0.9381 - val_dice_coef_rv: 0.9057 - lr: 9.0000e-05\n",
      "Epoch 35/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8978 - dice_coef_labels: 0.8883 - dice_coef_myo: 0.8312 - dice_coef_lv: 0.9431 - dice_coef_rv: 0.9164\n",
      "Epoch 00035: val_dice_coef_labels did not improve from 0.88310\n",
      "\n",
      "Epoch 00035: val_dice_coef_labels did not improve from 0.88310\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8978 - dice_coef_labels: 0.8883 - dice_coef_myo: 0.8312 - dice_coef_lv: 0.9431 - dice_coef_rv: 0.9164 - val_loss: -0.8859 - val_dice_coef_labels: 0.8817 - val_dice_coef_myo: 0.8366 - val_dice_coef_lv: 0.9284 - val_dice_coef_rv: 0.9033 - lr: 9.0000e-05\n",
      "Epoch 36/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8976 - dice_coef_labels: 0.8881 - dice_coef_myo: 0.8307 - dice_coef_lv: 0.9426 - dice_coef_rv: 0.9164\n",
      "Epoch 00036: val_dice_coef_labels did not improve from 0.88310\n",
      "\n",
      "Epoch 00036: val_dice_coef_labels did not improve from 0.88310\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8976 - dice_coef_labels: 0.8881 - dice_coef_myo: 0.8307 - dice_coef_lv: 0.9426 - dice_coef_rv: 0.9164 - val_loss: -0.8892 - val_dice_coef_labels: 0.8823 - val_dice_coef_myo: 0.8350 - val_dice_coef_lv: 0.9375 - val_dice_coef_rv: 0.9048 - lr: 9.0000e-05\n",
      "Epoch 37/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8973 - dice_coef_labels: 0.8880 - dice_coef_myo: 0.8308 - dice_coef_lv: 0.9425 - dice_coef_rv: 0.9161\n",
      "Epoch 00037: val_dice_coef_labels improved from 0.88310 to 0.88331, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 18:31:19,356 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00037: val_dice_coef_labels improved from 0.88310 to 0.88331, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 332ms/step - loss: -0.8973 - dice_coef_labels: 0.8880 - dice_coef_myo: 0.8308 - dice_coef_lv: 0.9425 - dice_coef_rv: 0.9161 - val_loss: -0.8902 - val_dice_coef_labels: 0.8833 - val_dice_coef_myo: 0.8357 - val_dice_coef_lv: 0.9378 - val_dice_coef_rv: 0.9061 - lr: 9.0000e-05\n",
      "Epoch 38/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8978 - dice_coef_labels: 0.8883 - dice_coef_myo: 0.8310 - dice_coef_lv: 0.9428 - dice_coef_rv: 0.9166\n",
      "Epoch 00038: val_dice_coef_labels did not improve from 0.88331\n",
      "\n",
      "Epoch 00038: val_dice_coef_labels did not improve from 0.88331\n",
      "356/356 [==============================] - 110s 309ms/step - loss: -0.8978 - dice_coef_labels: 0.8883 - dice_coef_myo: 0.8310 - dice_coef_lv: 0.9428 - dice_coef_rv: 0.9166 - val_loss: -0.8893 - val_dice_coef_labels: 0.8823 - val_dice_coef_myo: 0.8339 - val_dice_coef_lv: 0.9368 - val_dice_coef_rv: 0.9057 - lr: 9.0000e-05\n",
      "Epoch 39/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8978 - dice_coef_labels: 0.8887 - dice_coef_myo: 0.8313 - dice_coef_lv: 0.9421 - dice_coef_rv: 0.9169\n",
      "Epoch 00039: val_dice_coef_labels improved from 0.88331 to 0.88346, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 18:35:08,565 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: val_dice_coef_labels improved from 0.88331 to 0.88346, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 333ms/step - loss: -0.8978 - dice_coef_labels: 0.8887 - dice_coef_myo: 0.8313 - dice_coef_lv: 0.9421 - dice_coef_rv: 0.9169 - val_loss: -0.8906 - val_dice_coef_labels: 0.8835 - val_dice_coef_myo: 0.8368 - val_dice_coef_lv: 0.9384 - val_dice_coef_rv: 0.9058 - lr: 9.0000e-05\n",
      "Epoch 40/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8978 - dice_coef_labels: 0.8883 - dice_coef_myo: 0.8314 - dice_coef_lv: 0.9427 - dice_coef_rv: 0.9164\n",
      "Epoch 00040: val_dice_coef_labels did not improve from 0.88346\n",
      "\n",
      "Epoch 00040: val_dice_coef_labels did not improve from 0.88346\n",
      "356/356 [==============================] - 110s 309ms/step - loss: -0.8978 - dice_coef_labels: 0.8883 - dice_coef_myo: 0.8314 - dice_coef_lv: 0.9427 - dice_coef_rv: 0.9164 - val_loss: -0.8881 - val_dice_coef_labels: 0.8820 - val_dice_coef_myo: 0.8336 - val_dice_coef_lv: 0.9352 - val_dice_coef_rv: 0.9050 - lr: 9.0000e-05\n",
      "Epoch 41/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8984 - dice_coef_labels: 0.8887 - dice_coef_myo: 0.8325 - dice_coef_lv: 0.9436 - dice_coef_rv: 0.9165\n",
      "Epoch 00041: val_dice_coef_labels did not improve from 0.88346\n",
      "\n",
      "Epoch 00041: val_dice_coef_labels did not improve from 0.88346\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8984 - dice_coef_labels: 0.8887 - dice_coef_myo: 0.8325 - dice_coef_lv: 0.9436 - dice_coef_rv: 0.9165 - val_loss: -0.8888 - val_dice_coef_labels: 0.8824 - val_dice_coef_myo: 0.8358 - val_dice_coef_lv: 0.9353 - val_dice_coef_rv: 0.9047 - lr: 9.0000e-05\n",
      "Epoch 42/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8990 - dice_coef_labels: 0.8894 - dice_coef_myo: 0.8330 - dice_coef_lv: 0.9437 - dice_coef_rv: 0.9173\n",
      "Epoch 00042: val_dice_coef_labels improved from 0.88346 to 0.88421, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 18:40:49,055 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: val_dice_coef_labels improved from 0.88346 to 0.88421, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 332ms/step - loss: -0.8990 - dice_coef_labels: 0.8894 - dice_coef_myo: 0.8330 - dice_coef_lv: 0.9437 - dice_coef_rv: 0.9173 - val_loss: -0.8905 - val_dice_coef_labels: 0.8842 - val_dice_coef_myo: 0.8370 - val_dice_coef_lv: 0.9375 - val_dice_coef_rv: 0.9069 - lr: 9.0000e-05\n",
      "Epoch 43/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8989 - dice_coef_labels: 0.8895 - dice_coef_myo: 0.8323 - dice_coef_lv: 0.9434 - dice_coef_rv: 0.9177\n",
      "Epoch 00043: val_dice_coef_labels did not improve from 0.88421\n",
      "\n",
      "Epoch 00043: val_dice_coef_labels did not improve from 0.88421\n",
      "356/356 [==============================] - 110s 309ms/step - loss: -0.8989 - dice_coef_labels: 0.8895 - dice_coef_myo: 0.8323 - dice_coef_lv: 0.9434 - dice_coef_rv: 0.9177 - val_loss: -0.8911 - val_dice_coef_labels: 0.8841 - val_dice_coef_myo: 0.8361 - val_dice_coef_lv: 0.9388 - val_dice_coef_rv: 0.9070 - lr: 9.0000e-05\n",
      "Epoch 44/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8992 - dice_coef_labels: 0.8898 - dice_coef_myo: 0.8320 - dice_coef_lv: 0.9436 - dice_coef_rv: 0.9183\n",
      "Epoch 00044: val_dice_coef_labels did not improve from 0.88421\n",
      "\n",
      "Epoch 00044: val_dice_coef_labels did not improve from 0.88421\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8992 - dice_coef_labels: 0.8898 - dice_coef_myo: 0.8320 - dice_coef_lv: 0.9436 - dice_coef_rv: 0.9183 - val_loss: -0.8915 - val_dice_coef_labels: 0.8840 - val_dice_coef_myo: 0.8360 - val_dice_coef_lv: 0.9396 - val_dice_coef_rv: 0.9071 - lr: 9.0000e-05\n",
      "Epoch 45/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8992 - dice_coef_labels: 0.8900 - dice_coef_myo: 0.8330 - dice_coef_lv: 0.9433 - dice_coef_rv: 0.9181\n",
      "Epoch 00045: val_dice_coef_labels did not improve from 0.88421\n",
      "\n",
      "Epoch 00045: val_dice_coef_labels did not improve from 0.88421\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8992 - dice_coef_labels: 0.8900 - dice_coef_myo: 0.8330 - dice_coef_lv: 0.9433 - dice_coef_rv: 0.9181 - val_loss: -0.8893 - val_dice_coef_labels: 0.8822 - val_dice_coef_myo: 0.8339 - val_dice_coef_lv: 0.9376 - val_dice_coef_rv: 0.9053 - lr: 9.0000e-05\n",
      "Epoch 46/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9000 - dice_coef_labels: 0.8907 - dice_coef_myo: 0.8338 - dice_coef_lv: 0.9438 - dice_coef_rv: 0.9187\n",
      "Epoch 00046: val_dice_coef_labels did not improve from 0.88421\n",
      "\n",
      "Epoch 00046: val_dice_coef_labels did not improve from 0.88421\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9000 - dice_coef_labels: 0.8907 - dice_coef_myo: 0.8338 - dice_coef_lv: 0.9438 - dice_coef_rv: 0.9187 - val_loss: -0.8885 - val_dice_coef_labels: 0.8815 - val_dice_coef_myo: 0.8327 - val_dice_coef_lv: 0.9366 - val_dice_coef_rv: 0.9042 - lr: 9.0000e-05\n",
      "Epoch 47/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8991 - dice_coef_labels: 0.8897 - dice_coef_myo: 0.8327 - dice_coef_lv: 0.9436 - dice_coef_rv: 0.9179\n",
      "Epoch 00047: val_dice_coef_labels did not improve from 0.88421\n",
      "\n",
      "Epoch 00047: val_dice_coef_labels did not improve from 0.88421\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8991 - dice_coef_labels: 0.8897 - dice_coef_myo: 0.8327 - dice_coef_lv: 0.9436 - dice_coef_rv: 0.9179 - val_loss: -0.8911 - val_dice_coef_labels: 0.8840 - val_dice_coef_myo: 0.8372 - val_dice_coef_lv: 0.9388 - val_dice_coef_rv: 0.9066 - lr: 2.7000e-05\n",
      "Epoch 48/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8992 - dice_coef_labels: 0.8898 - dice_coef_myo: 0.8326 - dice_coef_lv: 0.9433 - dice_coef_rv: 0.9180\n",
      "Epoch 00048: val_dice_coef_labels did not improve from 0.88421\n",
      "\n",
      "Epoch 00048: val_dice_coef_labels did not improve from 0.88421\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8992 - dice_coef_labels: 0.8898 - dice_coef_myo: 0.8326 - dice_coef_lv: 0.9433 - dice_coef_rv: 0.9180 - val_loss: -0.8897 - val_dice_coef_labels: 0.8831 - val_dice_coef_myo: 0.8351 - val_dice_coef_lv: 0.9369 - val_dice_coef_rv: 0.9061 - lr: 2.7000e-05\n",
      "Epoch 49/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9001 - dice_coef_labels: 0.8906 - dice_coef_myo: 0.8338 - dice_coef_lv: 0.9443 - dice_coef_rv: 0.9186\n",
      "Epoch 00049: val_dice_coef_labels did not improve from 0.88421\n",
      "\n",
      "Epoch 00049: val_dice_coef_labels did not improve from 0.88421\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9001 - dice_coef_labels: 0.8906 - dice_coef_myo: 0.8338 - dice_coef_lv: 0.9443 - dice_coef_rv: 0.9186 - val_loss: -0.8895 - val_dice_coef_labels: 0.8834 - val_dice_coef_myo: 0.8362 - val_dice_coef_lv: 0.9359 - val_dice_coef_rv: 0.9062 - lr: 2.7000e-05\n",
      "Epoch 50/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9005 - dice_coef_labels: 0.8910 - dice_coef_myo: 0.8341 - dice_coef_lv: 0.9450 - dice_coef_rv: 0.9190\n",
      "Epoch 00050: val_dice_coef_labels did not improve from 0.88421\n",
      "\n",
      "Epoch 00050: val_dice_coef_labels did not improve from 0.88421\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9005 - dice_coef_labels: 0.8910 - dice_coef_myo: 0.8341 - dice_coef_lv: 0.9450 - dice_coef_rv: 0.9190 - val_loss: -0.8900 - val_dice_coef_labels: 0.8831 - val_dice_coef_myo: 0.8358 - val_dice_coef_lv: 0.9379 - val_dice_coef_rv: 0.9058 - lr: 2.7000e-05\n",
      "Epoch 51/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9006 - dice_coef_labels: 0.8914 - dice_coef_myo: 0.8340 - dice_coef_lv: 0.9440 - dice_coef_rv: 0.9196\n",
      "Epoch 00051: val_dice_coef_labels did not improve from 0.88421\n",
      "\n",
      "Epoch 00051: val_dice_coef_labels did not improve from 0.88421\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9006 - dice_coef_labels: 0.8914 - dice_coef_myo: 0.8340 - dice_coef_lv: 0.9440 - dice_coef_rv: 0.9196 - val_loss: -0.8899 - val_dice_coef_labels: 0.8833 - val_dice_coef_myo: 0.8355 - val_dice_coef_lv: 0.9365 - val_dice_coef_rv: 0.9064 - lr: 2.7000e-05\n",
      "Epoch 52/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9007 - dice_coef_labels: 0.8915 - dice_coef_myo: 0.8345 - dice_coef_lv: 0.9441 - dice_coef_rv: 0.9194\n",
      "Epoch 00052: val_dice_coef_labels improved from 0.88421 to 0.88453, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 18:59:27,357 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00052: val_dice_coef_labels improved from 0.88421 to 0.88453, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 332ms/step - loss: -0.9007 - dice_coef_labels: 0.8915 - dice_coef_myo: 0.8345 - dice_coef_lv: 0.9441 - dice_coef_rv: 0.9194 - val_loss: -0.8911 - val_dice_coef_labels: 0.8845 - val_dice_coef_myo: 0.8356 - val_dice_coef_lv: 0.9379 - val_dice_coef_rv: 0.9076 - lr: 2.7000e-05\n",
      "Epoch 53/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9010 - dice_coef_labels: 0.8917 - dice_coef_myo: 0.8351 - dice_coef_lv: 0.9446 - dice_coef_rv: 0.9196\n",
      "Epoch 00053: val_dice_coef_labels did not improve from 0.88453\n",
      "\n",
      "Epoch 00053: val_dice_coef_labels did not improve from 0.88453\n",
      "356/356 [==============================] - 110s 309ms/step - loss: -0.9010 - dice_coef_labels: 0.8917 - dice_coef_myo: 0.8351 - dice_coef_lv: 0.9446 - dice_coef_rv: 0.9196 - val_loss: -0.8898 - val_dice_coef_labels: 0.8834 - val_dice_coef_myo: 0.8351 - val_dice_coef_lv: 0.9368 - val_dice_coef_rv: 0.9065 - lr: 2.7000e-05\n",
      "Epoch 54/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9006 - dice_coef_labels: 0.8915 - dice_coef_myo: 0.8335 - dice_coef_lv: 0.9438 - dice_coef_rv: 0.9202\n",
      "Epoch 00054: val_dice_coef_labels did not improve from 0.88453\n",
      "\n",
      "Epoch 00054: val_dice_coef_labels did not improve from 0.88453\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9006 - dice_coef_labels: 0.8915 - dice_coef_myo: 0.8335 - dice_coef_lv: 0.9438 - dice_coef_rv: 0.9202 - val_loss: -0.8909 - val_dice_coef_labels: 0.8838 - val_dice_coef_myo: 0.8354 - val_dice_coef_lv: 0.9387 - val_dice_coef_rv: 0.9066 - lr: 2.7000e-05\n",
      "Epoch 55/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9007 - dice_coef_labels: 0.8913 - dice_coef_myo: 0.8344 - dice_coef_lv: 0.9445 - dice_coef_rv: 0.9194\n",
      "Epoch 00055: val_dice_coef_labels did not improve from 0.88453\n",
      "\n",
      "Epoch 00055: val_dice_coef_labels did not improve from 0.88453\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9007 - dice_coef_labels: 0.8913 - dice_coef_myo: 0.8344 - dice_coef_lv: 0.9445 - dice_coef_rv: 0.9194 - val_loss: -0.8902 - val_dice_coef_labels: 0.8835 - val_dice_coef_myo: 0.8357 - val_dice_coef_lv: 0.9376 - val_dice_coef_rv: 0.9064 - lr: 2.7000e-05\n",
      "Epoch 56/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9009 - dice_coef_labels: 0.8915 - dice_coef_myo: 0.8342 - dice_coef_lv: 0.9447 - dice_coef_rv: 0.9198\n",
      "Epoch 00056: val_dice_coef_labels did not improve from 0.88453\n",
      "\n",
      "Epoch 00056: val_dice_coef_labels did not improve from 0.88453\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9009 - dice_coef_labels: 0.8915 - dice_coef_myo: 0.8342 - dice_coef_lv: 0.9447 - dice_coef_rv: 0.9198 - val_loss: -0.8895 - val_dice_coef_labels: 0.8828 - val_dice_coef_myo: 0.8357 - val_dice_coef_lv: 0.9366 - val_dice_coef_rv: 0.9053 - lr: 2.7000e-05\n",
      "Epoch 57/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.8999 - dice_coef_labels: 0.8906 - dice_coef_myo: 0.8335 - dice_coef_lv: 0.9437 - dice_coef_rv: 0.9188\n",
      "Epoch 00057: val_dice_coef_labels did not improve from 0.88453\n",
      "\n",
      "Epoch 00057: val_dice_coef_labels did not improve from 0.88453\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.8999 - dice_coef_labels: 0.8906 - dice_coef_myo: 0.8335 - dice_coef_lv: 0.9437 - dice_coef_rv: 0.9188 - val_loss: -0.8911 - val_dice_coef_labels: 0.8844 - val_dice_coef_myo: 0.8375 - val_dice_coef_lv: 0.9376 - val_dice_coef_rv: 0.9071 - lr: 8.1000e-06\n",
      "Epoch 58/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9011 - dice_coef_labels: 0.8919 - dice_coef_myo: 0.8344 - dice_coef_lv: 0.9445 - dice_coef_rv: 0.9201\n",
      "Epoch 00058: val_dice_coef_labels did not improve from 0.88453\n",
      "\n",
      "Epoch 00058: val_dice_coef_labels did not improve from 0.88453\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9011 - dice_coef_labels: 0.8919 - dice_coef_myo: 0.8344 - dice_coef_lv: 0.9445 - dice_coef_rv: 0.9201 - val_loss: -0.8904 - val_dice_coef_labels: 0.8835 - val_dice_coef_myo: 0.8363 - val_dice_coef_lv: 0.9374 - val_dice_coef_rv: 0.9061 - lr: 8.1000e-06\n",
      "Epoch 59/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9006 - dice_coef_labels: 0.8912 - dice_coef_myo: 0.8347 - dice_coef_lv: 0.9445 - dice_coef_rv: 0.9191\n",
      "Epoch 00059: val_dice_coef_labels did not improve from 0.88453\n",
      "\n",
      "Epoch 00059: val_dice_coef_labels did not improve from 0.88453\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9006 - dice_coef_labels: 0.8912 - dice_coef_myo: 0.8347 - dice_coef_lv: 0.9445 - dice_coef_rv: 0.9191 - val_loss: -0.8908 - val_dice_coef_labels: 0.8839 - val_dice_coef_myo: 0.8366 - val_dice_coef_lv: 0.9380 - val_dice_coef_rv: 0.9064 - lr: 8.1000e-06\n",
      "Epoch 60/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9012 - dice_coef_labels: 0.8918 - dice_coef_myo: 0.8352 - dice_coef_lv: 0.9447 - dice_coef_rv: 0.9198\n",
      "Epoch 00060: val_dice_coef_labels improved from 0.88453 to 0.88496, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 19:14:23,678 INFO Assets written to: models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00060: val_dice_coef_labels improved from 0.88453 to 0.88496, saving model to models/2D/ax_sax/gcn_and_acdc_exlusive_ax/2020-07-23_17_19/model.h5\n",
      "356/356 [==============================] - 118s 332ms/step - loss: -0.9012 - dice_coef_labels: 0.8918 - dice_coef_myo: 0.8352 - dice_coef_lv: 0.9447 - dice_coef_rv: 0.9198 - val_loss: -0.8916 - val_dice_coef_labels: 0.8850 - val_dice_coef_myo: 0.8370 - val_dice_coef_lv: 0.9386 - val_dice_coef_rv: 0.9082 - lr: 8.1000e-06\n",
      "Epoch 61/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9008 - dice_coef_labels: 0.8914 - dice_coef_myo: 0.8341 - dice_coef_lv: 0.9447 - dice_coef_rv: 0.9197\n",
      "Epoch 00061: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00061: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 110s 310ms/step - loss: -0.9008 - dice_coef_labels: 0.8914 - dice_coef_myo: 0.8341 - dice_coef_lv: 0.9447 - dice_coef_rv: 0.9197 - val_loss: -0.8904 - val_dice_coef_labels: 0.8832 - val_dice_coef_myo: 0.8363 - val_dice_coef_lv: 0.9381 - val_dice_coef_rv: 0.9057 - lr: 8.1000e-06\n",
      "Epoch 62/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9018 - dice_coef_labels: 0.8923 - dice_coef_myo: 0.8355 - dice_coef_lv: 0.9451 - dice_coef_rv: 0.9205\n",
      "Epoch 00062: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00062: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 312ms/step - loss: -0.9018 - dice_coef_labels: 0.8923 - dice_coef_myo: 0.8355 - dice_coef_lv: 0.9451 - dice_coef_rv: 0.9205 - val_loss: -0.8907 - val_dice_coef_labels: 0.8840 - val_dice_coef_myo: 0.8376 - val_dice_coef_lv: 0.9376 - val_dice_coef_rv: 0.9063 - lr: 8.1000e-06\n",
      "Epoch 63/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9011 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8345 - dice_coef_lv: 0.9444 - dice_coef_rv: 0.9201\n",
      "Epoch 00063: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00063: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9011 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8345 - dice_coef_lv: 0.9444 - dice_coef_rv: 0.9201 - val_loss: -0.8895 - val_dice_coef_labels: 0.8826 - val_dice_coef_myo: 0.8348 - val_dice_coef_lv: 0.9369 - val_dice_coef_rv: 0.9055 - lr: 8.1000e-06\n",
      "Epoch 64/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9014 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8350 - dice_coef_lv: 0.9452 - dice_coef_rv: 0.9199\n",
      "Epoch 00064: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00064: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9014 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8350 - dice_coef_lv: 0.9452 - dice_coef_rv: 0.9199 - val_loss: -0.8911 - val_dice_coef_labels: 0.8843 - val_dice_coef_myo: 0.8361 - val_dice_coef_lv: 0.9384 - val_dice_coef_rv: 0.9071 - lr: 8.1000e-06\n",
      "Epoch 65/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9009 - dice_coef_labels: 0.8917 - dice_coef_myo: 0.8350 - dice_coef_lv: 0.9444 - dice_coef_rv: 0.9198\n",
      "Epoch 00065: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00065: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9009 - dice_coef_labels: 0.8917 - dice_coef_myo: 0.8350 - dice_coef_lv: 0.9444 - dice_coef_rv: 0.9198 - val_loss: -0.8913 - val_dice_coef_labels: 0.8841 - val_dice_coef_myo: 0.8371 - val_dice_coef_lv: 0.9390 - val_dice_coef_rv: 0.9067 - lr: 2.4300e-06\n",
      "Epoch 66/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9014 - dice_coef_labels: 0.8919 - dice_coef_myo: 0.8343 - dice_coef_lv: 0.9454 - dice_coef_rv: 0.9202\n",
      "Epoch 00066: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00066: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9014 - dice_coef_labels: 0.8919 - dice_coef_myo: 0.8343 - dice_coef_lv: 0.9454 - dice_coef_rv: 0.9202 - val_loss: -0.8909 - val_dice_coef_labels: 0.8840 - val_dice_coef_myo: 0.8361 - val_dice_coef_lv: 0.9376 - val_dice_coef_rv: 0.9070 - lr: 2.4300e-06\n",
      "Epoch 67/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9014 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8349 - dice_coef_lv: 0.9453 - dice_coef_rv: 0.9200\n",
      "Epoch 00067: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00067: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9014 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8349 - dice_coef_lv: 0.9453 - dice_coef_rv: 0.9200 - val_loss: -0.8908 - val_dice_coef_labels: 0.8840 - val_dice_coef_myo: 0.8367 - val_dice_coef_lv: 0.9379 - val_dice_coef_rv: 0.9069 - lr: 2.4300e-06\n",
      "Epoch 68/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9014 - dice_coef_labels: 0.8922 - dice_coef_myo: 0.8349 - dice_coef_lv: 0.9446 - dice_coef_rv: 0.9205\n",
      "Epoch 00068: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00068: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9014 - dice_coef_labels: 0.8922 - dice_coef_myo: 0.8349 - dice_coef_lv: 0.9446 - dice_coef_rv: 0.9205 - val_loss: -0.8915 - val_dice_coef_labels: 0.8846 - val_dice_coef_myo: 0.8378 - val_dice_coef_lv: 0.9392 - val_dice_coef_rv: 0.9072 - lr: 2.4300e-06\n",
      "Epoch 69/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9015 - dice_coef_labels: 0.8923 - dice_coef_myo: 0.8349 - dice_coef_lv: 0.9447 - dice_coef_rv: 0.9207\n",
      "Epoch 00069: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00069: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9015 - dice_coef_labels: 0.8923 - dice_coef_myo: 0.8349 - dice_coef_lv: 0.9447 - dice_coef_rv: 0.9207 - val_loss: -0.8894 - val_dice_coef_labels: 0.8825 - val_dice_coef_myo: 0.8351 - val_dice_coef_lv: 0.9374 - val_dice_coef_rv: 0.9051 - lr: 2.4300e-06\n",
      "Epoch 70/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9011 - dice_coef_labels: 0.8917 - dice_coef_myo: 0.8347 - dice_coef_lv: 0.9448 - dice_coef_rv: 0.9197\n",
      "Epoch 00070: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00070: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9011 - dice_coef_labels: 0.8917 - dice_coef_myo: 0.8347 - dice_coef_lv: 0.9448 - dice_coef_rv: 0.9197 - val_loss: -0.8904 - val_dice_coef_labels: 0.8836 - val_dice_coef_myo: 0.8362 - val_dice_coef_lv: 0.9378 - val_dice_coef_rv: 0.9064 - lr: 2.4300e-06\n",
      "Epoch 71/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9009 - dice_coef_labels: 0.8916 - dice_coef_myo: 0.8346 - dice_coef_lv: 0.9444 - dice_coef_rv: 0.9199\n",
      "Epoch 00071: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00071: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9009 - dice_coef_labels: 0.8916 - dice_coef_myo: 0.8346 - dice_coef_lv: 0.9444 - dice_coef_rv: 0.9199 - val_loss: -0.8912 - val_dice_coef_labels: 0.8842 - val_dice_coef_myo: 0.8371 - val_dice_coef_lv: 0.9389 - val_dice_coef_rv: 0.9068 - lr: 7.2900e-07\n",
      "Epoch 72/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9020 - dice_coef_labels: 0.8924 - dice_coef_myo: 0.8356 - dice_coef_lv: 0.9458 - dice_coef_rv: 0.9203\n",
      "Epoch 00072: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00072: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9020 - dice_coef_labels: 0.8924 - dice_coef_myo: 0.8356 - dice_coef_lv: 0.9458 - dice_coef_rv: 0.9203 - val_loss: -0.8907 - val_dice_coef_labels: 0.8840 - val_dice_coef_myo: 0.8369 - val_dice_coef_lv: 0.9376 - val_dice_coef_rv: 0.9066 - lr: 7.2900e-07\n",
      "Epoch 73/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9013 - dice_coef_labels: 0.8918 - dice_coef_myo: 0.8348 - dice_coef_lv: 0.9453 - dice_coef_rv: 0.9200\n",
      "Epoch 00073: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00073: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9013 - dice_coef_labels: 0.8918 - dice_coef_myo: 0.8348 - dice_coef_lv: 0.9453 - dice_coef_rv: 0.9200 - val_loss: -0.8911 - val_dice_coef_labels: 0.8842 - val_dice_coef_myo: 0.8362 - val_dice_coef_lv: 0.9383 - val_dice_coef_rv: 0.9071 - lr: 7.2900e-07\n",
      "Epoch 74/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9014 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8351 - dice_coef_lv: 0.9451 - dice_coef_rv: 0.9201\n",
      "Epoch 00074: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00074: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9014 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8351 - dice_coef_lv: 0.9451 - dice_coef_rv: 0.9201 - val_loss: -0.8903 - val_dice_coef_labels: 0.8832 - val_dice_coef_myo: 0.8363 - val_dice_coef_lv: 0.9382 - val_dice_coef_rv: 0.9057 - lr: 7.2900e-07\n",
      "Epoch 75/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9018 - dice_coef_labels: 0.8925 - dice_coef_myo: 0.8358 - dice_coef_lv: 0.9451 - dice_coef_rv: 0.9205\n",
      "Epoch 00075: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00075: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9018 - dice_coef_labels: 0.8925 - dice_coef_myo: 0.8358 - dice_coef_lv: 0.9451 - dice_coef_rv: 0.9205 - val_loss: -0.8906 - val_dice_coef_labels: 0.8838 - val_dice_coef_myo: 0.8360 - val_dice_coef_lv: 0.9374 - val_dice_coef_rv: 0.9068 - lr: 7.2900e-07\n",
      "Epoch 76/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9018 - dice_coef_labels: 0.8924 - dice_coef_myo: 0.8361 - dice_coef_lv: 0.9455 - dice_coef_rv: 0.9202\n",
      "Epoch 00076: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00076: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9018 - dice_coef_labels: 0.8924 - dice_coef_myo: 0.8361 - dice_coef_lv: 0.9455 - dice_coef_rv: 0.9202 - val_loss: -0.8914 - val_dice_coef_labels: 0.8845 - val_dice_coef_myo: 0.8373 - val_dice_coef_lv: 0.9388 - val_dice_coef_rv: 0.9073 - lr: 7.2900e-07\n",
      "Epoch 77/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9017 - dice_coef_labels: 0.8924 - dice_coef_myo: 0.8351 - dice_coef_lv: 0.9452 - dice_coef_rv: 0.9206\n",
      "Epoch 00077: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00077: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9017 - dice_coef_labels: 0.8924 - dice_coef_myo: 0.8351 - dice_coef_lv: 0.9452 - dice_coef_rv: 0.9206 - val_loss: -0.8914 - val_dice_coef_labels: 0.8845 - val_dice_coef_myo: 0.8368 - val_dice_coef_lv: 0.9392 - val_dice_coef_rv: 0.9073 - lr: 2.1870e-07\n",
      "Epoch 78/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9016 - dice_coef_labels: 0.8922 - dice_coef_myo: 0.8352 - dice_coef_lv: 0.9456 - dice_coef_rv: 0.9203\n",
      "Epoch 00078: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00078: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9016 - dice_coef_labels: 0.8922 - dice_coef_myo: 0.8352 - dice_coef_lv: 0.9456 - dice_coef_rv: 0.9203 - val_loss: -0.8908 - val_dice_coef_labels: 0.8841 - val_dice_coef_myo: 0.8365 - val_dice_coef_lv: 0.9375 - val_dice_coef_rv: 0.9067 - lr: 2.1870e-07\n",
      "Epoch 79/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9017 - dice_coef_labels: 0.8923 - dice_coef_myo: 0.8349 - dice_coef_lv: 0.9452 - dice_coef_rv: 0.9207\n",
      "Epoch 00079: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00079: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9017 - dice_coef_labels: 0.8923 - dice_coef_myo: 0.8349 - dice_coef_lv: 0.9452 - dice_coef_rv: 0.9207 - val_loss: -0.8911 - val_dice_coef_labels: 0.8842 - val_dice_coef_myo: 0.8374 - val_dice_coef_lv: 0.9380 - val_dice_coef_rv: 0.9068 - lr: 2.1870e-07\n",
      "Epoch 80/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9019 - dice_coef_labels: 0.8927 - dice_coef_myo: 0.8357 - dice_coef_lv: 0.9453 - dice_coef_rv: 0.9209\n",
      "Epoch 00080: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00080: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 312ms/step - loss: -0.9019 - dice_coef_labels: 0.8927 - dice_coef_myo: 0.8357 - dice_coef_lv: 0.9453 - dice_coef_rv: 0.9209 - val_loss: -0.8905 - val_dice_coef_labels: 0.8836 - val_dice_coef_myo: 0.8367 - val_dice_coef_lv: 0.9382 - val_dice_coef_rv: 0.9063 - lr: 2.1870e-07\n",
      "Epoch 81/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9011 - dice_coef_labels: 0.8916 - dice_coef_myo: 0.8342 - dice_coef_lv: 0.9451 - dice_coef_rv: 0.9200\n",
      "Epoch 00081: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00081: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9011 - dice_coef_labels: 0.8916 - dice_coef_myo: 0.8342 - dice_coef_lv: 0.9451 - dice_coef_rv: 0.9200 - val_loss: -0.8912 - val_dice_coef_labels: 0.8842 - val_dice_coef_myo: 0.8367 - val_dice_coef_lv: 0.9392 - val_dice_coef_rv: 0.9070 - lr: 2.1870e-07\n",
      "Epoch 82/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9012 - dice_coef_labels: 0.8918 - dice_coef_myo: 0.8343 - dice_coef_lv: 0.9451 - dice_coef_rv: 0.9202\n",
      "Epoch 00082: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00082: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 310ms/step - loss: -0.9012 - dice_coef_labels: 0.8918 - dice_coef_myo: 0.8343 - dice_coef_lv: 0.9451 - dice_coef_rv: 0.9202 - val_loss: -0.8916 - val_dice_coef_labels: 0.8847 - val_dice_coef_myo: 0.8373 - val_dice_coef_lv: 0.9392 - val_dice_coef_rv: 0.9077 - lr: 2.1870e-07\n",
      "Epoch 83/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9013 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8350 - dice_coef_lv: 0.9449 - dice_coef_rv: 0.9201\n",
      "Epoch 00083: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00083: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9013 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8350 - dice_coef_lv: 0.9449 - dice_coef_rv: 0.9201 - val_loss: -0.8907 - val_dice_coef_labels: 0.8838 - val_dice_coef_myo: 0.8370 - val_dice_coef_lv: 0.9380 - val_dice_coef_rv: 0.9064 - lr: 6.5610e-08\n",
      "Epoch 84/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9014 - dice_coef_labels: 0.8921 - dice_coef_myo: 0.8347 - dice_coef_lv: 0.9447 - dice_coef_rv: 0.9204\n",
      "Epoch 00084: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00084: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 110s 310ms/step - loss: -0.9014 - dice_coef_labels: 0.8921 - dice_coef_myo: 0.8347 - dice_coef_lv: 0.9447 - dice_coef_rv: 0.9204 - val_loss: -0.8905 - val_dice_coef_labels: 0.8839 - val_dice_coef_myo: 0.8367 - val_dice_coef_lv: 0.9372 - val_dice_coef_rv: 0.9061 - lr: 6.5610e-08\n",
      "Epoch 85/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9012 - dice_coef_labels: 0.8918 - dice_coef_myo: 0.8351 - dice_coef_lv: 0.9450 - dice_coef_rv: 0.9199\n",
      "Epoch 00085: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00085: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 310ms/step - loss: -0.9012 - dice_coef_labels: 0.8918 - dice_coef_myo: 0.8351 - dice_coef_lv: 0.9450 - dice_coef_rv: 0.9199 - val_loss: -0.8909 - val_dice_coef_labels: 0.8839 - val_dice_coef_myo: 0.8369 - val_dice_coef_lv: 0.9387 - val_dice_coef_rv: 0.9068 - lr: 6.5610e-08\n",
      "Epoch 86/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9013 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8353 - dice_coef_lv: 0.9448 - dice_coef_rv: 0.9200\n",
      "Epoch 00086: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00086: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9013 - dice_coef_labels: 0.8920 - dice_coef_myo: 0.8353 - dice_coef_lv: 0.9448 - dice_coef_rv: 0.9200 - val_loss: -0.8909 - val_dice_coef_labels: 0.8840 - val_dice_coef_myo: 0.8371 - val_dice_coef_lv: 0.9385 - val_dice_coef_rv: 0.9066 - lr: 6.5610e-08\n",
      "Epoch 87/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9013 - dice_coef_labels: 0.8921 - dice_coef_myo: 0.8352 - dice_coef_lv: 0.9446 - dice_coef_rv: 0.9203\n",
      "Epoch 00087: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00087: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9013 - dice_coef_labels: 0.8921 - dice_coef_myo: 0.8352 - dice_coef_lv: 0.9446 - dice_coef_rv: 0.9203 - val_loss: -0.8904 - val_dice_coef_labels: 0.8836 - val_dice_coef_myo: 0.8365 - val_dice_coef_lv: 0.9373 - val_dice_coef_rv: 0.9060 - lr: 6.5610e-08\n",
      "Epoch 88/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9016 - dice_coef_labels: 0.8923 - dice_coef_myo: 0.8350 - dice_coef_lv: 0.9449 - dice_coef_rv: 0.9205\n",
      "Epoch 00088: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00088: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9016 - dice_coef_labels: 0.8923 - dice_coef_myo: 0.8350 - dice_coef_lv: 0.9449 - dice_coef_rv: 0.9205 - val_loss: -0.8905 - val_dice_coef_labels: 0.8836 - val_dice_coef_myo: 0.8364 - val_dice_coef_lv: 0.9379 - val_dice_coef_rv: 0.9062 - lr: 6.5610e-08\n",
      "Epoch 89/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9018 - dice_coef_labels: 0.8922 - dice_coef_myo: 0.8353 - dice_coef_lv: 0.9460 - dice_coef_rv: 0.9202\n",
      "Epoch 00089: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00089: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
      "356/356 [==============================] - 111s 312ms/step - loss: -0.9018 - dice_coef_labels: 0.8922 - dice_coef_myo: 0.8353 - dice_coef_lv: 0.9460 - dice_coef_rv: 0.9202 - val_loss: -0.8911 - val_dice_coef_labels: 0.8842 - val_dice_coef_myo: 0.8367 - val_dice_coef_lv: 0.9381 - val_dice_coef_rv: 0.9068 - lr: 1.9683e-08\n",
      "Epoch 90/300\n",
      "356/356 [==============================] - ETA: 0s - loss: -0.9020 - dice_coef_labels: 0.8925 - dice_coef_myo: 0.8352 - dice_coef_lv: 0.9455 - dice_coef_rv: 0.9208\n",
      "Epoch 00090: val_dice_coef_labels did not improve from 0.88496\n",
      "\n",
      "Epoch 00090: val_dice_coef_labels did not improve from 0.88496\n",
      "356/356 [==============================] - 111s 311ms/step - loss: -0.9020 - dice_coef_labels: 0.8925 - dice_coef_myo: 0.8352 - dice_coef_lv: 0.9455 - dice_coef_rv: 0.9208 - val_loss: -0.8917 - val_dice_coef_labels: 0.8849 - val_dice_coef_myo: 0.8376 - val_dice_coef_lv: 0.9389 - val_dice_coef_rv: 0.9079 - lr: 1.9683e-08\n",
      "Epoch 00090: early stopping\n"
     ]
    }
   ],
   "source": [
    "initial_epoch = 0\n",
    "# training\n",
    "\n",
    "# start a new main process for this training to free gpu memory afterwards\n",
    "logging.info('Fit model, start trainings process')\n",
    "# fit model with trainingsgenerator\n",
    "\n",
    "results = model.fit(\n",
    "    x=batch_generator,\n",
    "    epochs=config['EPOCHS'],\n",
    "    callbacks=get_callbacks(config, batch_generator, validation_generator),\n",
    "    steps_per_epoch = len(batch_generator),\n",
    "    validation_data=validation_generator,\n",
    "    initial_epoch=initial_epoch,\n",
    "    max_queue_size=20,\n",
    "    workers=0,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write trainings history to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa199986198>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#logging.info(results.history)\n",
    "df_history = pd.DataFrame(results.history)\n",
    "df_history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all cells for training, this cell will terminate the current jupyter process \n",
    "# --> free all ressources after the training has finished\n",
    "os.system('kill %d' % os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/3D/wrapper/gcn2nd/fold1/2020-06-27_11_24'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['MODEL_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(config['MODEL_PATH'], 'model.json'), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(os.path.join(config['MODEL_PATH'],'checkpoint.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
