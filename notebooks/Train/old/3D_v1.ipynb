{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/data/git/cardio\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1709982873418640778\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6172083567224082683\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23137137460\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3547627308205375572\n",
      "physical_device_desc: \"device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4893802178515127108\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-09-05 12:31:08,731 INFO -------------------- Start --------------------\n",
      "2019-09-05 12:31:08,732 INFO Working directory: /mnt/data/git/cardio.\n",
      "2019-09-05 12:31:08,745 INFO Log file: ./logs/3D/new_model.log\n",
      "2019-09-05 12:31:08,746 INFO config saved:\n",
      " {\n",
      "    \"ACTIVATION\": \"elu\",\n",
      "    \"ARCHITECTURE\": \"3D\",\n",
      "    \"AUGMENT\": false,\n",
      "    \"AUGMENT_GRID\": true,\n",
      "    \"BATCHSIZE\": 4,\n",
      "    \"BATCH_NORMALISATION\": true,\n",
      "    \"CONFIG_PATH\": \"reports/configs/3D/new_model/2019-09-05_12_31\",\n",
      "    \"DATASET\": \"tetra\",\n",
      "    \"DECAY\": 0.0,\n",
      "    \"DIM\": [\n",
      "        12,\n",
      "        224,\n",
      "        224\n",
      "    ],\n",
      "    \"DROPOUT_L1_L2\": 0.3,\n",
      "    \"DROPOUT_L3_L4\": 0.4,\n",
      "    \"DROPOUT_L5\": 0.5,\n",
      "    \"EPOCHS\": 150,\n",
      "    \"EPOCHS_BETWEEN_CHECKPOINTS\": 5,\n",
      "    \"EPSILON\": 1e-08,\n",
      "    \"EXPERIMENT\": \"3D/new_model\",\n",
      "    \"FOLDS\": 4,\n",
      "    \"GENERATOR_WORKER\": 2,\n",
      "    \"HISTORY_PATH\": \"reports/history/3D/new_model/2019-09-05_12_31\",\n",
      "    \"IMG_CHANNELS\": 1,\n",
      "    \"INITIAL_EPOCH\": 0,\n",
      "    \"LEARNING_RATE\": 0.001,\n",
      "    \"LOSS_FUNCTION\": \"bce_dice_jac_loss\",\n",
      "    \"MASK_CLASSES\": 4,\n",
      "    \"MASK_VALUES\": [\n",
      "        0,\n",
      "        1,\n",
      "        2,\n",
      "        3\n",
      "    ],\n",
      "    \"MODEL_PATH\": \"models/3D/new_model/2019-09-05_12_31\",\n",
      "    \"MONITOR_FUNCTION\": \"val_dice_coef_labels\",\n",
      "    \"MONITOR_MODE\": \"max\",\n",
      "    \"OPTIMIZER\": \"Adam\",\n",
      "    \"RESAMPLE\": false,\n",
      "    \"SHUFFLE\": true,\n",
      "    \"SPACING\": [\n",
      "        1.0,\n",
      "        1.0,\n",
      "        8\n",
      "    ],\n",
      "    \"SPACING_X\": 1.0,\n",
      "    \"SPACING_Y\": 1.0,\n",
      "    \"TENSORBOARD_LOG_DIR\": \"reports/tensorboard_logs/3D/new_model/2019-09-05_12_31\",\n",
      "    \"TEST_PATH\": \"data/raw/tetra/3D/test/\",\n",
      "    \"TRAIN_PATH\": \"data/raw/tetra/3D/train/\",\n",
      "    \"VAL_PATH\": \"data/raw/tetra/3D/val/\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.Tensorflow_helper import choose_gpu_by_id\n",
    "from pyforest import *\n",
    "\n",
    "\n",
    "# define GPU id to use\n",
    "# 0 = 1080 Bus ID 2\n",
    "# 1 = Titan Bus ID 131\n",
    "# 2 = Titan Bus ID 132\n",
    "gpu_id = '0'\n",
    "current_gpu = choose_gpu_by_id(gpu_id)\n",
    "\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import SimpleITK as sitk\n",
    "import glob\n",
    "import datetime\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from ipywidgets import interact\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from src.utils.utils_io import Console_and_file_logger, init_config\n",
    "from src.visualization.visualize import show_2D_or_3D\n",
    "from src.data.dataset import get_metadata_maybe, filter_4d_vol, describe_sitk, get_img_msk_files_from_split_dir\n",
    "from src.data.generators import DataGenerator\n",
    "from src.utils.unet_3d_metrics import weighted_dice_coefficient_loss\n",
    "from src.models.ModelManager import get_model\n",
    "from src.utils.KerasCallbacks import get_callbacks\n",
    "from keras.utils import plot_model\n",
    "import src.utils.my_metrics as metr\n",
    "\n",
    "\n",
    "# define experiment name for report, model and log paths + filenames\n",
    "EXPERIMENT = '3D/new_model'\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# image params\n",
    "ARCHITECTURE = '3D'\n",
    "DIM = [12, 224, 224]\n",
    "#IMG_Z = 12\n",
    "#IMG_WIDTH = 224\n",
    "#IMG_HEIGHT = 224\n",
    "SPACING = [1.0,1.0,8] # used by sitk, opposite order than numpy or tensorflow!\n",
    "IMG_CHANNELS = 1\n",
    "MASK_VALUES = [0, 1, 2, 3]  \n",
    "MASK_CLASSES = len(MASK_VALUES)\n",
    "# Background = 0 = Y[:,:,0]\n",
    "# RV = 1 = Y[:,:,1] \n",
    "# Myo = 2 = Y[:,:,2] \n",
    "# LV = 3 = Y[:,:,3]\n",
    "AUGMENT = False\n",
    "SHUFFLE = True\n",
    "AUGMENT_GRID = True\n",
    "RESAMPLE = False\n",
    "SPACING_X = 1.00\n",
    "SPACING_Y = 1.00\n",
    "\n",
    "# path params\n",
    "DATASET = 'tetra'  # 'acdc' # or 'tetra'\n",
    "TRAIN_PATH = 'data/raw/tetra/3D/train/'\n",
    "VAL_PATH = 'data/raw/tetra/3D/val/'\n",
    "TEST_PATH = 'data/raw/tetra/3D/test/'\n",
    "\n",
    "MODEL_PATH = os.path.join(os.path.join('models', EXPERIMENT), str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "TENSORBOARD_LOG_DIR = os.path.join(os.path.join('reports/tensorboard_logs', EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "CONFIG_PATH = os.path.join(os.path.join('reports/configs/',EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "HISTORY_PATH = os.path.join(os.path.join('reports/history/',EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "\n",
    "# training params\n",
    "ARCHITECTURE = '3D'\n",
    "GENERATOR_WORKER = 2 # if not set use batchsize\n",
    "seed = 42\n",
    "BATCHSIZE =  4 # 32, 64, 16, 1\n",
    "INITIAL_EPOCH = 0\n",
    "EPOCHS = 150\n",
    "FOLDS = 4\n",
    "EPOCHS_BETWEEN_CHECKPOINTS = 5\n",
    "MONITOR_FUNCTION = 'val_dice_coef_labels'\n",
    "MONITOR_MODE = 'max'\n",
    "\n",
    "# Network params\n",
    "OPTIMIZER = 'Adam'  # Adam, Adagrad, RMSprop, Adadelta,  # https://keras.io/optimizers/\n",
    "ACTIVATION = 'elu'  # 'elu' --> works well with binary_crossentropy and bce_dice_loss, relu does not work, it clips negative values, bse does return negative values\n",
    "LEARNING_RATE = 0.001\n",
    "DECAY = 0.0\n",
    "EPSILON = 1e-08\n",
    "DROPOUT_L1_L2 = 0.3 # best with 0.4 and other 0.5\n",
    "DROPOUT_L3_L4 = 0.4\n",
    "DROPOUT_L5 = 0.5\n",
    "BATCH_NORMALISATION = True\n",
    "\n",
    "#metrics = [jaccard_coef, jaccard_coef_background, jaccard_coef_rv, jaccard_coef_lv, jaccard_coef_myo]\n",
    "metrics = [\n",
    "    metr.dice_coef_labels,\n",
    "    metr.dice_coef_myo,\n",
    "    metr.dice_coef_lv,\n",
    "    metr.dice_coef_rv,\n",
    "]\n",
    "\n",
    "#LOSS_FUNCTION = keras.losses.categorical_crossentropy\n",
    "#weights = np.array([1,2,2,3]) # Class one at 1, class 2, 10 times the normal weights, class 3 and 4 20x.\n",
    "#LOSS_FUNCTION = weighted_categorical_crossentropy(weights)\n",
    "#LOSS_FUNCTION = cce_dice_loss\n",
    "LOSS_FUNCTION = metr.bce_dice_jac_loss\n",
    "\n",
    "Console_and_file_logger(EXPERIMENT, logging.INFO)\n",
    "\n",
    "\n",
    "# Define a config for param injection,\n",
    "# save a serialized version, \n",
    "# make sure all paths exist\n",
    "config = init_config(locals(), True)\n",
    "\n",
    "# set warnings lvl for skimage\n",
    "#warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "# define a Tensorflow config\n",
    "#tf_config = tf.ConfigProto()\n",
    "#tf_config.gpu_options.allow_growth = True\n",
    "#tf_session = tf.Session(config=tf_config)\n",
    "#tf.keras.backend.set_session(tf_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training, val and test-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-05 12:31:08,772 INFO x_train files: 754, y_train files: 754\n",
      "2019-09-05 12:31:08,772 INFO x_val files: 130, y_val files: 130\n",
      "2019-09-05 12:31:08,772 INFO x_test files: 126, y_test files: 126\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2D special\n",
    "# load only slices from the lower, middle or upper part\n",
    "X_train, Y_train = get_samples(path=TRAIN_PATH, samples=0, part='all', no_patients = 0, preprocessed=False)\n",
    "X_val, Y_val = get_samples(path=VAL_PATH, samples=0, part='all', no_patients = 0, preprocessed=False)\n",
    "X_test, Y_test = get_samples(path=TEST_PATH, samples=0, part='all', no_patients = 0, preprocessed=False)\n",
    "\"\"\"\n",
    "\n",
    "x_train, y_train = get_img_msk_files_from_split_dir(config['TRAIN_PATH'])\n",
    "x_val, y_val = get_img_msk_files_from_split_dir(config['VAL_PATH'])\n",
    "x_test, y_test = get_img_msk_files_from_split_dir(config['TEST_PATH'])\n",
    "\n",
    "logging.info('x_train files: {}, y_train files: {}'.format(len(x_train), len(y_train)))\n",
    "logging.info('x_val files: {}, y_val files: {}'.format(len(x_val), len(y_val)))\n",
    "logging.info('x_test files: {}, y_test files: {}'.format(len(x_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-05 12:31:08,787 INFO Create DataGenerator\n",
      "2019-09-05 12:31:08,790 INFO Datagenerator created with: \n",
      " shape: [12, 224, 224]\n",
      " batchsize: 4\n",
      " Scaler: MinMax\n",
      " Images: 754 \n",
      " Augment_grid: True\n",
      "2019-09-05 12:31:08,790 INFO No augmentation\n",
      "2019-09-05 12:31:08,790 INFO Create DataGenerator\n",
      "2019-09-05 12:31:08,791 INFO Datagenerator created with: \n",
      " shape: [12, 224, 224]\n",
      " batchsize: 4\n",
      " Scaler: MinMax\n",
      " Images: 130 \n",
      " Augment_grid: False\n",
      "2019-09-05 12:31:08,791 INFO No augmentation\n",
      "2019-09-05 12:31:08,792 INFO Create DataGenerator\n",
      "2019-09-05 12:31:08,793 INFO Datagenerator created with: \n",
      " shape: [12, 224, 224]\n",
      " batchsize: 4\n",
      " Scaler: MinMax\n",
      " Images: 126 \n",
      " Augment_grid: False\n",
      "2019-09-05 12:31:08,793 INFO No augmentation\n"
     ]
    }
   ],
   "source": [
    "# create a batch generator\n",
    "batch_generator = DataGenerator(x_train, y_train, config=config)\n",
    "config['AUGMENT_GRID'] = False # make sure no augmentation will be applied to the evaluation data\n",
    "validation_generator = DataGenerator(x_val, y_val , config=config)\n",
    "test_generator = DataGenerator(x_test, y_test, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2221192f6c04c989a79ecbcd78caa2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=94, description='batch', max=188), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select batch generator output\n",
    "x = ''\n",
    "y = ''\n",
    "@interact\n",
    "def select_batch(batch = (0,len(batch_generator), 1)):\n",
    "    global x, y\n",
    "    x, y = batch_generator.__getitem__(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227d693f04be4ef095d39f08cbd83acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='im', max=3), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def select_image_in_batch(im = (0,config['BATCHSIZE']- 1, 1)):\n",
    "    \n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    show_2D_or_3D(x[im], y[im])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c91821bdb14c259518a9ebecba3227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='config_file', options=('reports/configs/3D/new_model/2019-09-05_11…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def interact_load_pretrained_model(config_file=glob.glob('reports/configs/{}/**/**/*.json'.format(config.get('ARCHITECTURE', '2D')), recursive=False), load=False):\n",
    "    \"\"\"\n",
    "    load past config for model training \n",
    "    \"\"\"\n",
    "    # load config with all params into global namespace\n",
    "    if load:\n",
    "        with open(config_file, encoding='utf-8') as data_file:\n",
    "            config = json.loads(data_file.read())\n",
    "        #globals()['MODEL_PATH'] = config['MODEL_PATH']\n",
    "        logging.info('Experiment: {}'.format(config['EXPERIMENT']))\n",
    "        logging.info('config:\\n {}'.format(json.dumps(config, indent=4, sort_keys=True)))\n",
    "    \n",
    "        try:\n",
    "            # load model\n",
    "            globals()['model'] = load_pretrained_model(config, metrics)\n",
    "            model.summary()\n",
    "        except Exception as e:\n",
    "            logging.error(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f163ae0b44e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Create model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "logging.info('Create model')\n",
    "model = get_model(config, metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file=os.path.join(config.get('CONFIG_PATH'),'model.png'), show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-05 12:31:14,439 INFO Fit model, start trainings process\n",
      "2019-09-05 12:31:15,246 INFO feed 4 Tensorboard is ready\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "188/188 [==============================] - 137s 728ms/step - loss: 0.3455 - dice_coef_labels: 0.0227 - dice_coef_myo: 0.0152 - dice_coef_lv: 0.0151 - dice_coef_rv: 0.0363 - val_loss: 0.5302 - val_dice_coef_labels: 0.0253 - val_dice_coef_myo: 0.0164 - val_dice_coef_lv: 0.0134 - val_dice_coef_rv: 0.0432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-05 12:33:48,827 INFO Saved model to disk: models/3D/new_model/2019-09-05_12_31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_dice_coef_labels improved from -inf to 0.02530, saving model to models/3D/new_model/2019-09-05_12_31/checkpoint.h5\n",
      "Epoch 2/150\n",
      "188/188 [==============================] - 116s 619ms/step - loss: -0.0019 - dice_coef_labels: 0.0974 - dice_coef_myo: 0.0708 - dice_coef_lv: 0.0743 - dice_coef_rv: 0.1312 - val_loss: 0.3768 - val_dice_coef_labels: 0.0676 - val_dice_coef_myo: 0.0480 - val_dice_coef_lv: 0.0476 - val_dice_coef_rv: 0.0882\n",
      "\n",
      "Epoch 00002: val_dice_coef_labels improved from 0.02530 to 0.06758, saving model to models/3D/new_model/2019-09-05_12_31/checkpoint.h5\n",
      "Epoch 3/150\n",
      "188/188 [==============================] - 118s 629ms/step - loss: -0.3663 - dice_coef_labels: 0.3875 - dice_coef_myo: 0.2576 - dice_coef_lv: 0.3640 - dice_coef_rv: 0.4479 - val_loss: -0.3452 - val_dice_coef_labels: 0.3717 - val_dice_coef_myo: 0.3059 - val_dice_coef_lv: 0.2859 - val_dice_coef_rv: 0.4578\n",
      "\n",
      "Epoch 00003: val_dice_coef_labels improved from 0.06758 to 0.37166, saving model to models/3D/new_model/2019-09-05_12_31/checkpoint.h5\n",
      "Epoch 4/150\n",
      "188/188 [==============================] - 120s 636ms/step - loss: -0.5467 - dice_coef_labels: 0.5619 - dice_coef_myo: 0.4034 - dice_coef_lv: 0.5821 - dice_coef_rv: 0.6084 - val_loss: -0.5067 - val_dice_coef_labels: 0.5267 - val_dice_coef_myo: 0.3670 - val_dice_coef_lv: 0.4918 - val_dice_coef_rv: 0.5836\n",
      "\n",
      "Epoch 00004: val_dice_coef_labels improved from 0.37166 to 0.52670, saving model to models/3D/new_model/2019-09-05_12_31/checkpoint.h5\n",
      "Epoch 5/150\n",
      "188/188 [==============================] - 117s 625ms/step - loss: -0.5921 - dice_coef_labels: 0.6074 - dice_coef_myo: 0.4653 - dice_coef_lv: 0.6514 - dice_coef_rv: 0.6386 - val_loss: -0.5703 - val_dice_coef_labels: 0.5854 - val_dice_coef_myo: 0.4254 - val_dice_coef_lv: 0.5756 - val_dice_coef_rv: 0.6338\n",
      "\n",
      "Epoch 00005: val_dice_coef_labels improved from 0.52670 to 0.58542, saving model to models/3D/new_model/2019-09-05_12_31/checkpoint.h5\n",
      "Epoch 6/150\n",
      "188/188 [==============================] - 120s 637ms/step - loss: -0.6379 - dice_coef_labels: 0.6522 - dice_coef_myo: 0.5136 - dice_coef_lv: 0.6889 - dice_coef_rv: 0.6871 - val_loss: -0.5957 - val_dice_coef_labels: 0.6092 - val_dice_coef_myo: 0.4527 - val_dice_coef_lv: 0.5845 - val_dice_coef_rv: 0.6378\n",
      "\n",
      "Epoch 00006: val_dice_coef_labels improved from 0.58542 to 0.60916, saving model to models/3D/new_model/2019-09-05_12_31/checkpoint.h5\n",
      "Epoch 7/150\n",
      "188/188 [==============================] - 118s 628ms/step - loss: -0.6418 - dice_coef_labels: 0.6560 - dice_coef_myo: 0.5136 - dice_coef_lv: 0.6886 - dice_coef_rv: 0.6881 - val_loss: -0.5691 - val_dice_coef_labels: 0.5827 - val_dice_coef_myo: 0.4584 - val_dice_coef_lv: 0.5750 - val_dice_coef_rv: 0.5928\n",
      "\n",
      "Epoch 00007: val_dice_coef_labels did not improve from 0.60916\n",
      "Epoch 8/150\n",
      "188/188 [==============================] - 120s 637ms/step - loss: -0.6763 - dice_coef_labels: 0.6895 - dice_coef_myo: 0.5551 - dice_coef_lv: 0.7220 - dice_coef_rv: 0.7194 - val_loss: -0.6317 - val_dice_coef_labels: 0.6458 - val_dice_coef_myo: 0.4724 - val_dice_coef_lv: 0.7043 - val_dice_coef_rv: 0.6749\n",
      "\n",
      "Epoch 00008: val_dice_coef_labels improved from 0.60916 to 0.64577, saving model to models/3D/new_model/2019-09-05_12_31/checkpoint.h5\n",
      "Epoch 9/150\n",
      "188/188 [==============================] - 120s 636ms/step - loss: -0.6786 - dice_coef_labels: 0.6920 - dice_coef_myo: 0.5490 - dice_coef_lv: 0.7244 - dice_coef_rv: 0.7269 - val_loss: -0.6659 - val_dice_coef_labels: 0.6792 - val_dice_coef_myo: 0.5533 - val_dice_coef_lv: 0.6956 - val_dice_coef_rv: 0.7034\n",
      "\n",
      "Epoch 00009: val_dice_coef_labels improved from 0.64577 to 0.67921, saving model to models/3D/new_model/2019-09-05_12_31/checkpoint.h5\n",
      "Epoch 10/150\n",
      "188/188 [==============================] - 119s 630ms/step - loss: -0.6936 - dice_coef_labels: 0.7062 - dice_coef_myo: 0.5629 - dice_coef_lv: 0.7421 - dice_coef_rv: 0.7354 - val_loss: -0.6622 - val_dice_coef_labels: 0.6747 - val_dice_coef_myo: 0.4692 - val_dice_coef_lv: 0.7241 - val_dice_coef_rv: 0.7087\n",
      "\n",
      "Epoch 00010: val_dice_coef_labels did not improve from 0.67921\n",
      "Epoch 11/150\n",
      "188/188 [==============================] - 119s 633ms/step - loss: -0.6986 - dice_coef_labels: 0.7114 - dice_coef_myo: 0.5786 - dice_coef_lv: 0.7450 - dice_coef_rv: 0.7390 - val_loss: -0.6727 - val_dice_coef_labels: 0.6834 - val_dice_coef_myo: 0.5686 - val_dice_coef_lv: 0.7187 - val_dice_coef_rv: 0.7038\n",
      "\n",
      "Epoch 00011: val_dice_coef_labels improved from 0.67921 to 0.68344, saving model to models/3D/new_model/2019-09-05_12_31/checkpoint.h5\n",
      "Epoch 12/150\n",
      "188/188 [==============================] - 120s 639ms/step - loss: -0.7240 - dice_coef_labels: 0.7356 - dice_coef_myo: 0.5960 - dice_coef_lv: 0.7735 - dice_coef_rv: 0.7624 - val_loss: -0.6778 - val_dice_coef_labels: 0.6895 - val_dice_coef_myo: 0.5705 - val_dice_coef_lv: 0.6937 - val_dice_coef_rv: 0.7061\n",
      "\n",
      "Epoch 00012: val_dice_coef_labels improved from 0.68344 to 0.68951, saving model to models/3D/new_model/2019-09-05_12_31/checkpoint.h5\n",
      "Epoch 13/150\n",
      "188/188 [==============================] - 120s 640ms/step - loss: -0.7198 - dice_coef_labels: 0.7309 - dice_coef_myo: 0.5978 - dice_coef_lv: 0.7698 - dice_coef_rv: 0.7574 - val_loss: -0.6502 - val_dice_coef_labels: 0.6633 - val_dice_coef_myo: 0.5087 - val_dice_coef_lv: 0.6564 - val_dice_coef_rv: 0.6855\n",
      "\n",
      "Epoch 00013: val_dice_coef_labels did not improve from 0.68951\n",
      "Epoch 14/150\n",
      "188/188 [==============================] - 123s 652ms/step - loss: -0.7421 - dice_coef_labels: 0.7527 - dice_coef_myo: 0.6163 - dice_coef_lv: 0.7874 - dice_coef_rv: 0.7827 - val_loss: -0.6583 - val_dice_coef_labels: 0.6701 - val_dice_coef_myo: 0.5165 - val_dice_coef_lv: 0.6195 - val_dice_coef_rv: 0.7019\n",
      "\n",
      "Epoch 00014: val_dice_coef_labels did not improve from 0.68951\n",
      "Epoch 15/150\n",
      "188/188 [==============================] - 118s 626ms/step - loss: -0.7409 - dice_coef_labels: 0.7515 - dice_coef_myo: 0.6148 - dice_coef_lv: 0.7862 - dice_coef_rv: 0.7778 - val_loss: -0.7132 - val_dice_coef_labels: 0.7237 - val_dice_coef_myo: 0.6273 - val_dice_coef_lv: 0.7703 - val_dice_coef_rv: 0.7344\n",
      "\n",
      "Epoch 00015: val_dice_coef_labels improved from 0.68951 to 0.72375, saving model to models/3D/new_model/2019-09-05_12_31/checkpoint.h5\n",
      "Epoch 16/150\n",
      "188/188 [==============================] - 120s 636ms/step - loss: -0.7435 - dice_coef_labels: 0.7537 - dice_coef_myo: 0.6200 - dice_coef_lv: 0.7941 - dice_coef_rv: 0.7801 - val_loss: -0.6846 - val_dice_coef_labels: 0.6970 - val_dice_coef_myo: 0.5968 - val_dice_coef_lv: 0.7420 - val_dice_coef_rv: 0.7006\n",
      "\n",
      "Epoch 00016: val_dice_coef_labels did not improve from 0.72375\n",
      "Epoch 17/150\n",
      "188/188 [==============================] - 123s 653ms/step - loss: -0.7538 - dice_coef_labels: 0.7642 - dice_coef_myo: 0.6301 - dice_coef_lv: 0.7928 - dice_coef_rv: 0.7920 - val_loss: -0.6149 - val_dice_coef_labels: 0.6288 - val_dice_coef_myo: 0.5604 - val_dice_coef_lv: 0.6867 - val_dice_coef_rv: 0.6248\n",
      "\n",
      "Epoch 00017: val_dice_coef_labels did not improve from 0.72375\n",
      "Epoch 18/150\n",
      "188/188 [==============================] - 120s 638ms/step - loss: -0.7641 - dice_coef_labels: 0.7737 - dice_coef_myo: 0.6313 - dice_coef_lv: 0.7888 - dice_coef_rv: 0.8040 - val_loss: -0.6928 - val_dice_coef_labels: 0.7042 - val_dice_coef_myo: 0.5528 - val_dice_coef_lv: 0.7044 - val_dice_coef_rv: 0.7172\n",
      "\n",
      "Epoch 00018: val_dice_coef_labels did not improve from 0.72375\n",
      "Epoch 19/150\n",
      "188/188 [==============================] - 122s 648ms/step - loss: -0.7647 - dice_coef_labels: 0.7740 - dice_coef_myo: 0.6477 - dice_coef_lv: 0.8070 - dice_coef_rv: 0.8034 - val_loss: -0.6861 - val_dice_coef_labels: 0.6982 - val_dice_coef_myo: 0.5727 - val_dice_coef_lv: 0.7252 - val_dice_coef_rv: 0.7149\n",
      "\n",
      "Epoch 00019: val_dice_coef_labels did not improve from 0.72375\n",
      "Epoch 20/150\n",
      "188/188 [==============================] - 123s 654ms/step - loss: -0.7794 - dice_coef_labels: 0.7883 - dice_coef_myo: 0.6642 - dice_coef_lv: 0.8220 - dice_coef_rv: 0.8124 - val_loss: -0.6875 - val_dice_coef_labels: 0.6994 - val_dice_coef_myo: 0.5931 - val_dice_coef_lv: 0.7697 - val_dice_coef_rv: 0.6984\n",
      "\n",
      "Epoch 00020: val_dice_coef_labels did not improve from 0.72375\n",
      "Epoch 21/150\n",
      "168/188 [=========================>....] - ETA: 12s - loss: -0.7750 - dice_coef_labels: 0.7839 - dice_coef_myo: 0.6575 - dice_coef_lv: 0.8143 - dice_coef_rv: 0.8194"
     ]
    }
   ],
   "source": [
    "initial_epoch = 0\n",
    "# training\n",
    "\n",
    "# start a new main process for this training to free gpu memory afterwards\n",
    "with tf.device(current_gpu):\n",
    "    logging.info('Fit model, start trainings process')\n",
    "    # fit model with trainingsgenerator\n",
    "    results = model.fit_generator(\n",
    "        generator=batch_generator,\n",
    "        epochs=config['EPOCHS'],\n",
    "        callbacks=get_callbacks(config, batch_generator, validation_generator),\n",
    "        steps_per_epoch = len(batch_generator),\n",
    "        validation_data=validation_generator,\n",
    "        initial_epoch=initial_epoch,\n",
    "        max_queue_size=30,\n",
    "        workers=8,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write trainings history to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(results.history)\n",
    "df_history = pd.DataFrame(results.history)\n",
    "\n",
    "df_history.to_csv(os.path.join('reports/history/3D_unet/', config['EXPERIMENT'] + '.csv'))\n",
    "df_history.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils_io import ensure_dir\n",
    "model_json = model.to_json()\n",
    "model_path = os.path.join('models/', config['EXPERIMENT'])\n",
    "ensure_dir(model_path)\n",
    "with open(os.path.join(model_path, 'model.json'), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "name = 'weights_e-{0}_val_loss-{1}.h5'.format(config['EXPERIMENT'], '01')\n",
    "model.save_weights(os.path.join(model_path, name))\n",
    "logging.info(\"Saved model to disk: {}\".format(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for all batches\n",
    "from medpy.metric.binary import hd, dc,jc,precision,recall\n",
    "import numpy as np\n",
    "gt_ = []\n",
    "pred_ = []\n",
    "img_ = []\n",
    "n_batches = len(test_generator)\n",
    "#n_batches = 2\n",
    "logging.info('load and predict {} batches'.format(n_batches))\n",
    "#with tf.device(current_gpu):\n",
    "#    pred = model.predict_generator(batch_generator, steps = len(batch_generator))\n",
    "#\n",
    "#gt_ = [gt_.extend(batch[1]) for batch in batch_generator]\n",
    "    \n",
    "\n",
    "\n",
    "for idx,batch in enumerate(test_generator):\n",
    "    if idx <= n_batches:\n",
    "        with tf.device(current_gpu):\n",
    "            img_.extend(batch[0])\n",
    "            pred_.extend(((model.predict_on_batch(batch[0]))>=0.5).astype(np.bool))\n",
    "        gt_.extend(batch[1])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# reshape\n",
    "gt = np.array(gt_)\n",
    "pred = np.array(pred_)\n",
    "\n",
    "logging.info('gt shape: {}'.format(gt.shape))\n",
    "logging.info('pred shape: {}'.format(pred.shape))\n",
    "del gt_\n",
    "del pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc medpy scores\n",
    "jaccard_coef = jc(pred, gt)\n",
    "dice_score = dc(pred, gt)\n",
    "precision_score = precision(pred, gt)\n",
    "recall_score = recall(pred, gt)\n",
    "\n",
    "logging.info('jac: {}'.format(jaccard_coef))\n",
    "logging.info('dice: {}'.format(dice_score))\n",
    "logging.info('prec: {}'.format(precision_score))\n",
    "logging.info('recall: {}'.format(recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc IOU per channel\n",
    "for c in range(pred.shape[-1]):\n",
    "    pred_ = pred[...,c]\n",
    "    gt_ = gt[...,c]\n",
    "    # calc medpy scores\n",
    "    jaccard_coef = jc(pred_, gt_)\n",
    "    dice_score = dc(pred_, gt_)\n",
    "    precision_score = precision(pred_, gt_)\n",
    "    recall_score = recall(pred_, gt_)\n",
    "\n",
    "    logging.info('jac: {}'.format(jaccard_coef))\n",
    "    logging.info('dice: {}'.format(dice_score))\n",
    "    logging.info('prec: {}'.format(precision_score))\n",
    "    logging.info('recall: {}'.format(recall_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.my_metrics import jaccard_coef, jaccard_coef_background, jaccard_coef_rv, jaccard_coef_lv, jaccard_coef_myo, bce_dice_iou_loss, weighted_categorical_crossentropy, cce_dice_loss, weighted_cce_dice_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc IOU per channel\n",
    "for c in range(pred.shape[-1]):\n",
    "    pred_ = pred[...,c]\n",
    "    gt_ = gt[...,c]\n",
    "    # calc medpy scores\n",
    "    jaccard_coef = jc(pred_, gt_)\n",
    "    dice_score = dc(pred_, gt_)\n",
    "    precision_score = precision(pred_, gt_)\n",
    "    recall_score = recall(pred_, gt_)\n",
    "\n",
    "    logging.info('jac: {}'.format(jaccard_coef))\n",
    "    logging.info('dice: {}'.format(dice_score))\n",
    "    logging.info('prec: {}'.format(precision_score))\n",
    "    logging.info('recall: {}'.format(recall_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.visualize import plot_3d_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_vol(img_[0], gt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_vol(img_[0], pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_vol(pred_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
