{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/data/git/cardio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2020-07-23 15:41:56,112 INFO -------------------- Start --------------------\n",
      "2020-07-23 15:41:56,115 INFO Working directory: /mnt/data/git/cardio.\n",
      "2020-07-23 15:41:56,115 INFO Log file: ./logs/Create 3D dataframe for voxelmorph.log\n",
      "2020-07-23 15:41:56,116 INFO Log level for console: INFO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.utils.utils_io.Console_and_file_logger at 0x7f4044c75710>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root \n",
    "change_wd_to_project_root()\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from src.utils.notebook_imports import *\n",
    "from src.utils.utils_io import Console_and_file_logger, ensure_dir\n",
    "from src.visualization.Visualize import plot_3d_vol, plot_4d_vol, plot_value_histogram, show_2D_or_3D\n",
    "from src.data.Dataset import get_metadata_maybe, filter_4d_vol, copy_meta_and_save, create_3d_volumes_from_4d_files, describe_sitk, describe_volume, describe_path, get_phase, is_patient_in_df, get_extremas\n",
    "Console_and_file_logger('Create 3D dataframe for voxelmorph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a 3D dataframe \n",
    "## Extract the t position from the filenames\n",
    "## normalize labeled timesteps to values between 0 and 5\n",
    "## Filter all patients with less than 5 labeled timesteps\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = sorted(glob.glob(os.path.join('data/raw/gcn_05_2020_ax_sax_86/AX_3D_ISO/', '*msk.nrrd')))\n",
    "len(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_from_columns(row):\n",
    "    \n",
    "    d = '{:02}'.format(int(row['DD']))\n",
    "    m = '{:02}'.format(int(row['MM']))\n",
    "    y = '{:04}'.format(int(row['YYYY']))\n",
    "    return '{}-{}-{}'.format(y, m, d)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_from_filename(f_name):\n",
    "    \n",
    "    import re\n",
    "    return re.findall(r'\\d\\d\\d\\d-\\d\\d-\\d\\d',f_name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volumes(f_name):\n",
    "    \"\"\"\n",
    "    expects a full filename for a nrrd mask\n",
    "    returns: a dict with the format: {label1 : size1, label2 : size2 ...}\n",
    "    volume size in ml^3, calculated with # voxels * spacing_x * spacing_y * spacing_z\n",
    "    \"\"\"\n",
    "    # load image, transform to nda\n",
    "    img = sitk.ReadImage(f_name)\n",
    "    nda = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # describe image, get dict of key, values\n",
    "    descr = describe_volume(f_name)\n",
    "    \n",
    "    # helper, calculate the volume in ml for one label\n",
    "    def calc_vol(index):\n",
    "        return (nda==index).sum() * descr.get('x-spacing',1) * descr.get('y-spacing',1) * descr.get('z-spacing',1)//1000\n",
    "    \n",
    "    # calc volume for each label in ml, return a dict with label-value: volume-size in ml\n",
    "    volumes = dict([(int(i),calc_vol(i)) for i in np.unique(nda)])\n",
    "    return volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract t from the filenames\n",
    "def extract_t_from_filename(f_name):\n",
    "    return int(os.path.basename(os.path.normpath(f_name)).split('__')[1].split('_')[0].replace('t',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_volume_dataframe(df, timesteps=5):\n",
    "    \"\"\"\n",
    "    Handle Nan fields, convert columns datatypes, calc t_norm, create img and mask file columns\n",
    "    drop all patients with labeled timesteps != 5\n",
    "    returns cleaned df\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    # handle nan\n",
    "    df = df.fillna(0)\n",
    "    df['file'] = img_path\n",
    "    df['patient'] = df.apply(lambda x : os.path.basename(x['file']).split('-')[1], axis=1)\n",
    "    try: # 4D files\n",
    "        df['t'] = df.apply(lambda x : os.path.basename(x['file']).split('_msk')[0].split('__')[1].replace('t', ''), axis=1)\n",
    "    except:\n",
    "        logging.info('try 3D pattern matching to etract t from the filenames')\n",
    "        df['t'] = df.file.apply(extract_t_from_filename)\n",
    "    # convert strings to int, for the 4 labels per patient and the timestep\n",
    "    df[[0, 1, 2, 3, 't']] = df[[0, 1, 2, 3, 't']].astype(np.int)\n",
    "    # convert patient id to string, make sure\n",
    "    df['patient'] = df['patient'].astype(str)\n",
    "    \n",
    "    # rename label columns names\n",
    "    cols = list(df.columns)\n",
    "    cols[0:4]  = ['background', 'rv', 'myo', 'lv'] \n",
    "    df.columns = cols\n",
    "    \n",
    "    # find all patients with labeled timesteps != 5\n",
    "    patients = len(df['patient'].unique())\n",
    "    print('found {} patients'.format(patients))\n",
    "    c = Counter(df.patient)\n",
    "    p_remove = [key for key,value in c.items() if value != timesteps]\n",
    "    print('patients with labeled timesteps != {}: \\n{}'.format(timesteps,p_remove))\n",
    "    df = df[~df['patient'].isin(p_remove)]\n",
    "    patients = len(df['patient'].unique())\n",
    "    print('found {} cleaned patients'.format(patients))\n",
    "    \n",
    "    # sort values by patient id and timesteps, \n",
    "    # create the normalized time columne, expecting every patient to have 5 timesteps (cleaned before)\n",
    "    df.sort_values(['patient', 't'], inplace=True)\n",
    "    patients = len(df['patient'].unique())\n",
    "    print('found {} patients'.format(patients))\n",
    "    temp = list(range(timesteps))\n",
    "    df['t_norm'] = temp * patients\n",
    "    \n",
    "    # rename columns to work the same way as the 2D dataframe\n",
    "    df['y_path'] = df['file']\n",
    "    df['x_path'] = df['file'].str.replace('msk', 'img')\n",
    "    df.columns = df.columns.str.replace('file', 'y_path')\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15095917dba4418fa9dc9cd6055aeef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='f_name', options=('data/raw/gcn_05_2020_ax_sax_86/AX_3D_ISO/0000-0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def calc_vol_size_interact(f_name=img_path):\n",
    "    \"\"\"\n",
    "    calculate the volume sizes for each label of a 3D volume\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(f_name)\n",
    "    img = sitk.ReadImage(f_name)\n",
    "    nda = sitk.GetArrayFromImage(img)\n",
    "\n",
    "    logging.info('Shape: {}'.format(img.GetSize()))\n",
    "    logging.info('Spacing: {}'.format(img.GetSpacing()))\n",
    "    logging.info('{}{}{}'.format('-'*10, ' Volumes sizes in voxels ', '-'*10))\n",
    "    logging.info('Backround voxels: {}'.format((nda==0).sum()))\n",
    "    logging.info('RV voxels: {}'.format((nda==1).sum()))\n",
    "    logging.info('Myo voxels: {}'.format((nda==2).sum()))\n",
    "    logging.info('LV voxels: {}'.format((nda==3).sum()))\n",
    "    \n",
    "    #bsa = Wurzel(Größe [cm] x Gewicht [kg] / 3600)\n",
    "    vols = get_volumes(f_name)\n",
    "    logging.info('{}{}{}'.format('-'*10, ' Volume sizes in ml ', '-'*10))\n",
    "    logging.info('Background in ml: {}'.format(vols[0]))\n",
    "    logging.info('RV in ml: {}'.format(vols[1]))\n",
    "    logging.info('MYO in ml: {}'.format(vols[2]))\n",
    "    logging.info('LV in ml: {}'.format(vols[3]))\n",
    "    #describe_sitk(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create volume dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df_volumes = pd.DataFrame([get_volumes(f) for f in img_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean volume dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 10:50:20,047 INFO try 3D pattern matching to etract t from the filenames\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-27f14b8b00c9>\u001b[0m in \u001b[0;36mclean_volume_dataframe\u001b[0;34m(df, timesteps)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 4D files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_msk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6486\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-27f14b8b00c9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 4D files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_msk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: ('list index out of range', 'occurred at index 0')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bc43e2cf631e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_volumes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_volume_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_volumes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# check for nan values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_volumes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_volumes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# show top of df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_volumes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-27f14b8b00c9>\u001b[0m in \u001b[0;36mclean_volume_dataframe\u001b[0;34m(df, timesteps)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'try 3D pattern matching to etract t from the filenames'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_t_from_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# convert strings to int, for the 4 labels per patient and the timestep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-84f871ffc315>\u001b[0m in \u001b[0;36mextract_t_from_filename\u001b[0;34m(f_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# extract t from the filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_t_from_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "df_volumes = clean_volume_dataframe(df_volumes)\n",
    "# check for nan values\n",
    "df_volumes[df_volumes.isnull().any(axis=1)]\n",
    "# show top of df\n",
    "df_volumes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dicom tag dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 21:18:44,202 INFO Using GCN dataset\n",
      "2019-11-27 21:18:44,203 INFO search in subfolders ...\n",
      "2019-11-27 21:18:44,210 INFO describing path: data/raw/GCN/3D/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_dicom</th>\n",
       "      <th>patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>04NEJQU7</td>\n",
       "      <td>04NEJQUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>04NEJQU7</td>\n",
       "      <td>04NEJQUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>04NEJQU7</td>\n",
       "      <td>04NEJQUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>04NEJQU7</td>\n",
       "      <td>04NEJQUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>04NEJQU7</td>\n",
       "      <td>04NEJQUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>D4PXE75F</td>\n",
       "      <td>KW4MJ3XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>D4PXE75F</td>\n",
       "      <td>KW4MJ3XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>D4PXE75F</td>\n",
       "      <td>KW4MJ3XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>D4PXE75F</td>\n",
       "      <td>KW4MJ3XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>D4PXE75F</td>\n",
       "      <td>KW4MJ3XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>PEXM9GE</td>\n",
       "      <td>PEXM9GEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>PEXM9GE</td>\n",
       "      <td>PEXM9GEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>PEXM9GE</td>\n",
       "      <td>PEXM9GEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>PEXM9GE</td>\n",
       "      <td>PEXM9GEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>PEXM9GE</td>\n",
       "      <td>PEXM9GEK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_dicom   patient\n",
       "135  04NEJQU7      04NEJQUZ\n",
       "136  04NEJQU7      04NEJQUZ\n",
       "137  04NEJQU7      04NEJQUZ\n",
       "138  04NEJQU7      04NEJQUZ\n",
       "139  04NEJQU7      04NEJQUZ\n",
       "711  D4PXE75F      KW4MJ3XX\n",
       "712  D4PXE75F      KW4MJ3XX\n",
       "713  D4PXE75F      KW4MJ3XX\n",
       "714  D4PXE75F      KW4MJ3XX\n",
       "715  D4PXE75F      KW4MJ3XX\n",
       "788  PEXM9GE       PEXM9GEK\n",
       "789  PEXM9GE       PEXM9GEK\n",
       "790  PEXM9GE       PEXM9GEK\n",
       "791  PEXM9GE       PEXM9GEK\n",
       "792  PEXM9GE       PEXM9GEK"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will search for subdirectories if no partterns match in the parent folder\n",
    "# filepatterns are defined by the dataset parameter\n",
    "df2 = describe_path('data/raw/GCN/3D/', dataset='GCN', plot_histogram=False)\n",
    "\n",
    "# drop masks as own rows, they will be in the same row as the image\n",
    "df2 = df2[df2['image'] == True]\n",
    "\n",
    "# create the same patient columns as in the volume df\n",
    "df2['patient_dicom'] = df2.PatientID\n",
    "df2['x_path'] = df2['f_name']\n",
    "\n",
    "# same files have different patient IDs in the dicom tag than in the filename, use the ids from the filesnames, \n",
    "# they should be correct according to manual research in metadata.xls and circle\n",
    "df2['patient'] = df2.apply(lambda x : os.path.basename(x['x_path']).split('-')[1], axis=1)\n",
    "df2[df2.apply(lambda x : x['patient_dicom'] != x['patient'], axis=1)][['patient_dicom', 'patient']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean dicom tag dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 209 patients\n",
      "patients with labeled timesteps != 5: \n",
      "['E2HMADJ3', 'F0QP6ZJR', 'GYMP57R6', 'L1ACV3UE', 'RNMQ8VH6', 'TX0L610P']\n",
      "found 209 cleaned patients\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1015, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1015, 48)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all patients in the second dataframe with labeled timesteps != 5\n",
    "patients = len(df2['patient'].unique())\n",
    "print('found {} patients'.format(patients))\n",
    "from collections import Counter\n",
    "c = Counter(df2.patient)\n",
    "p_remove = [key for key,value in c.items() if value != 5]\n",
    "print('patients with labeled timesteps != 5: \\n{}'.format(p_remove))\n",
    "df2 = df2[~df2['patient'].isin(p_remove)]\n",
    "print('found {} cleaned patients'.format(patients))\n",
    "\n",
    "df_volumes.shape\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if both dataframes have the same ids\n",
    "set(df_volumes.patient.unique()) - set(df2.patient.unique())\n",
    "set(df2.patient.unique()) - set(df_volumes.patient.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if both dataframes have the same x_path / unique key\n",
    "set(df_volumes['x_path'].unique()) - set(df2['x_path'].unique())\n",
    "set(df2['x_path'].unique()) - set(df_volumes['x_path'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge volume dataframe and dicom metadata dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1015, 57)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge by x_path, which is unique for the 3d files, patient id is not unique, because we have 5 files per patient\n",
    "df = pd.merge(df_volumes, df2, on='x_path')\n",
    "len(df_volumes.patient.unique())\n",
    "df.shape\n",
    "# check if all patient ids have matched\n",
    "all(df.patient_x == df.patient_y)\n",
    "# delete double columns\n",
    "df['patient'] = df['patient_x']\n",
    "df = df.drop('patient_y', axis =1)\n",
    "df = df.drop('patient_x', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "df.to_csv('reports/vae/3d_gcn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the Excel metadata and merge into the existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the joined metadata xls\n",
    "df_meta = pd.read_excel('data/external/metadata_joined.xls')\n",
    "df_meta['patient'] = df_meta['PID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if all patient ids of our current df are in this excel sheet\n",
    "set(df.patient) - set(df_meta.patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015, 145)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge and save to disk\n",
    "df = pd.merge(df, df_meta, on='patient', how='left')\n",
    "df.shape\n",
    "df.to_csv('reports/vae/3d_gcn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Excel with corrected outcome sheet and merge into existing one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in corrected xls sheet, dwefine the patient columns, delete PID column\n",
    "df_outcome_corrected = pd.read_excel('data/external/Outcome_TOF_GCN_HL_15072018_for Tarique and Sven.xlsx')\n",
    "df_outcome_corrected['patient'] = df_outcome_corrected['PID']\n",
    "df_outcome_corrected = df_outcome_corrected.drop('PID', axis=1)\n",
    "# minor cleaning is neccessary because the excel sheet had spaces in pid and outcome column\n",
    "df_outcome_corrected['patient'] = df_outcome_corrected['patient'].apply(lambda x : x.replace(' ', ''))\n",
    "df_outcome_corrected['Outcome y/n'] = df_outcome_corrected['Outcome y/n'].apply(lambda x : str(x).replace(' ', ''))\n",
    "\n",
    "# check if all patient ids of our current df are in this excel sheet\n",
    "len(set(df.patient) - set(df_outcome_corrected.patient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'y': 25, 'n': 341, 'nan': 44})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_outcome_corrected['Outcome y/n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['n', 'y', nan, '?'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# currrent outcome column values\n",
    "df['Outcome y/n'].unique()\n",
    "# drop all double columns, keep the columns from the corrected sheet\n",
    "df = df.drop(['Outcome y/n', 'Date PVR', 'PVR nach MRT y/n', 'Date Outcome'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015, 147)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['background', 'rv', 'myo', 'lv', 'y_path', 't', 't_norm', 'y_path',\n",
       "       'x_path', '.50-quantle',\n",
       "       ...\n",
       "       'Year of the redo surgeries Jahr der Redos',\n",
       "       'redo after V1 RE OP nach V1',\n",
       "       'surgery date while enrolled in study OP Datum während Studie',\n",
       "       'tricuspid insufficiency grades 0-4 tricinsuf', 'Last Report Date_y',\n",
       "       'PVR nach MRT y/n', 'Date PVR', 'Outcome y/n', 'Type Outcome_y',\n",
       "       'Date Outcome'],\n",
       "      dtype='object', length=147)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, df_outcome_corrected, on='patient', how='left')\n",
    "df.shape\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'n': 855, 'y': 60, 'nan': 100})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df['Outcome y/n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe of 3d files to disk\n",
    "df.to_csv('reports/vae/3d_gcn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Excel with corrected phases, merge into existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timesteps = pd.read_excel('data/external/GCN Dataset_timesteps.xlsx')\n",
    "\n",
    "# clean\n",
    "df_timesteps['Contoured?'] = df_timesteps['Contoured?'].str.replace(\"Y \", \"y\").replace('Y', 'y').replace('N ', 'N')\n",
    "df_timesteps['patient'] = df_timesteps['ID']\n",
    "df_timesteps = df_timesteps.drop('ID', axis=1, errors='ignore')\n",
    "\n",
    "# we only need the rows with exported xml files\n",
    "df_timesteps = df_timesteps[df_timesteps['XML exported']== 'Y' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a unique identifier to map them\n",
    "df_timesteps['patient_unique'] = df_timesteps['patient'] + '-' + df_timesteps.apply(get_date_from_columns, axis=1)\n",
    "df['patient_unique'] = df['patient'] + '-' + df['x_path'].apply(get_date_from_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if all patient ids of our current df are in this excel sheet\n",
    "set(df.patient) - set(df_timesteps.patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study #</th>\n",
       "      <th>YYYY</th>\n",
       "      <th>MM</th>\n",
       "      <th>DD</th>\n",
       "      <th>Loaded to circle?</th>\n",
       "      <th>Short Axis Stack Present</th>\n",
       "      <th>SA Stack Usable? Y or why not</th>\n",
       "      <th>Axial stack present?</th>\n",
       "      <th>Contoured?</th>\n",
       "      <th>Contoured By?</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "      <th>Unnamed: 31</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>patient</th>\n",
       "      <th>patient_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>y</td>\n",
       "      <td>AP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04NEJQUZ</td>\n",
       "      <td>04NEJQUZ-2007-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>y</td>\n",
       "      <td>AP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0AE4R74L</td>\n",
       "      <td>0AE4R74L-1900-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>y</td>\n",
       "      <td>AP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0HQQW4ZN</td>\n",
       "      <td>0HQQW4ZN-2007-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>y</td>\n",
       "      <td>AP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0PTV75MP</td>\n",
       "      <td>0PTV75MP-2005-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>y</td>\n",
       "      <td>SP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0RPELLU8</td>\n",
       "      <td>0RPELLU8-2007-02-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Study #    YYYY   MM    DD Loaded to circle? Short Axis Stack Present  \\\n",
       "2  3       2007.0  3.0  13.0  Y                 Y                         \n",
       "5  6       1900.0  1.0  1.0   Y                 Y                         \n",
       "6  7       2007.0  5.0  23.0  Y                 Y                         \n",
       "7  8       2005.0  6.0  27.0  Y                 Y                         \n",
       "9  10      2007.0  2.0  13.0  Y                 Y                         \n",
       "\n",
       "  SA Stack Usable? Y or why not Axial stack present? Contoured? Contoured By?  \\\n",
       "2  Y                             Y                    y          AP             \n",
       "5  Y                             N                    y          AP             \n",
       "6  Y                             Y                    y          AP             \n",
       "7  Y                             N                    y          AP             \n",
       "9  Y                             Y                    y          SP             \n",
       "\n",
       "   ... Unnamed: 25 Unnamed: 26 Unnamed: 27  Unnamed: 28  Unnamed: 29  \\\n",
       "2  ... NaN         NaN         NaN         NaN           NaN           \n",
       "5  ... NaN         NaN         NaN         NaN           NaN           \n",
       "6  ... NaN         NaN         NaN         NaN           NaN           \n",
       "7  ... NaN         NaN         NaN         NaN           NaN           \n",
       "9  ... NaN         NaN         NaN         NaN           NaN           \n",
       "\n",
       "   Unnamed: 30  Unnamed: 31  Unnamed: 32   patient       patient_unique  \n",
       "2 NaN          NaN           NaN          04NEJQUZ  04NEJQUZ-2007-03-13  \n",
       "5 NaN          NaN           NaN          0AE4R74L  0AE4R74L-1900-01-01  \n",
       "6 NaN          NaN           NaN          0HQQW4ZN  0HQQW4ZN-2007-05-23  \n",
       "7 NaN          NaN           NaN          0PTV75MP  0PTV75MP-2005-06-27  \n",
       "9 NaN          NaN           NaN          0RPELLU8  0RPELLU8-2007-02-13  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_timesteps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'MS': 203, 'ES': 203, 'MD': 203, 'PF': 203, 'ED': 203})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the phases for all matched patients\n",
    "temp = df.apply(get_phase, args=(df_timesteps, 'patient_unique'), axis=1)\n",
    "c = Counter(temp)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_unique</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [patient_unique, t]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1015, 149)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add phases to current dataframe\n",
    "df['phase'] = temp\n",
    "# transform to categorical values with ordering\n",
    "df['phase'] = pd.Categorical(df.phase, \n",
    "                      categories=['ED','MS','ES','PF','MD'],\n",
    "                      ordered=True)\n",
    "# check if there are timesteps we cant match to any phase\n",
    "df[df['phase'] == 'no_phase_fits'][['patient_unique', 't']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('reports/vae/3d_gcn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a motiongenerator from dataframe --> train voxelmorph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 16:36:40,672 INFO Create DataGenerator\n",
      "2019-11-27 16:36:40,674 INFO Datagenerator created with: \n",
      " shape: [16, 224, 224]\n",
      " batchsize: 2\n",
      " Scaler: MinMax\n",
      " Images: 812 \n",
      " Augment_grid: False \n",
      " Thread workers: 2\n",
      "2019-11-27 16:36:40,675 INFO No augmentation\n"
     ]
    }
   ],
   "source": [
    "from src.data.generators import MotionDataGenerator\n",
    "config = dict()\n",
    "config['BATCHSIZE'] = 2\n",
    "config['ARCHITECTURE'] = '3D' # 2D\n",
    "config['DIM'] = [16, 224, 224] # [16,244,244]\n",
    "config['SPACING'] = [7, 1.0,1.0] # used by sitk, opposite order than numpy or tensorflow!\n",
    "\n",
    "# create a list of z slices with t_n and t_n+1 , not possible for the last timestep\n",
    "t_1 = np.concatenate([df[df['t_norm'] == 0]['x_path'].values, df[df['t_norm'] == 1]['x_path'].values, df[df['t_norm'] == 2]['x_path'].values, df[df['t_norm'] == 3]['x_path'].values])\n",
    "t_2 = np.concatenate([df[df['t_norm'] == 1]['x_path'].values, df[df['t_norm'] == 2]['x_path'].values, df[df['t_norm'] == 3]['x_path'].values, df[df['t_norm'] == 4]['x_path'].values])\n",
    "batch_generator = MotionDataGenerator(t_1, t_2, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_1)\n",
    "len(t_2)\n",
    "len(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "from src.visualization.visualize import show_2D_or_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c06177aad7440e58ad8f48e88046411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=203, description='batch', max=406), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select batch generator output\n",
    "x = ''\n",
    "y = ''\n",
    "@interact\n",
    "def select_batch(batch = (0,len(batch_generator), 1)):\n",
    "    global x, y\n",
    "    input_ , output_ = batch_generator.__getitem__(batch)\n",
    "    x = input_[0]\n",
    "    y = output_[0]\n",
    "    logging.info(x.shape)\n",
    "    logging.info(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df197028ce5940c5a5174d0724260e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='im', max=1), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def select_image_in_batch(im = (0,x.shape[0]- 1, 1)):\n",
    "    \n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    show_2D_or_3D(x[im])\n",
    "    plt.show()\n",
    "    show_2D_or_3D(y[im])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataframe from all ACDC 3D volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw images\n",
    "images = sorted(glob.glob(os.path.join('data/raw/ACDC/original/all/**/','*[0-9][0-9].nii.gz'), recursive=True))\n",
    "masks = sorted(glob.glob(os.path.join('data/raw/ACDC/original/all/**/','*_gt.nii.gz'), recursive=True))\n",
    "len(images)\n",
    "len(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patient001'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(images[0]).split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 15:42:33,601 INFO Using acdc dataset\n",
      "2020-07-23 15:42:33,609 INFO describing path: data/raw/ACDC/original/all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200 entries, 0 to 199\n",
      "Data columns (total 47 columns):\n",
      ".50-quantle                200 non-null float64\n",
      ".75-quantile               200 non-null float64\n",
      ".99-quantile               200 non-null float64\n",
      "CardiacNumberOfImages      200 non-null object\n",
      "InstitutionAddress         200 non-null object\n",
      "InstitutionName            200 non-null object\n",
      "LargestImagePixelValue     200 non-null int64\n",
      "MagneticFieldStrength      200 non-null object\n",
      "Manufacturer               200 non-null object\n",
      "ManufacturerModelName      200 non-null object\n",
      "PatientAge                 200 non-null object\n",
      "PatientBirthDate           200 non-null object\n",
      "PatientID                  200 non-null object\n",
      "PatientPosition            200 non-null object\n",
      "PatientSex                 200 non-null object\n",
      "PatientSize                200 non-null object\n",
      "PatientWeight              200 non-null object\n",
      "ReferringPhysicianName     200 non-null object\n",
      "SeriesDescription          200 non-null object\n",
      "SliceLocation              200 non-null object\n",
      "SliceThickness             200 non-null object\n",
      "SmallestImagePixelValue    200 non-null int64\n",
      "StudyDescription           200 non-null object\n",
      "column                     200 non-null object\n",
      "dimension                  200 non-null int64\n",
      "f_name                     200 non-null object\n",
      "image                      200 non-null bool\n",
      "max                        200 non-null float64\n",
      "mean                       200 non-null float64\n",
      "min                        200 non-null float64\n",
      "row                        200 non-null object\n",
      "seriesinstanceuid          200 non-null object\n",
      "shape                      200 non-null object\n",
      "sizes                      200 non-null object\n",
      "slices                     200 non-null int64\n",
      "spacing                    200 non-null object\n",
      "studyinstanceuid           200 non-null object\n",
      "t-axis                     200 non-null int64\n",
      "t-spacing                  200 non-null int64\n",
      "x-axis                     200 non-null int64\n",
      "x-spacing                  200 non-null float64\n",
      "y-axis                     200 non-null int64\n",
      "y-spacing                  200 non-null float64\n",
      "z-axis                     200 non-null int64\n",
      "z-spacing                  200 non-null float64\n",
      "patient                    200 non-null object\n",
      "x_path                     200 non-null object\n",
      "dtypes: bool(1), float64(9), int64(9), object(28)\n",
      "memory usage: 73.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# images & image stats\n",
    "from src.data.Dataset import get_acdc_dataset_as_df, create_acdc_dataframe_for_cv\n",
    "df1 = describe_path('data/raw/ACDC/original/all', dataset='ACDC', plot_histogram=False)\n",
    "df1 = df1[df1['image'] == True]\n",
    "df1['patient'] = df1['f_name'].apply(lambda x : os.path.basename(x).split('.')[0].split('_')[0])\n",
    "df1['x_path'] = df1['f_name']\n",
    "df1.head()\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 16:10:21,542 INFO -------------------- Start --------------------\n",
      "2020-07-23 16:10:21,542 INFO Working directory: /mnt/data/git/cardio.\n",
      "2020-07-23 16:10:21,542 INFO Log file: ./logs/prediction3D.log\n",
      "2020-07-23 16:10:21,543 INFO Log level for console: DEBUG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.utils.utils_io.Console_and_file_logger at 0x7f3fb3276390>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Console_and_file_logger('prediction3D', logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 16:13:21,612 INFO Found: 0 files in data/raw/ACDC/2D/all/\n",
      "2020-07-23 16:13:22,074 INFO Created a dataframe with shape: (600, 5)\n",
      "2020-07-23 16:13:22,077 DEBUG 20 Patients found for pathology: DCM\n",
      "2020-07-23 16:13:22,077 DEBUG Fold: 0, Pathology: DCM train: ['patient003', 'patient004', 'patient005', 'patient006', 'patient007', 'patient008', 'patient010', 'patient011', 'patient012', 'patient013', 'patient014', 'patient015', 'patient017', 'patient019', 'patient020']\n",
      "2020-07-23 16:13:22,077 DEBUG Fold: 0, Pathology: DCM, test: ['patient001', 'patient002', 'patient009', 'patient016', 'patient018']\n",
      "2020-07-23 16:13:22,087 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,088 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,089 DEBUG Fold: 1, Pathology: DCM train: ['patient001', 'patient002', 'patient003', 'patient005', 'patient007', 'patient008', 'patient009', 'patient010', 'patient011', 'patient013', 'patient014', 'patient015', 'patient016', 'patient018', 'patient020']\n",
      "2020-07-23 16:13:22,090 DEBUG Fold: 1, Pathology: DCM, test: ['patient004', 'patient006', 'patient012', 'patient017', 'patient019']\n",
      "2020-07-23 16:13:22,100 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,100 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,102 DEBUG Fold: 2, Pathology: DCM train: ['patient001', 'patient002', 'patient004', 'patient006', 'patient007', 'patient008', 'patient009', 'patient011', 'patient012', 'patient013', 'patient015', 'patient016', 'patient017', 'patient018', 'patient019']\n",
      "2020-07-23 16:13:22,102 DEBUG Fold: 2, Pathology: DCM, test: ['patient003', 'patient005', 'patient010', 'patient014', 'patient020']\n",
      "2020-07-23 16:13:22,112 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,112 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,114 DEBUG Fold: 3, Pathology: DCM train: ['patient001', 'patient002', 'patient003', 'patient004', 'patient005', 'patient006', 'patient009', 'patient010', 'patient012', 'patient014', 'patient016', 'patient017', 'patient018', 'patient019', 'patient020']\n",
      "2020-07-23 16:13:22,114 DEBUG Fold: 3, Pathology: DCM, test: ['patient007', 'patient008', 'patient011', 'patient013', 'patient015']\n",
      "2020-07-23 16:13:22,123 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,124 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,126 DEBUG 20 Patients found for pathology: HCM\n",
      "2020-07-23 16:13:22,127 DEBUG Fold: 0, Pathology: HCM train: ['patient023', 'patient024', 'patient025', 'patient026', 'patient027', 'patient028', 'patient030', 'patient031', 'patient032', 'patient033', 'patient034', 'patient035', 'patient037', 'patient039', 'patient040']\n",
      "2020-07-23 16:13:22,127 DEBUG Fold: 0, Pathology: HCM, test: ['patient021', 'patient022', 'patient029', 'patient036', 'patient038']\n",
      "2020-07-23 16:13:22,136 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,137 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,138 DEBUG Fold: 1, Pathology: HCM train: ['patient021', 'patient022', 'patient023', 'patient025', 'patient027', 'patient028', 'patient029', 'patient030', 'patient031', 'patient033', 'patient034', 'patient035', 'patient036', 'patient038', 'patient040']\n",
      "2020-07-23 16:13:22,139 DEBUG Fold: 1, Pathology: HCM, test: ['patient024', 'patient026', 'patient032', 'patient037', 'patient039']\n",
      "2020-07-23 16:13:22,148 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,148 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,150 DEBUG Fold: 2, Pathology: HCM train: ['patient021', 'patient022', 'patient024', 'patient026', 'patient027', 'patient028', 'patient029', 'patient031', 'patient032', 'patient033', 'patient035', 'patient036', 'patient037', 'patient038', 'patient039']\n",
      "2020-07-23 16:13:22,150 DEBUG Fold: 2, Pathology: HCM, test: ['patient023', 'patient025', 'patient030', 'patient034', 'patient040']\n",
      "2020-07-23 16:13:22,160 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,160 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,162 DEBUG Fold: 3, Pathology: HCM train: ['patient021', 'patient022', 'patient023', 'patient024', 'patient025', 'patient026', 'patient029', 'patient030', 'patient032', 'patient034', 'patient036', 'patient037', 'patient038', 'patient039', 'patient040']\n",
      "2020-07-23 16:13:22,162 DEBUG Fold: 3, Pathology: HCM, test: ['patient027', 'patient028', 'patient031', 'patient033', 'patient035']\n",
      "2020-07-23 16:13:22,172 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,172 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,175 DEBUG 20 Patients found for pathology: MINF\n",
      "2020-07-23 16:13:22,175 DEBUG Fold: 0, Pathology: MINF train: ['patient043', 'patient044', 'patient045', 'patient046', 'patient047', 'patient048', 'patient050', 'patient051', 'patient052', 'patient053', 'patient054', 'patient055', 'patient057', 'patient059', 'patient060']\n",
      "2020-07-23 16:13:22,176 DEBUG Fold: 0, Pathology: MINF, test: ['patient041', 'patient042', 'patient049', 'patient056', 'patient058']\n",
      "2020-07-23 16:13:22,185 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,186 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,188 DEBUG Fold: 1, Pathology: MINF train: ['patient041', 'patient042', 'patient043', 'patient045', 'patient047', 'patient048', 'patient049', 'patient050', 'patient051', 'patient053', 'patient054', 'patient055', 'patient056', 'patient058', 'patient060']\n",
      "2020-07-23 16:13:22,188 DEBUG Fold: 1, Pathology: MINF, test: ['patient044', 'patient046', 'patient052', 'patient057', 'patient059']\n",
      "2020-07-23 16:13:22,197 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,198 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,200 DEBUG Fold: 2, Pathology: MINF train: ['patient041', 'patient042', 'patient044', 'patient046', 'patient047', 'patient048', 'patient049', 'patient051', 'patient052', 'patient053', 'patient055', 'patient056', 'patient057', 'patient058', 'patient059']\n",
      "2020-07-23 16:13:22,200 DEBUG Fold: 2, Pathology: MINF, test: ['patient043', 'patient045', 'patient050', 'patient054', 'patient060']\n",
      "2020-07-23 16:13:22,209 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,210 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,212 DEBUG Fold: 3, Pathology: MINF train: ['patient041', 'patient042', 'patient043', 'patient044', 'patient045', 'patient046', 'patient049', 'patient050', 'patient052', 'patient054', 'patient056', 'patient057', 'patient058', 'patient059', 'patient060']\n",
      "2020-07-23 16:13:22,212 DEBUG Fold: 3, Pathology: MINF, test: ['patient047', 'patient048', 'patient051', 'patient053', 'patient055']\n",
      "2020-07-23 16:13:22,222 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,223 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,225 DEBUG 20 Patients found for pathology: NOR\n",
      "2020-07-23 16:13:22,225 DEBUG Fold: 0, Pathology: NOR train: ['patient063', 'patient064', 'patient065', 'patient066', 'patient067', 'patient068', 'patient070', 'patient071', 'patient072', 'patient073', 'patient074', 'patient075', 'patient077', 'patient079', 'patient080']\n",
      "2020-07-23 16:13:22,226 DEBUG Fold: 0, Pathology: NOR, test: ['patient061', 'patient062', 'patient069', 'patient076', 'patient078']\n",
      "2020-07-23 16:13:22,235 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,236 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,237 DEBUG Fold: 1, Pathology: NOR train: ['patient061', 'patient062', 'patient063', 'patient065', 'patient067', 'patient068', 'patient069', 'patient070', 'patient071', 'patient073', 'patient074', 'patient075', 'patient076', 'patient078', 'patient080']\n",
      "2020-07-23 16:13:22,238 DEBUG Fold: 1, Pathology: NOR, test: ['patient064', 'patient066', 'patient072', 'patient077', 'patient079']\n",
      "2020-07-23 16:13:22,248 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,248 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,250 DEBUG Fold: 2, Pathology: NOR train: ['patient061', 'patient062', 'patient064', 'patient066', 'patient067', 'patient068', 'patient069', 'patient071', 'patient072', 'patient073', 'patient075', 'patient076', 'patient077', 'patient078', 'patient079']\n",
      "2020-07-23 16:13:22,251 DEBUG Fold: 2, Pathology: NOR, test: ['patient063', 'patient065', 'patient070', 'patient074', 'patient080']\n",
      "2020-07-23 16:13:22,260 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,261 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,262 DEBUG Fold: 3, Pathology: NOR train: ['patient061', 'patient062', 'patient063', 'patient064', 'patient065', 'patient066', 'patient069', 'patient070', 'patient072', 'patient074', 'patient076', 'patient077', 'patient078', 'patient079', 'patient080']\n",
      "2020-07-23 16:13:22,263 DEBUG Fold: 3, Pathology: NOR, test: ['patient067', 'patient068', 'patient071', 'patient073', 'patient075']\n",
      "2020-07-23 16:13:22,273 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,273 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,275 DEBUG 20 Patients found for pathology: RV\n",
      "2020-07-23 16:13:22,276 DEBUG Fold: 0, Pathology: RV train: ['patient083', 'patient084', 'patient085', 'patient086', 'patient087', 'patient088', 'patient090', 'patient091', 'patient092', 'patient093', 'patient094', 'patient095', 'patient097', 'patient099', 'patient100']\n",
      "2020-07-23 16:13:22,276 DEBUG Fold: 0, Pathology: RV, test: ['patient081', 'patient082', 'patient089', 'patient096', 'patient098']\n",
      "2020-07-23 16:13:22,286 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,286 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,288 DEBUG Fold: 1, Pathology: RV train: ['patient081', 'patient082', 'patient083', 'patient085', 'patient087', 'patient088', 'patient089', 'patient090', 'patient091', 'patient093', 'patient094', 'patient095', 'patient096', 'patient098', 'patient100']\n",
      "2020-07-23 16:13:22,289 DEBUG Fold: 1, Pathology: RV, test: ['patient084', 'patient086', 'patient092', 'patient097', 'patient099']\n",
      "2020-07-23 16:13:22,299 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,299 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,301 DEBUG Fold: 2, Pathology: RV train: ['patient081', 'patient082', 'patient084', 'patient086', 'patient087', 'patient088', 'patient089', 'patient091', 'patient092', 'patient093', 'patient095', 'patient096', 'patient097', 'patient098', 'patient099']\n",
      "2020-07-23 16:13:22,301 DEBUG Fold: 2, Pathology: RV, test: ['patient083', 'patient085', 'patient090', 'patient094', 'patient100']\n",
      "2020-07-23 16:13:22,311 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,311 DEBUG Files x_test: 0\n",
      "2020-07-23 16:13:22,313 DEBUG Fold: 3, Pathology: RV train: ['patient081', 'patient082', 'patient083', 'patient084', 'patient085', 'patient086', 'patient089', 'patient090', 'patient092', 'patient094', 'patient096', 'patient097', 'patient098', 'patient099', 'patient100']\n",
      "2020-07-23 16:13:22,313 DEBUG Fold: 3, Pathology: RV, test: ['patient087', 'patient088', 'patient091', 'patient093', 'patient095']\n",
      "2020-07-23 16:13:22,323 DEBUG Files x_train: 0\n",
      "2020-07-23 16:13:22,324 DEBUG Files x_test: 0\n"
     ]
    }
   ],
   "source": [
    "# pathology data\n",
    "df2 = create_acdc_dataframe_for_cv(path_to_data='data/raw/ACDC/2D/all/', img_pattern='*frame[0-9][0-9].nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = get_acdc_dataset_as_df('data/raw/ACDC/original/all/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>modality</th>\n",
       "      <th>pathology</th>\n",
       "      <th>patient</th>\n",
       "      <th>x_path</th>\n",
       "      <th>y_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fold, modality, pathology, patient, x_path, y_path]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 15:43:13,611 INFO Found: 200 files in data/raw/ACDC/original/all/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 6 columns):\n",
      "fold         0 non-null object\n",
      "modality     0 non-null object\n",
      "pathology    0 non-null object\n",
      "patient      0 non-null object\n",
      "x_path       0 non-null object\n",
      "y_path       0 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df2 = df2[df2['fold'] == 0]\n",
    "df2['y_path'] = df2['y_path'].apply(lambda x : x.replace('.nii.gz', '_gt.nii.gz'))\n",
    "df2.head()\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge both datasets by patient id\n",
    "df = pd.merge(df1, df2, on='x_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.50-quantle</th>\n",
       "      <th>.75-quantile</th>\n",
       "      <th>.99-quantile</th>\n",
       "      <th>LargestImagePixelValue</th>\n",
       "      <th>SmallestImagePixelValue</th>\n",
       "      <th>dimension</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>slices</th>\n",
       "      <th>t-axis</th>\n",
       "      <th>t-spacing</th>\n",
       "      <th>x-axis</th>\n",
       "      <th>x-spacing</th>\n",
       "      <th>y-axis</th>\n",
       "      <th>y-spacing</th>\n",
       "      <th>z-axis</th>\n",
       "      <th>z-spacing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47.430000</td>\n",
       "      <td>94.85000</td>\n",
       "      <td>269.293250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>601.265000</td>\n",
       "      <td>67.788950</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>9.510000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.120000</td>\n",
       "      <td>1.511710</td>\n",
       "      <td>247.140000</td>\n",
       "      <td>1.511710</td>\n",
       "      <td>9.510000</td>\n",
       "      <td>9.335000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.135717</td>\n",
       "      <td>56.16413</td>\n",
       "      <td>196.074704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>746.262436</td>\n",
       "      <td>35.019502</td>\n",
       "      <td>9.337879</td>\n",
       "      <td>2.395536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.958674</td>\n",
       "      <td>0.185097</td>\n",
       "      <td>39.343614</td>\n",
       "      <td>0.185097</td>\n",
       "      <td>2.395536</td>\n",
       "      <td>1.668591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>52.00000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>42.639797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>162.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>51.929940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>1.367190</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>1.367190</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>75.50000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>56.387890</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>88.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>65.481128</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>362.00000</td>\n",
       "      <td>1176.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4031.000000</td>\n",
       "      <td>242.061382</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>1.919640</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>1.919640</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       .50-quantle  .75-quantile  .99-quantile  LargestImagePixelValue  \\\n",
       "count  200.000000   200.00000     200.000000    200.0                    \n",
       "mean   47.430000    94.85000      269.293250    0.0                      \n",
       "std    23.135717    56.16413      196.074704    0.0                      \n",
       "min    19.000000    52.00000      135.000000    0.0                      \n",
       "25%    36.000000    68.00000      162.750000    0.0                      \n",
       "50%    43.000000    75.50000      216.000000    0.0                      \n",
       "75%    50.000000    88.00000      296.000000    0.0                      \n",
       "max    180.000000   362.00000     1176.000000   0.0                      \n",
       "\n",
       "       SmallestImagePixelValue  dimension          max        mean  \\\n",
       "count  200.0                    200.0      200.000000   200.000000   \n",
       "mean   100.0                    3.0        601.265000   67.788950    \n",
       "std    0.0                      0.0        746.262436   35.019502    \n",
       "min    100.0                    3.0        184.000000   42.639797    \n",
       "25%    100.0                    3.0        255.000000   51.929940    \n",
       "50%    100.0                    3.0        255.000000   56.387890    \n",
       "75%    100.0                    3.0        559.000000   65.481128    \n",
       "max    100.0                    3.0        4031.000000  242.061382   \n",
       "\n",
       "              min      slices  t-axis  t-spacing      x-axis   x-spacing  \\\n",
       "count  200.000000  200.000000  200.0   200.0      200.000000  200.000000   \n",
       "mean   8.500000    9.510000    0.0     0.0        220.120000  1.511710     \n",
       "std    9.337879    2.395536    0.0     0.0        33.958674   0.185097     \n",
       "min    0.000000    6.000000    0.0     0.0        154.000000  0.703125     \n",
       "25%    0.000000    8.000000    0.0     0.0        208.000000  1.367190     \n",
       "50%    5.500000    9.000000    0.0     0.0        216.000000  1.562500     \n",
       "75%    15.000000   10.000000   0.0     0.0        234.000000  1.562500     \n",
       "max    32.000000   18.000000   0.0     0.0        428.000000  1.919640     \n",
       "\n",
       "           y-axis   y-spacing      z-axis   z-spacing  \n",
       "count  200.000000  200.000000  200.000000  200.000000  \n",
       "mean   247.140000  1.511710    9.510000    9.335000    \n",
       "std    39.343614   0.185097    2.395536    1.668591    \n",
       "min    154.000000  0.703125    6.000000    5.000000    \n",
       "25%    224.000000  1.367190    8.000000    10.000000   \n",
       "50%    256.000000  1.562500    9.000000    10.000000   \n",
       "75%    256.000000  1.562500    10.000000   10.000000   \n",
       "max    512.000000  1.919640    18.000000   10.000000   "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(200, 52)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('reports/vae/3d_acdc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
