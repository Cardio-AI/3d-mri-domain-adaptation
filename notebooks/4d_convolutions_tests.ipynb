{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD CUSTOM LAMBDA Layers, CUSTOM KERAS LAYERS AND MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/data/git/cardio\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "\n",
    "# define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.notebook_imports import *\n",
    "from pyforest import *\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras.layers.convolutional import Conv3D, Conv3DTranspose\n",
    "\n",
    "GPU_IDS = '1'\n",
    "#current_gpu = choose_gpu_by_id(GPU_IDS)\n",
    "#print(current_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(1.)%1==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 -2 -1]\n",
      "[ 2.5 -1.  -0.5]\n",
      "((2, 3), (-1, -1), (0, 1))\n",
      "(slice(2, 13, 1), slice(None, None, 1), slice(0, 11, 1))\n",
      "(slice(None, None, 1), slice(1, 9, 1), slice(None, None, 1))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (11,8,9) into shape (10,8,10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-3695b0eb66c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mempty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (11,8,9) into shape (10,8,10)"
     ]
    }
   ],
   "source": [
    "# build slice interactive to pad/crop in one step\n",
    "import numpy as np\n",
    "temp_shape = np.array((10,10,10))\n",
    "empty = np.zeros(temp_shape)\n",
    "img_shape = np.array((15,8,9))\n",
    "img = np.ones(img_shape)\n",
    "diff = img_shape - temp_shape\n",
    "print(diff)\n",
    "diff = diff/2\n",
    "print(diff)\n",
    "diff = tuple((int(x),int(x)) if abs(x)%1==0 else (int(x),int(x)+1) for x in diff)\n",
    "print(diff)\n",
    "\n",
    "crop = tuple(slice(abs(d[0]),abs(d[1])+t,1) if d[1] > 0 else slice(None,None,1) for d,t in zip(diff,temp_shape))\n",
    "\n",
    "pad = tuple(slice(abs(d[0]),t-abs(d[1]),1) if d[1] < 0 else slice(None,None,1) for d,t in zip(diff,temp_shape))\n",
    "\n",
    "print(crop)\n",
    "print(pad)\n",
    "empty[pad] = img[crop]\n",
    "\n",
    "empty.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 -2 -1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "temp_shape = np.array((10,10,10))\n",
    "empty = np.zeros(temp_shape)\n",
    "img_shape = np.array((15,8,9))\n",
    "img = np.ones(img_shape)\n",
    "diff = img_shape - temp_shape\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 10)\n",
      "(15, 8, 9)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "temp_shape =(15,8,9)\n",
    "target_shape=(10,10,10)\n",
    "img = np.ones(temp_shape)\n",
    "padded = pad_and_crop(img, target_shape)\n",
    "print(padded.shape)\n",
    "orig = pad_and_crop(padded, temp_shape)\n",
    "print(orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.3 µs ± 138 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pad_and_crop(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.05807925, 0.87913938, 0.2689524 , 0.59411846, 0.4752153 ,\n",
       "         0.04479035, 0.48679211, 0.05908073, 0.02259369],\n",
       "        [0.54299318, 0.98048016, 0.34515032, 0.28432311, 0.88249342,\n",
       "         0.65236019, 0.07173703, 0.99035071, 0.48426553],\n",
       "        [0.50606116, 0.56998084, 0.89481091, 0.52157982, 0.95678293,\n",
       "         0.09761827, 0.69549744, 0.19912031, 0.84466653],\n",
       "        [0.51377544, 0.69307193, 0.9527031 , 0.13213195, 0.22347649,\n",
       "         0.78744716, 0.4671425 , 0.83713698, 0.43973386],\n",
       "        [0.53498896, 0.45662402, 0.83328119, 0.3056392 , 0.07841027,\n",
       "         0.64448762, 0.11611232, 0.0278658 , 0.36514913],\n",
       "        [0.53520601, 0.4150704 , 0.39870117, 0.21899294, 0.73608936,\n",
       "         0.72657855, 0.55630066, 0.44814277, 0.73781528],\n",
       "        [0.49018425, 0.37410546, 0.47152566, 0.75408359, 0.44361466,\n",
       "         0.72132013, 0.12271277, 0.98121923, 0.03612006],\n",
       "        [0.88130854, 0.81717421, 0.54579282, 0.42597479, 0.18406432,\n",
       "         0.79891496, 0.1017725 , 0.49514578, 0.82643638],\n",
       "        [0.81893671, 0.86266673, 0.10160151, 0.80064123, 0.54568228,\n",
       "         0.3404599 , 0.85547882, 0.59577427, 0.14220371]]),\n",
       " array([[0.4828172 , 0.55767264, 0.68993827, 0.42235572, 0.23574339,\n",
       "         0.90857293, 0.5022598 , 0.30901218],\n",
       "        [0.34335465, 0.99801843, 0.96691761, 0.25498934, 0.00686455,\n",
       "         0.31055983, 0.5329057 , 0.77540555],\n",
       "        [0.5526282 , 0.41389909, 0.7759927 , 0.39369766, 0.83684228,\n",
       "         0.75974364, 0.32661809, 0.6484803 ],\n",
       "        [0.57442864, 0.27654149, 0.44127725, 0.7346883 , 0.91042556,\n",
       "         0.72064263, 0.98942926, 0.20058708]]),\n",
       " array([], shape=(5, 0), dtype=float64),\n",
       " array([], shape=(8, 0), dtype=float64),\n",
       " array([[0.3497201 , 0.41158372, 0.96338013, 0.09607167, 0.37676957,\n",
       "         0.3542936 , 0.13788727],\n",
       "        [0.25828535, 0.95615015, 0.18636693, 0.99769491, 0.48156978,\n",
       "         0.66315058, 0.41602551],\n",
       "        [0.29971732, 0.24404707, 0.46663435, 0.38648409, 0.12541893,\n",
       "         0.91378736, 0.95480008],\n",
       "        [0.31520618, 0.87067175, 0.13645969, 0.52432083, 0.42516716,\n",
       "         0.53361442, 0.7455691 ],\n",
       "        [0.05389403, 0.10550765, 0.73950711, 0.81391511, 0.80681245,\n",
       "         0.37006415, 0.69935981],\n",
       "        [0.61603048, 0.42403769, 0.91130289, 0.25619002, 0.54193568,\n",
       "         0.01810912, 0.43175746]])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.random.rand(random.randint(0,9), random.randint(0,9)) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "lower = 5\n",
    "upper = 19\n",
    "target_shape = (10,10,10)\n",
    "images = [np.random.rand(random.randint(lower,upper),random.randint(lower,upper),random.randint(lower,upper)) for i in range(5)]\n",
    "\n",
    "img_nda, mask_nda,sax3d, saxtoax3d, a = map(lambda x: pad_and_crop(x, target_shape=target_shape),images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 10)\n",
      "(10, 10, 10)\n",
      "(10, 10, 10)\n",
      "(10, 10, 10)\n",
      "(10, 10, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(print(i.shape) for i in cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pad_and_crop(ndarray, target_shape=(10,10,10)):\n",
    "    \n",
    "    empty = np.zeros(target_shape)\n",
    "    target_shape= np.array(target_shape)\n",
    "    logging.debug('input shape', ndarray.shape)\n",
    "    logging.debug('target shape', target_shape)\n",
    "    \n",
    "    diff = ndarray.shape - target_shape\n",
    "    \n",
    "    # divide into summands to work with odd numbers\n",
    "    d = list((int(x//2),int(x//2)) if x%2==0 else (int(np.floor(x/2)), int(np.floor(x/2)+1)) for x in diff)\n",
    "    # replace the second slice parameter if it is None, which slice until end of ndarray\n",
    "    d = list((abs(x),abs(y)) if y !=0 else (abs(x),None) for x,y in d)\n",
    "    # create a bool list, negative numbers --> pad, else --> crop\n",
    "    pad_bool = diff<0\n",
    "    crop_bool = diff>0\n",
    "    \n",
    "    # create one slice obj for cropping and one for padding\n",
    "    pad = list(i if b else (None, None) for i,b in zip(d,pad_bool))\n",
    "    crop = list(i if b else (None, None) for i,b in zip(d,crop_bool))\n",
    "    \n",
    "    # Create one tuple of slice calls per pad/crop\n",
    "    # crop or pad from dif:-dif if second param not None, else replace by None to slice until the end\n",
    "    # slice params: slice(start,end,steps)\n",
    "    pad = tuple(slice(i[0], -i[1]) if i[1]!=None else slice(i[0],i[1]) for i in pad)\n",
    "    crop = tuple(slice(i[0], -i[1]) if i[1]!=None else slice(i[0],i[1]) for i in crop)\n",
    "    #print('crop',crop)\n",
    "    \n",
    "    # crop and pad in one step\n",
    "    empty[pad] = ndarray[crop]\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-c19ab4e4f826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "pad[diff<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8, 9)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (10,8,9) into shape (10,8,0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-e3bf11044a9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mempty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (10,8,9) into shape (10,8,0)"
     ]
    }
   ],
   "source": [
    "crop =(slice(2,-3), slice(None,None), slice(None,None))\n",
    "pad = (slice(None,None), slice(1,-1), slice(1,None))\n",
    "temp = img[crop]\n",
    "print(temp.shape)\n",
    "empty[pad] = img[crop]\n",
    "print(empty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 16, 224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 16, 224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create some testdata\n",
    "\n",
    "v_3ds = [np.random.random((1, 16, 224, 224, 3)) for i in range(5)]\n",
    "v_4d = np.stack(v_3ds, axis=1)\n",
    "v_4d.shape\n",
    "v_3ds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(16, 12, 10, 10, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 16, 10, 10, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 16, 10, 10, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  9,  4,  5,  7, 11,  3, 10,  6,  0,  2,  8], dtype=int32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a fake batch of a 3D stack\n",
    "v_3ds = [np.empty((16, 10, 10, 3)) for i in range(12)]\n",
    "[elem.fill(i) for i, elem in enumerate(v_3ds)]\n",
    "v_3ds = np.stack(v_3ds, axis=1)\n",
    "#v_3ds = np.stack(v_3ds)\n",
    "v_3ds.shape\n",
    "\n",
    "# swap axes\n",
    "v_3ds = tf.transpose(v_3ds, [1, 0, 2, 3, 4])\n",
    "v_3ds.shape\n",
    "# get indicies\n",
    "indicies = list(range(v_3ds.shape[0]))\n",
    "print(indicies)\n",
    "\n",
    "# create a list of slices\n",
    "v_3ds = [s for s in v_3ds]\n",
    "\n",
    "# zip together\n",
    "zipped = zip(v_3ds, indicies)\n",
    "\n",
    "zipped_shuffeld = tf.random.shuffle(zipped)\n",
    "\n",
    "v3d, ind =zip*(zipped_shuffeld)\n",
    "\n",
    "\n",
    "# evaluate\n",
    "\n",
    "# shuffle back\n",
    "v_3ds_shuffeled = \n",
    "data = (slice, ind) for slice, ind in zip(v3d, ind)\n",
    "sorted_by_second = sorted(data, key=lambda tup: tup[1])\n",
    "v3d, _ = zip*(sorted_by_second)\n",
    "\n",
    "# swap axis\n",
    "\n",
    "# evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected tensor with type tf.float32 not tf.float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-96b69806dd16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# apply 3D convolutions in a single session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_3ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbias_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       raise TypeError(\"Expected tensor with type %r not %r\" % (\n\u001b[0;32m---> 88\u001b[0;31m           dtype, value.dtype))\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected tensor with type tf.float32 not tf.float64"
     ]
    }
   ],
   "source": [
    "# apply 3D convolutions in a single session\n",
    "\n",
    "input = tf.constant(v_3ds[0], dtype=tf.float32)\n",
    "print(input.shape)\n",
    "bias_init = tf.constant_initializer(0)\n",
    "\n",
    "output = Conv3D(32, kernel_size=(3,3,3), strides=(2, 2, 2), padding='same')(input)\n",
    "\n",
    "with tf.Session() as s:\n",
    "\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    o = s.run(output)\n",
    "    print(o.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 16, 224, 224, 3)\n",
      "(1, 5, 8, 112, 112, 32)\n"
     ]
    }
   ],
   "source": [
    "# apply a 3D convolution on each timestep in a for loop - not sure if that works inside a graph\n",
    "\n",
    "def conv(input):\n",
    "    \n",
    "    result = []\n",
    "    for i in range(input.shape[1]):\n",
    "        result.append(Conv3D(32, kernel_size=(3,3,3), strides=(2, 2, 2), padding='same')(input[:,i,:,:,:]))\n",
    "    \n",
    "    return tf.stack(result, axis=1)\n",
    "\n",
    "input = tf.constant(v_4d, dtype=tf.float32)\n",
    "print(input.shape)\n",
    "output = conv(input)\n",
    "\n",
    "\n",
    "with tf.Session() as s:\n",
    "\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    o = s.run(output)\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv4d(Layer):\n",
    "    \n",
    "    def __init__(self, filters=2, kernel_size=(3,3,3),strides=(1,1,1), **kwargs):\n",
    "        self.strides = strides\n",
    "        self.kernel_size = kernel_size\n",
    "        self.filters = filters\n",
    "        super(Conv4d, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.conv3d = Conv3D(self.filters, kernel_size=self.kernel_size, strides=self.strides, padding='same')\n",
    "        self.conv3dshape = tuple((input_shape[0], *input_shape[2:]))\n",
    "        self.conv3d.build(self.conv3dshape)\n",
    "        self._trainable_weights = self.conv3d.trainable_weights\n",
    "        super(Conv4d, self).build(input_shape)\n",
    "\n",
    "    \n",
    "    def call(self, x):\n",
    "        print('conv4d called with x = {}'.format(x.shape))\n",
    "        result = []\n",
    "        for i in range(x.shape[1]):\n",
    "            vol_3d = x[:,i,:,:,:,:]\n",
    "            result.append(self.conv3d(vol_3d))\n",
    "        tensor = tf.stack(result, axis=1)\n",
    "        print('conv4d call will return: {}'.format(tensor.shape))\n",
    "        return tensor\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape_b = input_shape[0]\n",
    "        shape_t = input_shape[1]\n",
    "        shape_3d = input_shape[2:-1]\n",
    "        shape_3d = (shape_3d[0]//self.strides[0], shape_3d[1]//self.strides[1], shape_3d[2]//self.strides[2])\n",
    "        shape = (shape_b, shape_t, *shape_3d, self.filters)\n",
    "        print('conv4d output shape: {}'.format(shape))\n",
    "        return tuple(shape)\n",
    "    \n",
    "class Conv4DTranspose(Layer):\n",
    "    \n",
    "    def __init__(self, filters=2, kernel_size=(3,3,3),strides=(1,1,1), **kwargs):\n",
    "        self.strides = strides\n",
    "        self.kernel_size = kernel_size\n",
    "        self.filters = filters\n",
    "        super(Conv4DTranspose, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv3dtranspose = Conv3DTranspose(self.filters, kernel_size=self.kernel_size, strides=self.strides, padding='same')\n",
    "        self.conv3dtransposeshape = tuple((input_shape[0], *input_shape[2:]))\n",
    "        self.conv3dtranspose.build(self.conv3dtransposeshape)\n",
    "        self._trainable_weights = self.conv3dtranspose.trainable_weights\n",
    "        super(Conv4DTranspose, self).build(input_shape)\n",
    "    \n",
    "    \n",
    "    def call(self, x):\n",
    "        print('transpose4d called with x = {}'.format(x.shape))\n",
    "        result = []\n",
    "        for i in range(x.shape[1]):\n",
    "            vol_3d = x[:,i,:,:,:,:]\n",
    "            result.append(self.conv3dtranspose(vol_3d))\n",
    "        tensor = tf.stack(result, axis=1)\n",
    "        print('transpose4d call will return: {}'.format(tensor.shape))\n",
    "        return tensor\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \n",
    "        shape_b = input_shape[0]\n",
    "        shape_t = input_shape[1]\n",
    "        shape_3d = input_shape[2:-1]\n",
    "        shape_3d = (shape_3d[0]*self.strides[0], shape_3d[1]*self.strides[1], shape_3d[2]*self.strides[2])\n",
    "\n",
    "        shape = (shape_b, shape_t, *shape_3d, self.filters)\n",
    "        print('transpose4d output shape: {}'.format(shape))\n",
    "        return tuple(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 10, 11, 12, 3)\n",
      "(100, 5, 10, 11, 12, 3)\n",
      "(?, 5, 10, 11, 12, 3)\n",
      "conv4d called with x = (?, 5, 10, 11, 12, 3)\n",
      "conv4d call will return: (?, 5, 10, 11, 12, 32)\n",
      "conv4d output shape: (None, 5, 10, 11, 12, 32)\n",
      "transpose4d called with x = (?, 5, 10, 11, 12, 3)\n",
      "transpose4d call will return: (?, 5, ?, ?, ?, 32)\n",
      "transpose4d output shape: (None, 5, 10, 11, 12, 32)\n",
      "transpose4d called with x = (?, 5, ?, ?, ?, 32)\n",
      "transpose4d call will return: (?, 5, ?, ?, ?, 3)\n",
      "transpose4d output shape: (None, 5, 10, 11, 12, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5, 10, 11, 12, 3)  0         \n",
      "_________________________________________________________________\n",
      "conv4d (Conv4d)              (None, 5, 10, 11, 12, 32) 2624      \n",
      "_________________________________________________________________\n",
      "time_conv (TimeDistributed)  (None, 5, 10, 11, 12, 32) 27680     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 211200)            0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 50)                10560050  \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 19800)             1009800   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 5, 10, 11, 12, 3)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 5, 10, 11, 12, 3)  246       \n",
      "_________________________________________________________________\n",
      "transpose4d_1 (Conv4DTranspo (None, 5, 10, 11, 12, 32) 2624      \n",
      "_________________________________________________________________\n",
      "transpose4d_2 (Conv4DTranspo (None, 5, 10, 11, 12, 3)  2595      \n",
      "=================================================================\n",
      "Total params: 11,605,619\n",
      "Trainable params: 11,605,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.3230\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 992us/step - loss: 0.9282\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 981us/step - loss: 0.6038\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 980us/step - loss: 0.5074\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 982us/step - loss: 0.4431\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Flatten, Dense, Reshape\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "# create data\n",
    "x = np.random.random((100,5,10,11,12,3))\n",
    "print(x.shape)\n",
    "y = x *2\n",
    "#x = np.random.random((1,5,10,11,12,32))\n",
    "print(y.shape)\n",
    "\n",
    "input = Input((5,10,11,12,3), name='input')\n",
    "print(input.shape)\n",
    "shape = K.int_shape(input)\n",
    "output = Conv4d(filters=32, name='conv4d')(input)\n",
    "output = TimeDistributed(Conv3D(32, kernel_size=3, strides=1, padding='same'), name='time_conv')(output)\n",
    "output = Flatten()(output)\n",
    "output = Dense(50, activation='relu', name='dense1')(output)\n",
    "output = Dense(shape[1] * shape[2] * shape[3] * shape[4] * shape[5], activation='relu', name='dense2')(output)\n",
    "output = Reshape((shape[1], shape[2], shape[3], shape[4], shape[5]), name='reshape')(output)\n",
    "output = TimeDistributed(Conv3DTranspose(3, kernel_size=3, strides=1, padding='same', name='time_transpose'))(output)\n",
    "output = Conv4DTranspose(filters=32, name='transpose4d_1')(output)\n",
    "output = Conv4DTranspose(filters=3, name='transpose4d_2')(output)\n",
    "\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "result = model.fit(x=x, y=y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_50:0' shape=(?, 5, 10, 11, 12, 3) dtype=float32>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 10, 11, 12, 3)\n",
      "(1, 5, 10, 11, 12, 3)\n",
      "(?, 5, 10, 11, 12, 3)\n",
      "(?, 5, 10, 11, 12, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5, 10, 11, 12, 3)  0         \n",
      "_________________________________________________________________\n",
      "lambda_29 (Lambda)           (None, 5, 10, 11, 12, 3)  0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3490\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3490\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3490\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3490\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3490\n"
     ]
    }
   ],
   "source": [
    "# apply a 3D convolution on each timestep in a for loop - not sure if that works inside a graph\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Lambda\n",
    "def conv(input):\n",
    "    print(input.shape)\n",
    "    result = []\n",
    "    for i in range(input.shape[1]):\n",
    "        result.append(Conv3D(3, kernel_size=(3,3,3), strides=(1, 1, 1), padding='same')(input[:,i,:,:,:,:]))\n",
    "    return tf.stack(result, axis=1)\n",
    "\n",
    "\n",
    "def get_output_shape(input_shape):\n",
    "    \n",
    "    return tuple(input_shape)\n",
    "\n",
    "# create data\n",
    "x = np.random.random((1,5,10,11,12,3))\n",
    "print(x.shape)\n",
    "y = x *2\n",
    "print(y.shape)\n",
    "\n",
    "input = Input((5,10,11,12,3), name='input')\n",
    "print(input.shape)\n",
    "output = Lambda(conv, output_shape=get_output_shape)(input)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.compile(optimizer = 'adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "result = model.fit(x=x, y=y, epochs=5)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-518d34ab18cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf.keras import layers\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               latent_dim=32,\n",
    "               intermediate_dim=64,\n",
    "               name='encoder',\n",
    "               **kwargs):\n",
    "        super(Encoder, self).__init__(name=name, **kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n",
    "        self.dense_mean = layers.Dense(latent_dim)\n",
    "        self.dense_log_var = layers.Dense(latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        z_mean = self.dense_mean(x)\n",
    "        z_log_var = self.dense_log_var(x)\n",
    "        z = self.sampling((z_mean, z_log_var))\n",
    "        return z_mean, z_log_var, z\n",
    "\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "  \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               original_dim,\n",
    "               intermediate_dim=64,\n",
    "               name='decoder',\n",
    "               **kwargs):\n",
    "    super(Decoder, self).__init__(name=name, **kwargs)\n",
    "    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n",
    "    self.dense_output = layers.Dense(original_dim, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        return self.dense_output(x)\n",
    "\n",
    "\n",
    "class VariationalAutoEncoder(tf.keras.Model):\n",
    "    \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               original_dim,\n",
    "               intermediate_dim=64,\n",
    "               latent_dim=32,\n",
    "               name='autoencoder',\n",
    "               **kwargs):\n",
    "        super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\n",
    "        self.original_dim = original_dim\n",
    "        self.encoder = Encoder(latent_dim=latent_dim,\n",
    "                               intermediate_dim=intermediate_dim)\n",
    "        self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Add KL divergence regularization loss.\n",
    "        kl_loss = - 0.5 * tf.reduce_mean(\n",
    "            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "        self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "\n",
    "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "\n",
    "original_dim = 784\n",
    "vae = VariationalAutoEncoder(original_dim, 64, 32)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "vae.compile(optimizer, loss=keras.losses.mean_squared_error)\n",
    "vae.summary()\n",
    "#vae.fit(x_train, x_train, epochs=3, batch_size=64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPU_IDS': '1',\n",
       " 'EXPERIMENT': '3D/gcn/vae',\n",
       " 'DIM': [16, 224, 224],\n",
       " 'SPACING': [6, 1.0, 1.0],\n",
       " 'IMG_CHANNELS': 1,\n",
       " 'MASK_VALUES': [0, 1, 2, 3],\n",
       " 'MASK_CLASSES': 4,\n",
       " 'ARCHITECTURE': '3D',\n",
       " 'AUGMENT': False,\n",
       " 'SHUFFLE': True,\n",
       " 'AUGMENT_GRID': False,\n",
       " 'SEED': 42,\n",
       " 'BATCHSIZE': 2,\n",
       " 'SCALER': 'MinMax',\n",
       " 'EPOCHS': 50,\n",
       " 'SINGLE_OUTPUT': True,\n",
       " 'MSE': False,\n",
       " 'WEIGHTS': False,\n",
       " 'DATASET': 'gcn',\n",
       " 'TRAIN_PATH': 'data/raw/tetra/2D/train/',\n",
       " 'VAL_PATH': 'data/raw/tetra/2D/val/',\n",
       " 'TEST_PATH': 'data/raw/tetra/2D/test/',\n",
       " 'MODEL_PATH': 'models/3D/gcn/vae/2019-10-17_10_22',\n",
       " 'TENSORBOARD_LOG_DIR': 'reports/tensorboard_logs/3D/gcn/vae/2019-10-17_10_22',\n",
       " 'CONFIG_PATH': 'reports/configs/3D/gcn/vae/2019-10-17_10_22',\n",
       " 'HISTORY_PATH': 'reports/history/3D/gcn/vae/2019-10-17_10_22'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a config\n",
    "EXPERIMENT = '3D/gcn/vae'\n",
    "now = datetime.datetime.now()\n",
    "# image params\n",
    "DIM = [16, 224, 224]\n",
    "SPACING = [6, 1.0,1.0] # used by sitk, opposite order than numpy or tensorflow!\n",
    "# Greyscale images\n",
    "IMG_CHANNELS = 1\n",
    "# RV = 1 = Y[...,0] \n",
    "# Myo = 2 = Y[...,1] \n",
    "# LV = 3 = Y[...,2]\n",
    "MASK_VALUES = [0, 1, 2, 3]  \n",
    "MASK_CLASSES = len(MASK_VALUES)\n",
    "ARCHITECTURE = '3D'\n",
    "AUGMENT = False\n",
    "SHUFFLE = True\n",
    "AUGMENT_GRID = False\n",
    "SEED = 42\n",
    "BATCHSIZE =  2 # 64, 16, 1\n",
    "SCALER = 'MinMax'\n",
    "EPOCHS = 50\n",
    "\n",
    "SINGLE_OUTPUT = True\n",
    "\n",
    "MSE = False \n",
    "WEIGHTS = False\n",
    "\n",
    "# path params\n",
    "DATASET = 'gcn'  # 'acdc' # or 'tetra'\n",
    "TRAIN_PATH = 'data/raw/tetra/2D/train/'\n",
    "VAL_PATH = 'data/raw/tetra/2D/val/'\n",
    "TEST_PATH = 'data/raw/tetra/2D/test/'\n",
    "\n",
    "MODEL_PATH = os.path.join(os.path.join('models', EXPERIMENT), str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "TENSORBOARD_LOG_DIR = os.path.join(os.path.join('reports/tensorboard_logs', EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "CONFIG_PATH = os.path.join(os.path.join('reports/configs/',EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "HISTORY_PATH = os.path.join(os.path.join('reports/history/',EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "\n",
    "\n",
    "\n",
    "config = dict(((key, value) for key, value in locals().items()\n",
    "               if key.isupper() and key not in ['HTML', 'K']))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.vae import get_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 16, 224, 224, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 8, 112, 112,  896         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 4, 56, 56, 64 55360       conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 2, 28, 28, 12 221312      conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 200704)       0           conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 16)           3211280     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,488,916\n",
      "Trainable params: 3,488,916\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 200704)            602112    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 2, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_6 (Conv3DTr (None, 4, 56, 56, 128)    442496    \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_7 (Conv3DTr (None, 8, 112, 112, 64)   221248    \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_8 (Conv3DTr (None, 16, 224, 224, 32)  55328     \n",
      "_________________________________________________________________\n",
      "decoder_output (Conv3DTransp (None, 16, 224, 224, 1)   865       \n",
      "=================================================================\n",
      "Total params: 1,322,049\n",
      "Trainable params: 1,322,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 16, 224, 224, 1)   0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 3488916   \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 16, 224, 224, 1)   1322049   \n",
      "=================================================================\n",
      "Total params: 4,810,965\n",
      "Trainable params: 4,810,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder, vae = get_vae(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
