{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD CUSTOM LAMBDA Layers, CUSTOM KERAS LAYERS AND MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/data/git/cardio\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "\n",
    "# define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.notebook_imports import *\n",
    "from pyforest import *\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras.layers.convolutional import Conv3D, Conv3DTranspose\n",
    "\n",
    "GPU_IDS = '1'\n",
    "#current_gpu = choose_gpu_by_id(GPU_IDS)\n",
    "#print(current_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 16, 224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 16, 224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create some testdata\n",
    "\n",
    "v_3ds = [np.random.random((1, 16, 224, 224, 3)) for i in range(5)]\n",
    "v_4d = np.stack(v_3ds, axis=1)\n",
    "v_4d.shape\n",
    "v_3ds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(16, 12, 10, 10, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 16, 10, 10, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 16, 10, 10, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  9,  4,  5,  7, 11,  3, 10,  6,  0,  2,  8], dtype=int32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a fake batch of a 3D stack\n",
    "v_3ds = [np.empty((16, 10, 10, 3)) for i in range(12)]\n",
    "[elem.fill(i) for i, elem in enumerate(v_3ds)]\n",
    "v_3ds = np.stack(v_3ds, axis=1)\n",
    "#v_3ds = np.stack(v_3ds)\n",
    "v_3ds.shape\n",
    "\n",
    "# swap axes\n",
    "v_3ds = tf.transpose(v_3ds, [1, 0, 2, 3, 4])\n",
    "v_3ds.shape\n",
    "# get indicies\n",
    "indicies = list(range(v_3ds.shape[0]))\n",
    "print(indicies)\n",
    "\n",
    "# create a list of slices\n",
    "v_3ds = [s for s in v_3ds]\n",
    "\n",
    "# zip together\n",
    "zipped = zip(v_3ds, indicies)\n",
    "\n",
    "zipped_shuffeld = tf.random.shuffle(zipped)\n",
    "\n",
    "v3d, ind =zip*(zipped_shuffeld)\n",
    "\n",
    "\n",
    "# evaluate\n",
    "\n",
    "# shuffle back\n",
    "v_3ds_shuffeled = \n",
    "data = (slice, ind) for slice, ind in zip(v3d, ind)\n",
    "sorted_by_second = sorted(data, key=lambda tup: tup[1])\n",
    "v3d, _ = zip*(sorted_by_second)\n",
    "\n",
    "# swap axis\n",
    "\n",
    "# evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected tensor with type tf.float32 not tf.float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-96b69806dd16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# apply 3D convolutions in a single session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_3ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbias_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       raise TypeError(\"Expected tensor with type %r not %r\" % (\n\u001b[0;32m---> 88\u001b[0;31m           dtype, value.dtype))\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected tensor with type tf.float32 not tf.float64"
     ]
    }
   ],
   "source": [
    "# apply 3D convolutions in a single session\n",
    "\n",
    "input = tf.constant(v_3ds[0], dtype=tf.float32)\n",
    "print(input.shape)\n",
    "bias_init = tf.constant_initializer(0)\n",
    "\n",
    "output = Conv3D(32, kernel_size=(3,3,3), strides=(2, 2, 2), padding='same')(input)\n",
    "\n",
    "with tf.Session() as s:\n",
    "\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    o = s.run(output)\n",
    "    print(o.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 16, 224, 224, 3)\n",
      "(1, 5, 8, 112, 112, 32)\n"
     ]
    }
   ],
   "source": [
    "# apply a 3D convolution on each timestep in a for loop - not sure if that works inside a graph\n",
    "\n",
    "def conv(input):\n",
    "    \n",
    "    result = []\n",
    "    for i in range(input.shape[1]):\n",
    "        result.append(Conv3D(32, kernel_size=(3,3,3), strides=(2, 2, 2), padding='same')(input[:,i,:,:,:]))\n",
    "    \n",
    "    return tf.stack(result, axis=1)\n",
    "\n",
    "input = tf.constant(v_4d, dtype=tf.float32)\n",
    "print(input.shape)\n",
    "output = conv(input)\n",
    "\n",
    "\n",
    "with tf.Session() as s:\n",
    "\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    o = s.run(output)\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv4d(Layer):\n",
    "    \n",
    "    def __init__(self, filters=2, kernel_size=(3,3,3),strides=(1,1,1), **kwargs):\n",
    "        self.strides = strides\n",
    "        self.kernel_size = kernel_size\n",
    "        self.filters = filters\n",
    "        super(Conv4d, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.conv3d = Conv3D(self.filters, kernel_size=self.kernel_size, strides=self.strides, padding='same')\n",
    "        self.conv3dshape = tuple((input_shape[0], *input_shape[2:]))\n",
    "        self.conv3d.build(self.conv3dshape)\n",
    "        self._trainable_weights = self.conv3d.trainable_weights\n",
    "        super(Conv4d, self).build(input_shape)\n",
    "\n",
    "    \n",
    "    def call(self, x):\n",
    "        print('conv4d called with x = {}'.format(x.shape))\n",
    "        result = []\n",
    "        for i in range(x.shape[1]):\n",
    "            vol_3d = x[:,i,:,:,:,:]\n",
    "            result.append(self.conv3d(vol_3d))\n",
    "        tensor = tf.stack(result, axis=1)\n",
    "        print('conv4d call will return: {}'.format(tensor.shape))\n",
    "        return tensor\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape_b = input_shape[0]\n",
    "        shape_t = input_shape[1]\n",
    "        shape_3d = input_shape[2:-1]\n",
    "        shape_3d = (shape_3d[0]//self.strides[0], shape_3d[1]//self.strides[1], shape_3d[2]//self.strides[2])\n",
    "        shape = (shape_b, shape_t, *shape_3d, self.filters)\n",
    "        print('conv4d output shape: {}'.format(shape))\n",
    "        return tuple(shape)\n",
    "    \n",
    "class Conv4DTranspose(Layer):\n",
    "    \n",
    "    def __init__(self, filters=2, kernel_size=(3,3,3),strides=(1,1,1), **kwargs):\n",
    "        self.strides = strides\n",
    "        self.kernel_size = kernel_size\n",
    "        self.filters = filters\n",
    "        super(Conv4DTranspose, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv3dtranspose = Conv3DTranspose(self.filters, kernel_size=self.kernel_size, strides=self.strides, padding='same')\n",
    "        self.conv3dtransposeshape = tuple((input_shape[0], *input_shape[2:]))\n",
    "        self.conv3dtranspose.build(self.conv3dtransposeshape)\n",
    "        self._trainable_weights = self.conv3dtranspose.trainable_weights\n",
    "        super(Conv4DTranspose, self).build(input_shape)\n",
    "    \n",
    "    \n",
    "    def call(self, x):\n",
    "        print('transpose4d called with x = {}'.format(x.shape))\n",
    "        result = []\n",
    "        for i in range(x.shape[1]):\n",
    "            vol_3d = x[:,i,:,:,:,:]\n",
    "            result.append(self.conv3dtranspose(vol_3d))\n",
    "        tensor = tf.stack(result, axis=1)\n",
    "        print('transpose4d call will return: {}'.format(tensor.shape))\n",
    "        return tensor\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \n",
    "        shape_b = input_shape[0]\n",
    "        shape_t = input_shape[1]\n",
    "        shape_3d = input_shape[2:-1]\n",
    "        shape_3d = (shape_3d[0]*self.strides[0], shape_3d[1]*self.strides[1], shape_3d[2]*self.strides[2])\n",
    "\n",
    "        shape = (shape_b, shape_t, *shape_3d, self.filters)\n",
    "        print('transpose4d output shape: {}'.format(shape))\n",
    "        return tuple(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 10, 11, 12, 3)\n",
      "(100, 5, 10, 11, 12, 3)\n",
      "(?, 5, 10, 11, 12, 3)\n",
      "conv4d called with x = (?, 5, 10, 11, 12, 3)\n",
      "conv4d call will return: (?, 5, 10, 11, 12, 32)\n",
      "conv4d output shape: (None, 5, 10, 11, 12, 32)\n",
      "transpose4d called with x = (?, 5, 10, 11, 12, 3)\n",
      "transpose4d call will return: (?, 5, ?, ?, ?, 32)\n",
      "transpose4d output shape: (None, 5, 10, 11, 12, 32)\n",
      "transpose4d called with x = (?, 5, ?, ?, ?, 32)\n",
      "transpose4d call will return: (?, 5, ?, ?, ?, 3)\n",
      "transpose4d output shape: (None, 5, 10, 11, 12, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5, 10, 11, 12, 3)  0         \n",
      "_________________________________________________________________\n",
      "conv4d (Conv4d)              (None, 5, 10, 11, 12, 32) 2624      \n",
      "_________________________________________________________________\n",
      "time_conv (TimeDistributed)  (None, 5, 10, 11, 12, 32) 27680     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 211200)            0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 50)                10560050  \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 19800)             1009800   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 5, 10, 11, 12, 3)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 5, 10, 11, 12, 3)  246       \n",
      "_________________________________________________________________\n",
      "transpose4d_1 (Conv4DTranspo (None, 5, 10, 11, 12, 32) 2624      \n",
      "_________________________________________________________________\n",
      "transpose4d_2 (Conv4DTranspo (None, 5, 10, 11, 12, 3)  2595      \n",
      "=================================================================\n",
      "Total params: 11,605,619\n",
      "Trainable params: 11,605,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.3230\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 992us/step - loss: 0.9282\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 981us/step - loss: 0.6038\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 980us/step - loss: 0.5074\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 982us/step - loss: 0.4431\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Flatten, Dense, Reshape\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "# create data\n",
    "x = np.random.random((100,5,10,11,12,3))\n",
    "print(x.shape)\n",
    "y = x *2\n",
    "#x = np.random.random((1,5,10,11,12,32))\n",
    "print(y.shape)\n",
    "\n",
    "input = Input((5,10,11,12,3), name='input')\n",
    "print(input.shape)\n",
    "shape = K.int_shape(input)\n",
    "output = Conv4d(filters=32, name='conv4d')(input)\n",
    "output = TimeDistributed(Conv3D(32, kernel_size=3, strides=1, padding='same'), name='time_conv')(output)\n",
    "output = Flatten()(output)\n",
    "output = Dense(50, activation='relu', name='dense1')(output)\n",
    "output = Dense(shape[1] * shape[2] * shape[3] * shape[4] * shape[5], activation='relu', name='dense2')(output)\n",
    "output = Reshape((shape[1], shape[2], shape[3], shape[4], shape[5]), name='reshape')(output)\n",
    "output = TimeDistributed(Conv3DTranspose(3, kernel_size=3, strides=1, padding='same', name='time_transpose'))(output)\n",
    "output = Conv4DTranspose(filters=32, name='transpose4d_1')(output)\n",
    "output = Conv4DTranspose(filters=3, name='transpose4d_2')(output)\n",
    "\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "result = model.fit(x=x, y=y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_50:0' shape=(?, 5, 10, 11, 12, 3) dtype=float32>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 10, 11, 12, 3)\n",
      "(1, 5, 10, 11, 12, 3)\n",
      "(?, 5, 10, 11, 12, 3)\n",
      "(?, 5, 10, 11, 12, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5, 10, 11, 12, 3)  0         \n",
      "_________________________________________________________________\n",
      "lambda_29 (Lambda)           (None, 5, 10, 11, 12, 3)  0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3490\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3490\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3490\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3490\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3490\n"
     ]
    }
   ],
   "source": [
    "# apply a 3D convolution on each timestep in a for loop - not sure if that works inside a graph\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Lambda\n",
    "def conv(input):\n",
    "    print(input.shape)\n",
    "    result = []\n",
    "    for i in range(input.shape[1]):\n",
    "        result.append(Conv3D(3, kernel_size=(3,3,3), strides=(1, 1, 1), padding='same')(input[:,i,:,:,:,:]))\n",
    "    return tf.stack(result, axis=1)\n",
    "\n",
    "\n",
    "def get_output_shape(input_shape):\n",
    "    \n",
    "    return tuple(input_shape)\n",
    "\n",
    "# create data\n",
    "x = np.random.random((1,5,10,11,12,3))\n",
    "print(x.shape)\n",
    "y = x *2\n",
    "print(y.shape)\n",
    "\n",
    "input = Input((5,10,11,12,3), name='input')\n",
    "print(input.shape)\n",
    "output = Lambda(conv, output_shape=get_output_shape)(input)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.compile(optimizer = 'adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "result = model.fit(x=x, y=y, epochs=5)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-518d34ab18cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf.keras import layers\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               latent_dim=32,\n",
    "               intermediate_dim=64,\n",
    "               name='encoder',\n",
    "               **kwargs):\n",
    "        super(Encoder, self).__init__(name=name, **kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n",
    "        self.dense_mean = layers.Dense(latent_dim)\n",
    "        self.dense_log_var = layers.Dense(latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        z_mean = self.dense_mean(x)\n",
    "        z_log_var = self.dense_log_var(x)\n",
    "        z = self.sampling((z_mean, z_log_var))\n",
    "        return z_mean, z_log_var, z\n",
    "\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "  \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               original_dim,\n",
    "               intermediate_dim=64,\n",
    "               name='decoder',\n",
    "               **kwargs):\n",
    "    super(Decoder, self).__init__(name=name, **kwargs)\n",
    "    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n",
    "    self.dense_output = layers.Dense(original_dim, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        return self.dense_output(x)\n",
    "\n",
    "\n",
    "class VariationalAutoEncoder(tf.keras.Model):\n",
    "    \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               original_dim,\n",
    "               intermediate_dim=64,\n",
    "               latent_dim=32,\n",
    "               name='autoencoder',\n",
    "               **kwargs):\n",
    "        super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\n",
    "        self.original_dim = original_dim\n",
    "        self.encoder = Encoder(latent_dim=latent_dim,\n",
    "                               intermediate_dim=intermediate_dim)\n",
    "        self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Add KL divergence regularization loss.\n",
    "        kl_loss = - 0.5 * tf.reduce_mean(\n",
    "            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "        self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "\n",
    "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "\n",
    "original_dim = 784\n",
    "vae = VariationalAutoEncoder(original_dim, 64, 32)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "vae.compile(optimizer, loss=keras.losses.mean_squared_error)\n",
    "vae.summary()\n",
    "#vae.fit(x_train, x_train, epochs=3, batch_size=64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPU_IDS': '1',\n",
       " 'EXPERIMENT': '3D/gcn/vae',\n",
       " 'DIM': [16, 224, 224],\n",
       " 'SPACING': [6, 1.0, 1.0],\n",
       " 'IMG_CHANNELS': 1,\n",
       " 'MASK_VALUES': [0, 1, 2, 3],\n",
       " 'MASK_CLASSES': 4,\n",
       " 'ARCHITECTURE': '3D',\n",
       " 'AUGMENT': False,\n",
       " 'SHUFFLE': True,\n",
       " 'AUGMENT_GRID': False,\n",
       " 'SEED': 42,\n",
       " 'BATCHSIZE': 2,\n",
       " 'SCALER': 'MinMax',\n",
       " 'EPOCHS': 50,\n",
       " 'SINGLE_OUTPUT': True,\n",
       " 'MSE': False,\n",
       " 'WEIGHTS': False,\n",
       " 'DATASET': 'gcn',\n",
       " 'TRAIN_PATH': 'data/raw/tetra/2D/train/',\n",
       " 'VAL_PATH': 'data/raw/tetra/2D/val/',\n",
       " 'TEST_PATH': 'data/raw/tetra/2D/test/',\n",
       " 'MODEL_PATH': 'models/3D/gcn/vae/2019-10-17_10_22',\n",
       " 'TENSORBOARD_LOG_DIR': 'reports/tensorboard_logs/3D/gcn/vae/2019-10-17_10_22',\n",
       " 'CONFIG_PATH': 'reports/configs/3D/gcn/vae/2019-10-17_10_22',\n",
       " 'HISTORY_PATH': 'reports/history/3D/gcn/vae/2019-10-17_10_22'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a config\n",
    "EXPERIMENT = '3D/gcn/vae'\n",
    "now = datetime.datetime.now()\n",
    "# image params\n",
    "DIM = [16, 224, 224]\n",
    "SPACING = [6, 1.0,1.0] # used by sitk, opposite order than numpy or tensorflow!\n",
    "# Greyscale images\n",
    "IMG_CHANNELS = 1\n",
    "# RV = 1 = Y[...,0] \n",
    "# Myo = 2 = Y[...,1] \n",
    "# LV = 3 = Y[...,2]\n",
    "MASK_VALUES = [0, 1, 2, 3]  \n",
    "MASK_CLASSES = len(MASK_VALUES)\n",
    "ARCHITECTURE = '3D'\n",
    "AUGMENT = False\n",
    "SHUFFLE = True\n",
    "AUGMENT_GRID = False\n",
    "SEED = 42\n",
    "BATCHSIZE =  2 # 64, 16, 1\n",
    "SCALER = 'MinMax'\n",
    "EPOCHS = 50\n",
    "\n",
    "SINGLE_OUTPUT = True\n",
    "\n",
    "MSE = False \n",
    "WEIGHTS = False\n",
    "\n",
    "# path params\n",
    "DATASET = 'gcn'  # 'acdc' # or 'tetra'\n",
    "TRAIN_PATH = 'data/raw/tetra/2D/train/'\n",
    "VAL_PATH = 'data/raw/tetra/2D/val/'\n",
    "TEST_PATH = 'data/raw/tetra/2D/test/'\n",
    "\n",
    "MODEL_PATH = os.path.join(os.path.join('models', EXPERIMENT), str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "TENSORBOARD_LOG_DIR = os.path.join(os.path.join('reports/tensorboard_logs', EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "CONFIG_PATH = os.path.join(os.path.join('reports/configs/',EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "HISTORY_PATH = os.path.join(os.path.join('reports/history/',EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "\n",
    "\n",
    "\n",
    "config = dict(((key, value) for key, value in locals().items()\n",
    "               if key.isupper() and key not in ['HTML', 'K']))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.vae import get_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 16, 224, 224, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 8, 112, 112,  896         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 4, 56, 56, 64 55360       conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 2, 28, 28, 12 221312      conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 200704)       0           conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 16)           3211280     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,488,916\n",
      "Trainable params: 3,488,916\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 200704)            602112    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 2, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_6 (Conv3DTr (None, 4, 56, 56, 128)    442496    \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_7 (Conv3DTr (None, 8, 112, 112, 64)   221248    \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_8 (Conv3DTr (None, 16, 224, 224, 32)  55328     \n",
      "_________________________________________________________________\n",
      "decoder_output (Conv3DTransp (None, 16, 224, 224, 1)   865       \n",
      "=================================================================\n",
      "Total params: 1,322,049\n",
      "Trainable params: 1,322,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 16, 224, 224, 1)   0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 3488916   \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 16, 224, 224, 1)   1322049   \n",
      "=================================================================\n",
      "Total params: 4,810,965\n",
      "Trainable params: 4,810,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder, vae = get_vae(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
